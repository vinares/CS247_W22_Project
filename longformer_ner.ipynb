{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "longformer-ner-tim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Get access to our google drive"
      ],
      "metadata": {
        "id": "rwp4QvZOQUNZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZxVNdg8tIRq",
        "outputId": "c57184c4-a8c3-4003-f90d-f71cc9aca986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "··········\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 指定Google Drive云端硬盘的根目录，名为drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive # 此时colab中出现drive的文件夹，里面就是你的google drive的根目录文件"
      ],
      "metadata": {
        "id": "fQpd0Fv1F3Sx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ff0762-b5ba-4483-e9ae-20025124ff5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/Colab Notebooks\") "
      ],
      "metadata": {
        "id": "a5nVhDLbHGkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.Configuration\n",
        "This notebook can either train a new model or load a previously trained model (made from previous notebook version). Furthermore, this notebook can either create new NER tokens or load existing tokens (made from previous notebook version). In this notebook version, we will load model and load NER tokens."
      ],
      "metadata": {
        "id": "iU5bltYxQmNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# VERSION FOR SAVING/LOADING MODEL WEIGHTS\n",
        "# THIS SHOULD MATCH THE MODEL IN LOAD_MODEL_FROM\n",
        "VER=14 \n",
        "\n",
        "# IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n",
        "# OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\n",
        "LOAD_TOKENS_FROM = './TF-LongFormer-v12'\n",
        "\n",
        "# IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n",
        "# OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\n",
        "LOAD_MODEL_FROM = './TF-LongFormer-v14'\n",
        "\n",
        "# IF FOLLOWING IS NONE, THEN NOTEBOOK \n",
        "# USES INTERNET AND DOWNLOADS HUGGINGFACE \n",
        "# CONFIG, TOKENIZER, AND MODEL\n",
        "DOWNLOADED_MODEL_PATH = './TF-LongFormer-v12'\n",
        "\n",
        "if DOWNLOADED_MODEL_PATH is None:\n",
        "    DOWNLOADED_MODEL_PATH = 'model'    \n",
        "MODEL_NAME = 'allenai/longformer-base-4096'"
      ],
      "metadata": {
        "id": "IycJq2haQRmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if DOWNLOADED_MODEL_PATH == 'model':\n",
        "    os.mkdir('model')\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    tokenizer.save_pretrained('model')\n",
        "\n",
        "    config = AutoConfig.from_pretrained(MODEL_NAME) \n",
        "    config.save_pretrained('model')\n",
        "\n",
        "    backbone = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n",
        "    backbone.save_pretrained('model')"
      ],
      "metadata": {
        "id": "umHf8yvqRFFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Install Library"
      ],
      "metadata": {
        "id": "RVXoCj6oQymH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_HkH4nquxZL",
        "outputId": "ec59dae2-1cb9-403f-893d-ae07b237cec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.24.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.44.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (13.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Load Libraries"
      ],
      "metadata": {
        "id": "-XIomw_fQ3in"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "from transformers import *\n",
        "print('TF version',tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtwPn_xZRK7I",
        "outputId": "ac4497ff-1fca-42e9-e21d-56b10ad8e579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USE MULTIPLE GPUS\n",
        "# DECLARE HOW MANY GPUS YOU WISH TO USE. \n",
        "# KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\n",
        "\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('multiple strategy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5via-J6bSyNb",
        "outputId": "534d9e3a-45b3-465f-f209-59029a22e897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "multiple strategy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
        "print('Mixed precision enabled')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9OEl0A7TWUt",
        "outputId": "58972297-057f-4022-b4ce-c444c066fff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mixed precision enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Load Trainig data."
      ],
      "metadata": {
        "id": "t47GGHL1Q-HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('./ori_data/train.csv')\n",
        "print( train.shape )\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "1dw6OWR0TZGc",
        "outputId": "820fe6f4-0841-4c5d-aeba-1c2da3671dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144293, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4c5497e-cd68-454a-8970-9c7306fffc9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>discourse_start</th>\n",
              "      <th>discourse_end</th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_type_num</th>\n",
              "      <th>predictionstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>8.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>Modern humans today are always on their phone....</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Lead 1</td>\n",
              "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>230.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>They are some really bad consequences when stu...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Position 1</td>\n",
              "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>313.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>Some certain areas in the United States ban ph...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Evidence 1</td>\n",
              "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>402.0</td>\n",
              "      <td>758.0</td>\n",
              "      <td>When people have phones, they know about certa...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Evidence 2</td>\n",
              "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>759.0</td>\n",
              "      <td>886.0</td>\n",
              "      <td>Driving is one of the way how to get around. P...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Claim 1</td>\n",
              "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4c5497e-cd68-454a-8970-9c7306fffc9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4c5497e-cd68-454a-8970-9c7306fffc9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4c5497e-cd68-454a-8970-9c7306fffc9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             id  discourse_id  discourse_start  discourse_end  \\\n",
              "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
              "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
              "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
              "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
              "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
              "\n",
              "                                      discourse_text discourse_type  \\\n",
              "0  Modern humans today are always on their phone....           Lead   \n",
              "1  They are some really bad consequences when stu...       Position   \n",
              "2  Some certain areas in the United States ban ph...       Evidence   \n",
              "3  When people have phones, they know about certa...       Evidence   \n",
              "4  Driving is one of the way how to get around. P...          Claim   \n",
              "\n",
              "  discourse_type_num                                   predictionstring  \n",
              "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
              "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
              "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
              "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
              "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The train labels are:')\n",
        "train.discourse_type.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FtuWUptTlax",
        "outputId": "5545e68a-a35e-4be3-acfa-d8faf8f8f6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train labels are:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n",
              "       'Counterclaim', 'Rebuttal'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IDS = train.id.unique()\n",
        "print('There are',len(IDS),'train texts.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1gcNsaxTpbu",
        "outputId": "efc58fcd-fefb-481f-f90b-08a796c6fdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 15594 train texts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Tokenize Train\n",
        "The following code converts Kaggle's train dataset into a NER token array that we can use to train a NER transformer. I have made it very clear which targets belong to which class. This allows us to very easily convert this code to Question Answer formulation if we want. Just change the 14 NER arrays to be 14 arrays of start position and end position for each of the 7 classes. (You will need to think creatively what to do if a single text has multiple of one class)."
      ],
      "metadata": {
        "id": "KkhF9uHQREeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 1024\n",
        "\n",
        "# THE TOKENS AND ATTENTION ARRAYS\n",
        "tokenizer = AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)\n",
        "train_tokens = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n",
        "train_attention = np.zeros((len(IDS),MAX_LEN), dtype='int32')\n",
        "\n",
        "# THE 14 CLASSES FOR NER\n",
        "lead_b = np.zeros((len(IDS),MAX_LEN))\n",
        "lead_i = np.zeros((len(IDS),MAX_LEN))\n",
        "\n",
        "position_b = np.zeros((len(IDS),MAX_LEN))\n",
        "position_i = np.zeros((len(IDS),MAX_LEN))\n",
        "\n",
        "evidence_b = np.zeros((len(IDS),MAX_LEN))\n",
        "evidence_i = np.zeros((len(IDS),MAX_LEN))\n",
        "\n",
        "claim_b = np.zeros((len(IDS),MAX_LEN))\n",
        "claim_i = np.zeros((len(IDS),MAX_LEN))\n",
        "\n",
        "conclusion_b = np.zeros((len(IDS),MAX_LEN))\n",
        "conclusion_i = np.zeros((len(IDS),MAX_LEN))\n",
        "\n",
        "counterclaim_b = np.zeros((len(IDS),MAX_LEN))\n",
        "counterclaim_i = np.zeros((len(IDS),MAX_LEN))\n",
        "\n",
        "rebuttal_b = np.zeros((len(IDS),MAX_LEN))\n",
        "rebuttal_i = np.zeros((len(IDS),MAX_LEN))\n",
        "\n",
        "# HELPER VARIABLES\n",
        "train_lens = []\n",
        "targets_b = [lead_b, position_b, evidence_b, claim_b, conclusion_b, counterclaim_b, rebuttal_b]\n",
        "targets_i = [lead_i, position_i, evidence_i, claim_i, conclusion_i, counterclaim_i, rebuttal_i]\n",
        "target_map = {'Lead':0, 'Position':1, 'Evidence':2, 'Claim':3, 'Concluding Statement':4,\n",
        "             'Counterclaim':5, 'Rebuttal':6}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xPzUDzxTrxu",
        "outputId": "b670a6d9-e515-4daf-c770-fb1e8e25c8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file ./TF-LongFormer-v12/added_tokens.json. We won't load it.\n",
            "loading file ./TF-LongFormer-v12/vocab.json\n",
            "loading file ./TF-LongFormer-v12/merges.txt\n",
            "loading file ./TF-LongFormer-v12/tokenizer.json\n",
            "loading file None\n",
            "loading file ./TF-LongFormer-v12/special_tokens_map.json\n",
            "loading file ./TF-LongFormer-v12/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WE ASSUME DATAFRAME IS ASCENDING WHICH IT IS\n",
        "assert( np.sum(train.groupby('id')['discourse_start'].diff()<=0)==0 )\n",
        "\n",
        "# FOR LOOP THROUGH EACH TRAIN TEXT\n",
        "for id_num in range(len(IDS)):\n",
        "    if LOAD_TOKENS_FROM: break\n",
        "    if id_num%100==0: print(id_num,', ',end='')\n",
        "        \n",
        "    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n",
        "    n = IDS[id_num]\n",
        "    name = f'./ori_data/train/{n}.txt'\n",
        "    txt = open(name, 'r').read()\n",
        "    train_lens.append( len(txt.split()))\n",
        "    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n",
        "                                   truncation=True, return_offsets_mapping=True)\n",
        "    train_tokens[id_num,] = tokens['input_ids']\n",
        "    train_attention[id_num,] = tokens['attention_mask']\n",
        "    \n",
        "    # FIND TARGETS IN TEXT AND SAVE IN TARGET ARRAYS\n",
        "    offsets = tokens['offset_mapping']\n",
        "    offset_index = 0\n",
        "    df = train.loc[train.id==n]\n",
        "    for index,row in df.iterrows():\n",
        "        a = row.discourse_start\n",
        "        b = row.discourse_end\n",
        "        if offset_index>len(offsets)-1:\n",
        "            break\n",
        "        c = offsets[offset_index][0]\n",
        "        d = offsets[offset_index][1]\n",
        "        beginning = True\n",
        "        while b>c:\n",
        "            if (c>=a)&(b>=d):\n",
        "                k = target_map[row.discourse_type]\n",
        "                if beginning:\n",
        "                    targets_b[k][id_num][offset_index] = 1\n",
        "                    beginning = False\n",
        "                else:\n",
        "                    targets_i[k][id_num][offset_index] = 1\n",
        "            offset_index += 1\n",
        "            if offset_index>len(offsets)-1:\n",
        "                break\n",
        "            c = offsets[offset_index][0]\n",
        "            d = offsets[offset_index][1]"
      ],
      "metadata": {
        "id": "mT42hTlLUiBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_TOKENS_FROM is None:\n",
        "    plt.hist(train_lens,bins=100)\n",
        "    plt.title('Histogram of Train Word Counts',size=16)\n",
        "    plt.xlabel('Train Word Count',size=14)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5DkilRSKUpM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_TOKENS_FROM is None:\n",
        "    targets = np.zeros((len(IDS),MAX_LEN,15), dtype='int32')\n",
        "    for k in range(7):\n",
        "        targets[:,:,2*k] = targets_b[k]\n",
        "        targets[:,:,2*k+1] = targets_i[k]\n",
        "    targets[:,:,14] = 1-np.max(targets,axis=-1)"
      ],
      "metadata": {
        "id": "NkXfJ8QyUwwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_TOKENS_FROM is None:\n",
        "    np.save(f'targets_{MAX_LEN}', targets)\n",
        "    np.save(f'tokens_{MAX_LEN}', train_tokens)\n",
        "    np.save(f'attention_{MAX_LEN}', train_attention)\n",
        "    print('Saved NER tokens')\n",
        "else:\n",
        "    targets = np.load(f'{LOAD_TOKENS_FROM}/targets_{MAX_LEN}.npy')\n",
        "    train_tokens = np.load(f'{LOAD_TOKENS_FROM}/tokens_{MAX_LEN}.npy')\n",
        "    train_attention = np.load(f'{LOAD_TOKENS_FROM}/attention_{MAX_LEN}.npy')\n",
        "    print('Loaded NER tokens')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7QJb4P0U1Ad",
        "outputId": "eacb92a8-fa0a-4235-d9b8-151ece046faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded NER tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Build Model\n",
        "We will use LongFormer backbone and add our own NER head using one hidden layer of size 256 and one final layer with softmax. We use 15 classes because we have a B class and I class for each of 7 labels. And we have an additional class (called O class) for tokens that do not belong to one of the 14 classes."
      ],
      "metadata": {
        "id": "vezmb4pmRQbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    \n",
        "    tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'tokens', dtype=tf.int32)\n",
        "    attention = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention', dtype=tf.int32)\n",
        "    \n",
        "    config = AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH+'/config.json') \n",
        "    backbone = TFAutoModel.from_pretrained(DOWNLOADED_MODEL_PATH+'/tf_model.h5', config=config)\n",
        "    \n",
        "    x = backbone(tokens, attention_mask=attention)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x[0])\n",
        "    x = tf.keras.layers.Dense(15, activation='softmax', dtype='float32')(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=[tokens,attention], outputs=x)\n",
        "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4),\n",
        "                  loss = [tf.keras.losses.CategoricalCrossentropy()],\n",
        "                  metrics = [tf.keras.metrics.CategoricalAccuracy()])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "nCfvw5JaU870"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = build_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkTX7wXOVAr7",
        "outputId": "12ec942c-ac12-457e-eb14-286e1bab3061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./TF-LongFormer-v12/config.json\n",
            "Model config LongformerConfig {\n",
            "  \"_name_or_path\": \"./TF-LongFormer-v12/config.json\",\n",
            "  \"architectures\": [\n",
            "    \"LongformerModel\"\n",
            "  ],\n",
            "  \"attention_mode\": \"longformer\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"attention_window\": [\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"ignore_attention_mask\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 4098,\n",
            "  \"model_type\": \"longformer\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"sep_token_id\": 2,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./TF-LongFormer-v12/tf_model.h5\n",
            "Input ids are automatically padded from 5 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 5 to 512 to be a multiple of `config.attention_window`: 512\n",
            "All model checkpoint layers were used when initializing TFLongformerModel.\n",
            "\n",
            "All the layers of TFLongformerModel were initialized from the model checkpoint at ./TF-LongFormer-v12/tf_model.h5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Train or Load Model\n"
      ],
      "metadata": {
        "id": "f4PB17mLRaU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LEARNING RATE SCHEDULE AND MODEL CHECKPOINT\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 4 \n",
        "LRS = [0.25e-4, 0.25e-4, 0.25e-4, 0.25e-4, 0.25e-5] \n",
        "def lrfn(epoch):\n",
        "    return LRS[epoch]\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)"
      ],
      "metadata": {
        "id": "hCiiC8ebVNGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN VALID SPLIT 90% 10%\n",
        "np.random.seed(42)\n",
        "train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\n",
        "valid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\n",
        "np.random.seed(None)\n",
        "print('Train size',len(train_idx),', Valid size',len(valid_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfrV85nAVRWF",
        "outputId": "e74d7f4c-e630-4f66-e511-ee1fd3edaad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size 14034 , Valid size 1560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD MODEL\n",
        "if LOAD_MODEL_FROM:\n",
        "    model.load_weights(f'{LOAD_MODEL_FROM}/long_v{VER}.h5')\n",
        "    \n",
        "# OR TRAIN MODEL\n",
        "else:\n",
        "    model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n",
        "          y = targets[train_idx,],\n",
        "          validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n",
        "                             targets[valid_idx,]),\n",
        "          callbacks = [lr_callback],\n",
        "          epochs = EPOCHS,\n",
        "          batch_size = BATCH_SIZE,\n",
        "          verbose = 2)\n",
        "\n",
        "    # SAVE MODEL WEIGHTS\n",
        "    model.save_weights(f'long_v{VER}.h5')"
      ],
      "metadata": {
        "id": "4TQRP7JlVTvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Validate Model\n",
        "We will now make predictions on the validation texts. Our model makes label predictions for each token, we need to convert this into a list of word indices for each label. Note that the tokens and words are not the same. A single word may be broken into multiple tokens. Therefore we need to first create a map to change token indices to word indices."
      ],
      "metadata": {
        "id": "gMpF6Ls_Rgrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = model.predict([train_tokens[valid_idx,], train_attention[valid_idx,]], \n",
        "                  batch_size=16, verbose=2)\n",
        "print('OOF predictions shape:',p.shape)\n",
        "oof_preds = np.argmax(p,axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zixAg0IZVZvA",
        "outputId": "2f0ceec6-eeec-4217-c5ef-82741173884c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 - 189s - 189s/epoch - 2s/step\n",
            "OOF predictions shape: (1560, 1024, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n",
        "             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}"
      ],
      "metadata": {
        "id": "EfurIfnNVdso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preds(dataset='train', verbose=True, text_ids=IDS[valid_idx], preds=oof_preds):\n",
        "    all_predictions = []\n",
        "\n",
        "    for id_num in range(len(preds)):\n",
        "    \n",
        "        # GET ID\n",
        "        if (id_num%100==0)&(verbose): \n",
        "            print(id_num,', ',end='')\n",
        "        n = text_ids[id_num]\n",
        "    \n",
        "        # GET TOKEN POSITIONS IN CHARS\n",
        "        name = f'./ori_data/{dataset}/{n}.txt'\n",
        "        txt = open(name, 'r').read()\n",
        "        tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n",
        "                                   truncation=True, return_offsets_mapping=True)\n",
        "        off = tokens['offset_mapping']\n",
        "    \n",
        "        # GET WORD POSITIONS IN CHARS\n",
        "        w = []\n",
        "        blank = True\n",
        "        for i in range(len(txt)):\n",
        "            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n",
        "                w.append(i)\n",
        "                blank=False\n",
        "            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n",
        "                blank=True\n",
        "        w.append(1e6)\n",
        "            \n",
        "        # MAPPING FROM TOKENS TO WORDS\n",
        "        word_map = -1 * np.ones(MAX_LEN,dtype='int32')\n",
        "        w_i = 0\n",
        "        for i in range(len(off)):\n",
        "            if off[i][1]==0: continue\n",
        "            while off[i][0]>=w[w_i+1]: w_i += 1\n",
        "            word_map[i] = int(w_i)\n",
        "        \n",
        "        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n",
        "        ### KEY: ###\n",
        "        # 0: LEAD_B, 1: LEAD_I\n",
        "        # 2: POSITION_B, 3: POSITION_I\n",
        "        # 4: EVIDENCE_B, 5: EVIDENCE_I\n",
        "        # 6: CLAIM_B, 7: CLAIM_I\n",
        "        # 8: CONCLUSION_B, 9: CONCLUSION_I\n",
        "        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n",
        "        # 12: REBUTTAL_B, 13: REBUTTAL_I\n",
        "        # 14: NOTHING i.e. O\n",
        "        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n",
        "        pred = preds[id_num,]/2.0\n",
        "    \n",
        "        i = 0\n",
        "        while i<MAX_LEN:\n",
        "            prediction = []\n",
        "            start = pred[i]\n",
        "            if start in [0,1,2,3,4,5,6,7]:\n",
        "                prediction.append(word_map[i])\n",
        "                i += 1\n",
        "                if i>=MAX_LEN: break\n",
        "                while pred[i]==start+0.5:\n",
        "                    if not word_map[i] in prediction:\n",
        "                        prediction.append(word_map[i])\n",
        "                    i += 1\n",
        "                    if i>=MAX_LEN: break\n",
        "            else:\n",
        "                i += 1\n",
        "            prediction = [x for x in prediction if x!=-1]\n",
        "            if len(prediction)>4:\n",
        "                all_predictions.append( (n, target_map_rev[int(start)], \n",
        "                                ' '.join([str(x) for x in prediction]) ) )\n",
        "                \n",
        "    # MAKE DATAFRAME\n",
        "    df = pd.DataFrame(all_predictions)\n",
        "    df.columns = ['id','class','predictionstring']\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "IjCfJRbtWPyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof = get_preds( dataset='train', verbose=True, text_ids=IDS[valid_idx] )\n",
        "oof.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "dvP2CNd_WUjv",
        "outputId": "5f850165-d7f8-47d8-ea99-3d303cbfce19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e4032919-9d6a-4e12-9459-2069b9f08cdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>class</th>\n",
              "      <th>predictionstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50B3435E475B</td>\n",
              "      <td>Lead</td>\n",
              "      <td>3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50B3435E475B</td>\n",
              "      <td>Position</td>\n",
              "      <td>63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50B3435E475B</td>\n",
              "      <td>Claim</td>\n",
              "      <td>76 77 78 79 80 81 82 83 84 85 86 87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50B3435E475B</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>88 89 90 91 92 93 94 95 96 97 98 99 100 101 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50B3435E475B</td>\n",
              "      <td>Claim</td>\n",
              "      <td>162 163 164 165 166 167 168 169 170 171 172 17...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4032919-9d6a-4e12-9459-2069b9f08cdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4032919-9d6a-4e12-9459-2069b9f08cdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4032919-9d6a-4e12-9459-2069b9f08cdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             id     class                                   predictionstring\n",
              "0  50B3435E475B      Lead  3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...\n",
              "1  50B3435E475B  Position             63 64 65 66 67 68 69 70 71 72 73 74 75\n",
              "2  50B3435E475B     Claim                76 77 78 79 80 81 82 83 84 85 86 87\n",
              "3  50B3435E475B  Evidence  88 89 90 91 92 93 94 95 96 97 98 99 100 101 10...\n",
              "4  50B3435E475B     Claim  162 163 164 165 166 167 168 169 170 171 172 17..."
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The following classes are present in oof preds:')\n",
        "oof['class'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbMKG3epdcVD",
        "outputId": "1684b53f-993e-4799-9e63-2e40c6756bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following classes are present in oof preds:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Lead', 'Position', 'Claim', 'Evidence', 'Concluding Statement',\n",
              "       'Counterclaim', 'Rebuttal'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Compute Valiadation Metric"
      ],
      "metadata": {
        "id": "z9Zw8xw-Ruck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE FROM : Rob Mulla @robikscube\n",
        "# https://www.kaggle.com/robikscube/student-writing-competition-twitch\n",
        "def calc_overlap(row):\n",
        "    \"\"\"\n",
        "    Calculates the overlap between prediction and\n",
        "    ground truth and overlap percentages used for determining\n",
        "    true positives.\n",
        "    \"\"\"\n",
        "    set_pred = set(row.predictionstring_pred.split(' '))\n",
        "    set_gt = set(row.predictionstring_gt.split(' '))\n",
        "    # Length of each and intersection\n",
        "    len_gt = len(set_gt)\n",
        "    len_pred = len(set_pred)\n",
        "    inter = len(set_gt.intersection(set_pred))\n",
        "    overlap_1 = inter / len_gt\n",
        "    overlap_2 = inter/ len_pred\n",
        "    return [overlap_1, overlap_2]\n",
        "\n",
        "\n",
        "def score_feedback_comp(pred_df, gt_df):\n",
        "    \"\"\"\n",
        "    A function that scores for the kaggle\n",
        "        Student Writing Competition\n",
        "        \n",
        "    Uses the steps in the evaluation page here:\n",
        "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
        "    \"\"\"\n",
        "    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n",
        "        .reset_index(drop=True).copy()\n",
        "    pred_df = pred_df[['id','class','predictionstring']] \\\n",
        "        .reset_index(drop=True).copy()\n",
        "    pred_df['pred_id'] = pred_df.index\n",
        "    gt_df['gt_id'] = gt_df.index\n",
        "    # Step 1. all ground truths and predictions for a given class are compared.\n",
        "    joined = pred_df.merge(gt_df,\n",
        "                           left_on=['id','class'],\n",
        "                           right_on=['id','discourse_type'],\n",
        "                           how='outer',\n",
        "                           suffixes=('_pred','_gt')\n",
        "                          )\n",
        "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
        "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
        "\n",
        "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
        "\n",
        "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
        "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
        "    # the prediction is a match and considered a true positive.\n",
        "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
        "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
        "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
        "\n",
        "\n",
        "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
        "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
        "    tp_pred_ids = joined.query('potential_TP') \\\n",
        "        .sort_values('max_overlap', ascending=False) \\\n",
        "        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
        "\n",
        "    # 3. Any unmatched ground truths are false negatives\n",
        "    # and any unmatched predictions are false positives.\n",
        "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
        "\n",
        "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
        "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
        "\n",
        "    # Get numbers of each type\n",
        "    TP = len(tp_pred_ids)\n",
        "    FP = len(fp_pred_ids)\n",
        "    FN = len(unmatched_gt_ids)\n",
        "    #calc microf1\n",
        "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
        "    return my_f1_score"
      ],
      "metadata": {
        "id": "JNWoAmjMeIP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VALID DATAFRAME\n",
        "valid = train.loc[train['id'].isin(IDS[valid_idx])]"
      ],
      "metadata": {
        "id": "FITmvSryePIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "CLASSES = oof['class'].unique()\n",
        "for c in CLASSES:\n",
        "    pred_df = oof.loc[oof['class']==c].copy()\n",
        "    gt_df = valid.loc[valid['discourse_type']==c].copy()\n",
        "    f1 = score_feedback_comp(pred_df, gt_df)\n",
        "    print(c,f1)\n",
        "    f1s.append(f1)\n",
        "print()\n",
        "print('Overall',np.mean(f1s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DSTVDXHeRRR",
        "outputId": "2f6639e3-ca2a-4ed6-bc8b-46dbb04c80d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lead 0.8063284233496999\n",
            "Position 0.6841560234725578\n",
            "Claim 0.6057328285559762\n",
            "Evidence 0.6816788493279887\n",
            "Concluding Statement 0.7827050997782705\n",
            "Counterclaim 0.4854732895970009\n",
            "Rebuttal 0.39030955585464333\n",
            "\n",
            "Overall 0.6337691528480197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Infer Test Data"
      ],
      "metadata": {
        "id": "yhs2onNQR48x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GET TEST TEXT IDS\n",
        "files = os.listdir('./ori_data/test')\n",
        "TEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\n",
        "print('There are',len(TEST_IDS),'test texts.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgd1y0YgeWSC",
        "outputId": "56733e3a-d399-4749-b2ca-63bdcb9d92e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 5 test texts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT TEST TEXT TO TOKENS\n",
        "test_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n",
        "test_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n",
        "\n",
        "for id_num in range(len(TEST_IDS)):\n",
        "        \n",
        "    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n",
        "    n = TEST_IDS[id_num]\n",
        "    name = f'./ori_data/test/{n}.txt'\n",
        "    txt = open(name, 'r').read()\n",
        "    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n",
        "                                   truncation=True, return_offsets_mapping=True)\n",
        "    test_tokens[id_num,] = tokens['input_ids']\n",
        "    test_attention[id_num,] = tokens['attention_mask']"
      ],
      "metadata": {
        "id": "rzRQG3-4ec72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INFER TEST TEXTS\n",
        "p = model.predict([test_tokens, test_attention], \n",
        "                  batch_size=16, verbose=2)\n",
        "print('Test predictions shape:',p.shape)\n",
        "test_preds = np.argmax(p,axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQAiTnWNei8s",
        "outputId": "b3d0f025-1b73-4268-e130-65b53bc2fc27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 1s - 646ms/epoch - 646ms/step\n",
            "Test predictions shape: (5, 1024, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GET TEST PREDICIONS\n",
        "sub = get_preds( dataset='test', verbose=False, text_ids=TEST_IDS, preds=test_preds )\n",
        "sub.head()"
      ],
      "metadata": {
        "id": "dVYf0tHiemK0",
        "outputId": "a1f40f59-ccef-40d9-8fc3-74d9d756cadf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e5fb3ff-3a6c-4224-bce2-5f37e43639c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>class</th>\n",
              "      <th>predictionstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D46BCB48440A</td>\n",
              "      <td>Lead</td>\n",
              "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D46BCB48440A</td>\n",
              "      <td>Position</td>\n",
              "      <td>20 21 22 23 24 25 26 27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D46BCB48440A</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D46BCB48440A</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>150 151 152 153 154 155 156 157 158 159 160 16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D46BCB48440A</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>223 224 225 226 227 228 229 230 231 232 233 23...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e5fb3ff-3a6c-4224-bce2-5f37e43639c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e5fb3ff-3a6c-4224-bce2-5f37e43639c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e5fb3ff-3a6c-4224-bce2-5f37e43639c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             id     class                                   predictionstring\n",
              "0  D46BCB48440A      Lead  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n",
              "1  D46BCB48440A  Position                            20 21 22 23 24 25 26 27\n",
              "2  D46BCB48440A  Evidence  56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 7...\n",
              "3  D46BCB48440A  Evidence  150 151 152 153 154 155 156 157 158 159 160 16...\n",
              "4  D46BCB48440A  Evidence  223 224 225 226 227 228 229 230 231 232 233 23..."
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE SUBMISSION CSV\n",
        "sub.to_csv('submission.csv',index=False)"
      ],
      "metadata": {
        "id": "4sSOIcnCenID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.enable()\n",
        "\n",
        "import tez\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from joblib import Parallel, delayed\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer"
      ],
      "metadata": {
        "id": "DNups_Vq2DcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_id_map = {\n",
        "    \"B-Lead\": 0,\n",
        "    \"I-Lead\": 1,\n",
        "    \"B-Position\": 2,\n",
        "    \"I-Position\": 3,\n",
        "    \"B-Evidence\": 4,\n",
        "    \"I-Evidence\": 5,\n",
        "    \"B-Claim\": 6,\n",
        "    \"I-Claim\": 7,\n",
        "    \"B-Concluding Statement\": 8,\n",
        "    \"I-Concluding Statement\": 9,\n",
        "    \"B-Counterclaim\": 10,\n",
        "    \"I-Counterclaim\": 11,\n",
        "    \"B-Rebuttal\": 12,\n",
        "    \"I-Rebuttal\": 13,\n",
        "    \"O\": 14,\n",
        "    \"PAD\": -100,\n",
        "}\n",
        "\n",
        "\n",
        "id_target_map = {v: k for k, v in target_id_map.items()}\n",
        "\n",
        "class args1:\n",
        "    input_path = \"./ori_data/\"\n",
        "    model = \"./longformer-large-4096/\"\n",
        "    tez_model= \"./fb-longformer-large-1536/\"\n",
        "    output = \".\"\n",
        "    batch_size = 8\n",
        "    max_len = 4096\n",
        "    \n",
        "class args2:\n",
        "    input_path = \"./ori_data/\"\n",
        "    model = \".//longformer-large-4096/\"\n",
        "    tez_model= \"./fb-longformer-large-1536/\"\n",
        "    output = \".\"\n",
        "    batch_size = 8\n",
        "    max_len = 4096"
      ],
      "metadata": {
        "id": "aSeLHgw9212j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedbackDataset:\n",
        "    def __init__(self, samples, max_len, tokenizer):\n",
        "        self.samples = samples\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.length = len(samples)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.samples[idx][\"input_ids\"]\n",
        "        # print(input_ids)\n",
        "        # print(input_labels)\n",
        "\n",
        "        # add start token id to the input_ids\n",
        "        input_ids = [self.tokenizer.cls_token_id] + input_ids\n",
        "\n",
        "        if len(input_ids) > self.max_len - 1:\n",
        "            input_ids = input_ids[: self.max_len - 1]\n",
        "\n",
        "        # add end token id to the input_ids\n",
        "        input_ids = input_ids + [self.tokenizer.sep_token_id]\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # padding_length = self.max_len - len(input_ids)\n",
        "        # if padding_length > 0:\n",
        "        #     if self.tokenizer.padding_side == \"right\":\n",
        "        #         input_ids = input_ids + [self.tokenizer.pad_token_id] * padding_length\n",
        "        #         attention_mask = attention_mask + [0] * padding_length\n",
        "        #     else:\n",
        "        #         input_ids = [self.tokenizer.pad_token_id] * padding_length + input_ids\n",
        "        #         attention_mask = [0] * padding_length + attention_mask\n",
        "\n",
        "        # return {\n",
        "        #     \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "        #     \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
        "        # }\n",
        "\n",
        "        return {\n",
        "            \"ids\": input_ids,\n",
        "            \"mask\": attention_mask,\n",
        "        }"
      ],
      "metadata": {
        "id": "tGgtQ5EK6ImT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Collate:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        output = dict()\n",
        "        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n",
        "        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n",
        "\n",
        "        # calculate max token length of this batch\n",
        "        batch_max = max([len(ids) for ids in output[\"ids\"]])\n",
        "\n",
        "        # add padding\n",
        "        if self.tokenizer.padding_side == \"right\":\n",
        "            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n",
        "            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n",
        "        else:\n",
        "            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n",
        "            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n",
        "\n",
        "        # convert to tensors\n",
        "        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n",
        "        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "0uDXLKSp6KDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedbackModel(tez.Model):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super().__init__()\n",
        "        self.model_name = model_name\n",
        "        self.num_labels = num_labels\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "\n",
        "        hidden_dropout_prob: float = 0.1\n",
        "        layer_norm_eps: float = 1e-7\n",
        "        config.update(\n",
        "            {\n",
        "                \"output_hidden_states\": True,\n",
        "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
        "                \"layer_norm_eps\": layer_norm_eps,\n",
        "                \"add_pooling_layer\": False,\n",
        "            }\n",
        "        )\n",
        "        self.transformer = AutoModel.from_config(config)\n",
        "        self.output = nn.Linear(config.hidden_size, self.num_labels)\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        transformer_out = self.transformer(ids, mask)\n",
        "        sequence_output = transformer_out.last_hidden_state\n",
        "        logits = self.output(sequence_output)\n",
        "        logits = torch.softmax(logits, dim=-1)\n",
        "        return logits, 0, {}"
      ],
      "metadata": {
        "id": "OI8MOnY96Qsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _prepare_test_data_helper(args, tokenizer, ids):\n",
        "    test_samples = []\n",
        "    for idx in ids:\n",
        "        filename = os.path.join(args.input_path, \"test\", idx + \".txt\")\n",
        "        with open(filename, \"r\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        encoded_text = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=False,\n",
        "            return_offsets_mapping=True,\n",
        "        )\n",
        "        input_ids = encoded_text[\"input_ids\"]\n",
        "        offset_mapping = encoded_text[\"offset_mapping\"]\n",
        "\n",
        "        sample = {\n",
        "            \"id\": idx,\n",
        "            \"input_ids\": input_ids,\n",
        "            \"text\": text,\n",
        "            \"offset_mapping\": offset_mapping,\n",
        "        }\n",
        "\n",
        "        test_samples.append(sample)\n",
        "    return test_samples\n",
        "\n",
        "\n",
        "def prepare_test_data(df, tokenizer, args):\n",
        "    test_samples = []\n",
        "    ids = df[\"id\"].unique()\n",
        "    ids_splits = np.array_split(ids, 4)\n",
        "\n",
        "    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n",
        "        delayed(_prepare_test_data_helper)(args, tokenizer, idx) for idx in ids_splits\n",
        "    )\n",
        "    for result in results:\n",
        "        test_samples.extend(result)\n",
        "\n",
        "    return test_samples"
      ],
      "metadata": {
        "id": "ctJpE54d7Q4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(\"./ori_data/\", \"sample_submission.csv\"))\n",
        "df_ids = df[\"id\"].unique()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(args1.model)\n",
        "test_samples = prepare_test_data(df, tokenizer, args1)\n",
        "collate = Collate(tokenizer=tokenizer)\n",
        "\n",
        "raw_preds = []\n",
        "for fold_ in range(5):\n",
        "    current_idx = 0\n",
        "    test_dataset = FeedbackDataset(test_samples, args1.max_len, tokenizer)\n",
        "    \n",
        "    if fold_ < 5:\n",
        "        model = FeedbackModel(model_name=args1.model, num_labels=len(target_id_map) - 1)\n",
        "        model.load(os.path.join(args1.tez_model, f\"model_{fold_}.bin\"), weights_only=True)\n",
        "        preds_iter = model.predict(test_dataset, batch_size=args1.batch_size, n_jobs=-1, collate_fn=collate)\n",
        "    else:\n",
        "        model = FeedbackModel(model_name=args2.model, num_labels=len(target_id_map) - 1)\n",
        "        model.load(os.path.join(args2.tez_model, f\"model_{fold_-5}.bin\"), weights_only=True)\n",
        "        preds_iter = model.predict(test_dataset, batch_size=args2.batch_size, n_jobs=-1, collate_fn=collate)\n",
        "        \n",
        "    current_idx = 0\n",
        "    \n",
        "    for preds in preds_iter:\n",
        "        preds = preds.astype(np.float16)\n",
        "        preds = preds / 10\n",
        "        if fold_ == 0:\n",
        "            raw_preds.append(preds)\n",
        "        else:\n",
        "            raw_preds[current_idx] += preds\n",
        "            current_idx += 1\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DokvWpBX79yp",
        "outputId": "3a457b8f-dc79-42cf-e415-492a9357704d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.84s/it, stage=test]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.69s/it, stage=test]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.69s/it, stage=test]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.69s/it, stage=test]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.69s/it, stage=test]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_preds = []\n",
        "final_scores = []\n",
        "\n",
        "for rp in raw_preds:\n",
        "    pred_class = np.argmax(rp, axis=2)\n",
        "    pred_scrs = np.max(rp, axis=2)\n",
        "    for pred, pred_scr in zip(pred_class, pred_scrs):\n",
        "        pred = pred.tolist()\n",
        "        pred_scr = pred_scr.tolist()\n",
        "        final_preds.append(pred)\n",
        "        final_scores.append(pred_scr)\n",
        "\n",
        "for j in range(len(test_samples)):\n",
        "    tt = [id_target_map[p] for p in final_preds[j][1:]]\n",
        "    tt_score = final_scores[j][1:]\n",
        "    test_samples[j][\"preds\"] = tt\n",
        "    test_samples[j][\"pred_scores\"] = tt_score"
      ],
      "metadata": {
        "id": "utWmjrbn-79h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(final_preds))\n",
        "print(test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C7zF_dL_Xpv",
        "outputId": "8041db3d-10c2-4dfc-de2b-3e327c695745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "[{'id': '18409261F5C2', 'input_ids': [2940, 207, 9, 1791, 679, 1818, 1533, 5086, 64, 244, 106, 146, 357, 5717, 6, 8, 13, 205, 1219, 4, 9307, 33, 2343, 5, 674, 1791, 444, 154, 444, 357, 11, 49, 1074, 1118, 7, 49, 10428, 142, 51, 32, 6288, 7, 97, 18, 2949, 4, 345, 32, 67, 171, 28787, 14, 33, 5, 7654, 9, 6288, 7, 97, 82, 18, 5086, 4, 286, 1246, 6, 42447, 687, 300, 39, 8312, 9, 25461, 10, 821, 1957, 261, 142, 37, 13165, 7, 5, 14627, 4, 2044, 1246, 38, 33, 16, 5, 856, 868, 9, 46240, 6, 11, 61, 46240, 25245, 7, 21780, 298, 5646, 8, 3374, 5, 8453, 9, 37, 40223, 4, 96, 70, 9, 209, 1652, 6, 5, 6132, 25245, 7, 97, 82, 6, 8, 11916, 31, 5, 82, 198, 106, 145, 55, 26782, 6, 55, 2984, 6, 8, 1311, 5, 6132, 55, 5717, 7, 1701, 4, 9068, 6, 38, 679, 6288, 7, 97, 18, 2949, 64, 244, 951, 146, 10, 357, 2031, 142, 51, 33, 55, 676, 1118, 7, 47, 6, 216, 5, 15501, 8, 7407, 9, 110, 2031, 6, 8, 2029, 47, 1533, 17403, 7, 14775, 81, 4, 50118, 50118, 2709, 1246, 6, 905, 201, 1067, 59, 5, 40938, 9, 410, 43411, 1215, 31723, 6, 1060, 301, 21, 1714, 6000, 30, 6288, 7, 10, 621, 54, 34, 55, 676, 87, 123, 4, 287, 10, 664, 20986, 6, 410, 43411, 1215, 31723, 460, 21990, 9, 1959, 10, 9716, 6, 142, 37, 22610, 39, 985, 54, 4951, 11, 15584, 176, 4, 125, 43411, 1215, 31723, 18, 985, 6, 54, 3033, 149, 5, 26417, 16497, 11010, 20707, 6, 46405, 236, 69, 920, 7, 1407, 69, 2718, 4, 287, 10, 898, 6, 79, 3244, 7, 123, 59, 5, 29822, 14, 16145, 69, 77, 79, 21, 10, 9716, 6, 8, 5116, 1714, 39, 1508, 4, 4557, 7, 43411, 1215, 31723, 18, 985, 2992, 410, 43411, 1215, 31723, 18, 1508, 6, 91, 1059, 10, 1800, 8, 5823, 1827, 3299, 54, 7552, 10807, 9, 1074, 358, 183, 4, 318, 43411, 1215, 31723, 18, 985, 5844, 75, 57, 10, 9716, 54, 34, 3033, 149, 5, 29985, 24297, 9, 7105, 373, 5, 20707, 6, 172, 79, 1979, 75, 33, 57, 441, 7, 464, 410, 43411, 1215, 31723, 18, 1508, 6, 8, 37, 189, 33, 56, 39, 301, 847, 765, 4, 2044, 527, 52, 64, 1067, 59, 16, 5, 527, 9, 410, 43411, 1215, 31723, 6, 54, 460, 770, 7, 28, 10, 38034, 4, 43411, 1215, 31723, 460, 41069, 7396, 59, 145, 15, 1289, 6, 6288, 7, 5, 8817, 3418, 17288, 25, 79, 45536, 5069, 106, 6, 8, 27628, 6, 69, 1150, 16, 89, 7, 14235, 69, 35591, 4, 4557, 7, 43411, 1215, 31723, 18, 1150, 145, 10, 12086, 38034, 6, 37, 56, 5, 7070, 8, 1467, 5, 15154, 14, 115, 12562, 1459, 5, 2180, 4, 287, 10, 898, 6, 43411, 1215, 31723, 1059, 5, 3968, 38034, 9, 14, 2706, 4, 318, 43411, 1215, 31723, 18, 1150, 21, 3999, 10, 38034, 54, 56, 3203, 5, 2718, 43411, 1215, 31723, 21, 1884, 7, 1656, 6, 172, 79, 74, 3999, 33, 57, 441, 7, 1338, 5, 16889, 79, 21, 3970, 235, 122, 4, 9068, 6, 38, 679, 14, 6288, 7, 82, 54, 33, 55, 3734, 1118, 7, 47, 41, 244, 47, 146, 10, 357, 7579, 4, 50118, 50118, 21518, 40938, 52, 64, 1067, 59, 16, 5, 40938, 9, 43411, 1215, 31723, 6, 10, 32002, 8178, 313, 54, 1467, 5, 15501, 8, 7407, 9, 608, 2196, 4, 287, 43411, 1215, 31723, 21, 3051, 5, 2827, 9, 188, 3123, 6, 37, 794, 10, 333, 59, 7, 3529, 2196, 4, 43411, 1215, 31723, 3203, 1567, 5, 333, 6, 8, 37, 16619, 3804, 39, 865, 15, 7, 5, 14712, 621, 18, 6, 8, 2294, 5, 621, 31, 608, 103, 2196, 4, 43411, 1215, 31723, 30212, 13833, 5, 333, 59, 608, 2196, 6, 8, 2446, 7, 39, 32002, 2621, 6, 5, 333, 2294, 159, 154, 103, 13866, 4, 4557, 7, 5, 1351, 9, 43411, 1215, 31723, 54, 25673, 4075, 5, 333, 59, 5, 15501, 8, 7407, 9, 4441, 2196, 6, 5, 333, 21, 5305, 31, 5, 9247, 16882, 9, 2196, 6, 8, 2307, 62, 7, 28, 10, 333, 54, 4951, 136, 1262, 304, 4, 318, 43411, 1215, 31723, 938, 75, 2758, 5, 333, 59, 5, 15501, 8, 7407, 9, 2196, 6, 51, 74, 33, 18804, 24, 8, 4491, 88, 10, 2718, 61, 16, 182, 543, 7, 5312, 31, 4, 125, 27628, 6, 43411, 1215, 31723, 5305, 106, 31, 14, 21508, 154, 499, 4, 2044, 40938, 38, 236, 7, 1067, 59, 16, 5, 527, 9, 43411, 1215, 31723, 6, 54, 770, 1021, 28, 3299, 4, 43411, 1215, 31723, 399, 75, 216, 203, 59, 145, 10, 3299, 6, 4682, 14, 79, 770, 7, 28, 65, 6, 98, 69, 10642, 3244, 19, 69, 59, 69, 2031, 4, 287, 51, 3373, 5, 15501, 8, 7407, 9, 145, 10, 3299, 6, 43411, 1215, 31723, 2307, 55, 26782, 59, 5, 2031, 79, 16, 164, 7, 146, 4, 287, 10, 898, 6, 43411, 1215, 31723, 16, 203, 55, 933, 11, 69, 9734, 59, 145, 10, 3299, 6, 8, 2307, 62, 7, 28, 41, 2770, 3299, 4, 318, 79, 46405, 108, 1067, 19, 69, 10642, 59, 69, 2031, 6, 79, 74, 33, 156, 41, 8284, 196, 568, 14, 533, 74, 33, 19750, 69, 301, 4, 9068, 6, 38, 679, 14, 6288, 7, 97, 18, 2949, 64, 244, 951, 146, 10, 357, 2031, 30, 1311, 106, 5, 15501, 8, 7407, 9, 49, 2031, 4, 50118, 50118, 3762, 40938, 38, 236, 7, 1067, 59, 16, 5, 527, 9, 43411, 1215, 31723, 6, 54, 770, 7, 28, 10, 2470, 142, 69, 1441, 18, 5578, 69, 4, 264, 21, 25781, 11, 69, 9734, 25, 79, 460, 3776, 1492, 8, 3478, 6, 454, 69, 985, 851, 69, 10, 92, 4263, 7, 23158, 81, 4, 264, 174, 69, 7, 4374, 7, 555, 10, 15835, 28021, 6, 1195, 87, 145, 10, 3306, 39825, 4, 50118, 50118, 1620, 10, 898, 6, 43411, 1215, 31723, 3448, 7, 28, 10, 15835, 1679, 6, 8, 79, 1059, 65, 23, 5, 1046, 9, 3620, 4, 4557, 7, 69, 985, 1311, 69, 357, 2949, 6, 264, 1059, 10, 999, 14, 66, 1193, 1264, 97, 18, 11, 5, 232, 9, 488, 4, 2044, 40938, 38, 236, 7, 1067, 59, 16, 5, 527, 9, 43411, 1215, 31723, 1060, 301, 1714, 2446, 7, 10, 34619, 6376, 14, 1714, 39, 301, 4, 43411, 1215, 31723, 1299, 1654, 7, 28, 10, 2734, 6004, 6, 25, 24, 21, 10, 284, 5589, 4, 50118, 50118, 894, 399, 75, 216, 99, 7, 109, 6, 454, 37, 1317, 39, 8853, 1686, 19, 39, 284, 59, 3477, 44246, 4, 91, 2307, 2509, 11, 3477, 44246, 8, 27285, 24, 454, 37, 1687, 24, 10, 39, 499, 756, 4, 287, 10, 898, 6, 37, 2307, 62, 7, 555, 10, 29234, 6, 608, 402, 37, 6138, 4, 318, 24, 938, 75, 13, 39, 8853, 2758, 43411, 1215, 31723, 18, 284, 453, 59, 3477, 44246, 6, 37, 1979, 75, 33, 190, 1687, 24, 6, 8, 189, 33, 3831, 7, 28, 10, 45063, 5580, 621, 54, 965, 75, 441, 7, 464, 39, 7658, 9, 3606, 4, 9068, 6, 38, 679, 1818, 1533, 5086, 64, 244, 951, 146, 10, 357, 2031, 142, 24, 64, 492, 106, 1533, 17403, 7, 1701, 4, 50118, 50118, 1121, 6427, 6, 410, 43411, 1215, 31723, 6, 43411, 1215, 31723, 6, 43411, 1215, 31723, 6, 8, 171, 55, 1714, 49, 1445, 1074, 30, 6288, 7, 97, 82, 4, 318, 51, 399, 75, 2639, 97, 18, 2949, 6, 51, 74, 33, 4491, 88, 10, 2718, 14, 74, 45, 1157, 49, 801, 7, 24255, 4, 125, 6, 27628, 6, 51, 4689, 7, 4161, 7, 97, 82, 4, 287, 10, 898, 6, 51, 2307, 7, 28, 2415, 14, 58, 9132, 198, 5, 232, 4, 9068, 6, 38, 11, 679, 1818, 1533, 5086, 4], 'text': \"80% of Americans believe seeking multiple opinions can help them make better choices, and for good reason. Studies have shown the average Americans faring far better in their lives compared to their counterparts because they are listening to other's advice. There are also many myths that have the moral of listening to other people's opinions. For example, Perseus got his achievement of slaying a gorgon because he listened to the Oracle. Another example I have is the fable of Osiris, in which Osiris listens to Sekhmet and becomes the king of he underworld. In all of these stories, the hero listens to other people, and benefited from the people around them being more knowledgeable, more experienced, and giving the hero more choices to consider. Therefore, I believe listening to other's advice can help someone make a better choice because they have more experience compared to you, know the pros and cons of your choice, and gives you multiple perspectives to deliberate over.\\n\\nFor example, let us talk about the anecdote of little Generic_Name, whose life was changed forever by listening to a person who has more experience than him. As a young lad, little Generic_Name always dreamed of becoming a soldier, because he admired his mother who fought in WW2. But Generic_Name's mother, who lived through the inhospitable battlefield, didnt want her child to follow her path. As a result, she talked to him about the hardships that plagued her when she was a soldier, and successfully changed his mind. Thanks to Generic_Name's mother changing little Generic_Name's mind, He became a successful and joyous doctor who saves countless of lives every day. If Generic_Name's mother hadn't been a soldier who has lived through the darkest depths of hell called the battlefield, then she wouldn't have been able to change little Generic_Name's mind, and he may have had his life cut short. Another story we can talk about is the story of little Generic_Name, who always wanted to be a magician. Generic_Name always fantasizes about being on stage, listening to the crowds wild applause as she entertains them, and thankfully, her father is there to fulfill her fantasies. Thanks to Generic_Name's father being a renowned magician, he had the connections and knew the tricks that could excite the crowd. As a result, Generic_Name became the greatest magician of that generation. If Generic_Name's father wasnt a magician who had walked the path Generic_Name was planning to walk, then she wouldnt have been able to reach the heights she was reaching right now. Therefore, I believe that listening to people who have more experiences compared to you an help you make a better judgment.\\n\\nAnother anecdote we can talk about is the anecdote of Generic_Name, a menacing ancient man who knew the pros and cons of doing drugs. As Generic_Name was walking the streets of New Jersey, he saw a group about to eat drugs. Generic_Name walked towards the group, and he latched his hand on to the nearest person's, and stopped the person from doing some drugs. Generic_Name reprimanded the group about doing drugs, and thanks to his menacing presence, the group stopped downing some pills. Thanks to the effort of Generic_Name who lectured the group about the pros and cons of eating drugs, the group was saved from the evil influences of drugs, and grew up to be a group who fought against drug use. If Generic_Name wasn't telling the group about the pros and cons of drugs, they would have eaten it and fallen into a path which is very hard to recover from. But thankfully, Generic_Name saved them from that despairing future. Another anecdote I want to talk about is the story of Generic_Name, who wanted o be doctor. Generic_Name didn't know much about being a doctor, except that she wanted to be one, so her grandfather talked with her about her choice. As they discussed the pros and cons of being a doctor, Generic_Name grew more knowledgeable about the choice she is going to make. As a result, Generic_Name is much more firm in her beliefs about being a doctor, and grew up to be an amazing doctor. If she didnt' talk with her grandfather about her choice, she would have made an uniformed decision that likely would have ruined her life. Therefore, I believe that listening to other's advice can help someone make a better choice by giving them the pros and cons of their choice.\\n\\nOne anecdote I want to talk about is the story of Generic_Name, who wanted to be a lawyer because her friend's advised her. She was steadfast in her beliefs as she always enjoyed rules and regulations, until her mother gave her a new perspective to mull over. She told her to aim to become a supreme dragon, rather than being a struggling python.\\n\\nAs a result, Generic_Name aimed to be a supreme judge, and she became one at the age of 65. Thanks to her mother giving her better advice, She became a star that outshone other's in the world of law. Another anecdote I want to talk about is the story of Generic_Name whose life changed thanks to a fateful encounter that changed his life. Generic_Name felt forced to be a fashion designer, as it was a family tradition.\\n\\nHe didn't know what to do, until he heard his grandmother talking with his family about animal cloning. He grew interested in animal cloning and researched it until he considered it a his future career. As a result, he grew up to become a biologist, doing something he loves. If it wasn't for his grandmother telling Generic_Name's family members about animal cloning, he wouldn't have even considered it, and may have grown to be a nihilistic person who isn't able to change his fate of suffering. Therefore, I believe seeking multiple opinions can help someone make a better choice because it can give them multiple perspectives to consider.\\n\\nIn conclusion, little Generic_Name, Generic_Name, Generic_Name, and many more changed their entire lives by listening to other people. If they didn't seek other's advice, they would have fallen into a path that would not allow their potential to bloom. But, thankfully, they chose to listen to other people. As a result, they grew to be figures that were respected around the world. Therefore, I in believe seeking multiple opinions.\", 'offset_mapping': [(0, 2), (2, 3), (4, 6), (7, 16), (17, 24), (25, 32), (33, 41), (42, 50), (51, 54), (55, 59), (60, 64), (65, 69), (70, 76), (77, 84), (84, 85), (86, 89), (90, 93), (94, 98), (99, 105), (105, 106), (107, 114), (115, 119), (120, 125), (126, 129), (130, 137), (138, 147), (148, 151), (151, 154), (155, 158), (159, 165), (166, 168), (169, 174), (175, 180), (181, 189), (190, 192), (193, 198), (199, 211), (212, 219), (220, 224), (225, 228), (229, 238), (239, 241), (242, 247), (247, 249), (250, 256), (256, 257), (258, 263), (264, 267), (268, 272), (273, 277), (278, 283), (284, 288), (289, 293), (294, 297), (298, 303), (304, 306), (307, 316), (317, 319), (320, 325), (326, 332), (332, 334), (335, 343), (343, 344), (345, 348), (349, 356), (356, 357), (358, 363), (363, 365), (366, 369), (370, 373), (374, 385), (386, 388), (389, 396), (397, 398), (399, 400), (400, 403), (403, 405), (406, 413), (414, 416), (417, 425), (426, 428), (429, 432), (433, 439), (439, 440), (441, 448), (449, 456), (457, 458), (459, 463), (464, 466), (467, 470), (471, 472), (472, 476), (477, 479), (480, 486), (486, 487), (488, 490), (491, 496), (497, 503), (504, 511), (512, 514), (515, 518), (518, 519), (519, 522), (523, 526), (527, 534), (535, 538), (539, 543), (544, 546), (547, 549), (550, 560), (560, 561), (562, 564), (565, 568), (569, 571), (572, 577), (578, 585), (585, 586), (587, 590), (591, 595), (596, 603), (604, 606), (607, 612), (613, 619), (619, 620), (621, 624), (625, 634), (635, 639), (640, 643), (644, 650), (651, 657), (658, 662), (663, 668), (669, 673), (674, 687), (687, 688), (689, 693), (694, 705), (705, 706), (707, 710), (711, 717), (718, 721), (722, 726), (727, 731), (732, 739), (740, 742), (743, 751), (751, 752), (753, 762), (762, 763), (764, 765), (766, 773), (774, 783), (784, 786), (787, 792), (792, 794), (795, 801), (802, 805), (806, 810), (811, 818), (819, 823), (824, 825), (826, 832), (833, 839), (840, 847), (848, 852), (853, 857), (858, 862), (863, 873), (874, 882), (883, 885), (886, 889), (889, 890), (891, 895), (896, 899), (900, 904), (905, 908), (909, 913), (914, 916), (917, 921), (922, 928), (928, 929), (930, 933), (934, 939), (940, 943), (944, 952), (953, 965), (966, 968), (969, 979), (980, 984), (984, 985), (985, 986), (986, 987), (987, 990), (991, 998), (998, 999), (1000, 1003), (1004, 1006), (1007, 1011), (1012, 1017), (1018, 1021), (1022, 1030), (1031, 1033), (1034, 1040), (1041, 1048), (1048, 1049), (1049, 1053), (1053, 1054), (1055, 1060), (1061, 1065), (1066, 1069), (1070, 1077), (1078, 1085), (1086, 1088), (1089, 1098), (1099, 1101), (1102, 1103), (1104, 1110), (1111, 1114), (1115, 1118), (1119, 1123), (1124, 1134), (1135, 1139), (1140, 1143), (1143, 1144), (1145, 1147), (1148, 1149), (1150, 1155), (1156, 1159), (1159, 1160), (1161, 1167), (1168, 1175), (1175, 1176), (1176, 1180), (1181, 1187), (1188, 1195), (1196, 1198), (1199, 1207), (1208, 1209), (1210, 1217), (1217, 1218), (1219, 1226), (1227, 1229), (1230, 1237), (1238, 1241), (1242, 1248), (1249, 1252), (1253, 1259), (1260, 1262), (1263, 1265), (1265, 1266), (1266, 1267), (1268, 1271), (1272, 1279), (1279, 1280), (1280, 1284), (1284, 1286), (1287, 1293), (1293, 1294), (1295, 1298), (1299, 1304), (1305, 1312), (1313, 1316), (1317, 1320), (1320, 1323), (1323, 1329), (1330, 1341), (1341, 1342), (1343, 1348), (1349, 1353), (1354, 1357), (1358, 1363), (1364, 1366), (1367, 1373), (1374, 1377), (1378, 1382), (1382, 1383), (1384, 1386), (1387, 1388), (1389, 1395), (1395, 1396), (1397, 1400), (1401, 1407), (1408, 1410), (1411, 1414), (1415, 1420), (1421, 1424), (1425, 1434), (1435, 1439), (1440, 1447), (1448, 1451), (1452, 1456), (1457, 1460), (1461, 1464), (1465, 1466), (1467, 1474), (1474, 1475), (1476, 1479), (1480, 1492), (1493, 1500), (1501, 1504), (1505, 1509), (1509, 1510), (1511, 1517), (1518, 1520), (1521, 1528), (1528, 1529), (1529, 1533), (1533, 1535), (1536, 1542), (1543, 1551), (1552, 1558), (1559, 1566), (1566, 1567), (1567, 1571), (1571, 1573), (1574, 1578), (1578, 1579), (1580, 1582), (1583, 1589), (1590, 1591), (1592, 1602), (1603, 1606), (1607, 1610), (1610, 1613), (1614, 1620), (1621, 1624), (1625, 1630), (1631, 1640), (1641, 1643), (1644, 1649), (1650, 1655), (1656, 1659), (1659, 1660), (1661, 1663), (1664, 1671), (1671, 1672), (1672, 1676), (1676, 1678), (1679, 1685), (1686, 1690), (1690, 1692), (1693, 1697), (1698, 1699), (1700, 1707), (1708, 1711), (1712, 1715), (1716, 1721), (1722, 1729), (1730, 1733), (1734, 1741), (1742, 1748), (1749, 1751), (1752, 1756), (1757, 1763), (1764, 1767), (1768, 1779), (1779, 1780), (1781, 1785), (1786, 1789), (1790, 1796), (1796, 1798), (1799, 1803), (1804, 1808), (1809, 1813), (1814, 1816), (1817, 1823), (1824, 1830), (1831, 1838), (1838, 1839), (1839, 1843), (1843, 1845), (1846, 1850), (1850, 1851), (1852, 1855), (1856, 1858), (1859, 1862), (1863, 1867), (1868, 1871), (1872, 1875), (1876, 1880), (1881, 1884), (1885, 1890), (1890, 1891), (1892, 1899), (1900, 1905), (1906, 1908), (1909, 1912), (1913, 1917), (1918, 1923), (1924, 1926), (1927, 1930), (1931, 1936), (1937, 1939), (1940, 1946), (1947, 1954), (1954, 1955), (1955, 1959), (1959, 1960), (1961, 1964), (1965, 1971), (1972, 1978), (1979, 1981), (1982, 1984), (1985, 1986), (1987, 1995), (1995, 1996), (1997, 2004), (2004, 2005), (2005, 2009), (2010, 2016), (2017, 2023), (2023, 2027), (2028, 2033), (2034, 2039), (2040, 2042), (2043, 2048), (2048, 2049), (2050, 2059), (2060, 2062), (2063, 2066), (2067, 2073), (2074, 2078), (2079, 2087), (2088, 2090), (2091, 2094), (2095, 2101), (2101, 2105), (2106, 2110), (2110, 2111), (2112, 2115), (2116, 2126), (2126, 2127), (2128, 2131), (2132, 2138), (2139, 2141), (2142, 2147), (2148, 2150), (2151, 2158), (2159, 2162), (2163, 2172), (2172, 2173), (2174, 2180), (2181, 2183), (2184, 2191), (2191, 2192), (2192, 2196), (2196, 2198), (2199, 2205), (2206, 2211), (2212, 2213), (2214, 2222), (2223, 2231), (2231, 2232), (2233, 2235), (2236, 2239), (2240, 2243), (2244, 2255), (2256, 2259), (2260, 2264), (2265, 2268), (2269, 2275), (2276, 2280), (2281, 2286), (2287, 2290), (2290, 2293), (2294, 2297), (2298, 2303), (2303, 2304), (2305, 2307), (2308, 2309), (2310, 2316), (2316, 2317), (2318, 2325), (2325, 2326), (2326, 2330), (2331, 2337), (2338, 2341), (2342, 2350), (2351, 2359), (2360, 2362), (2363, 2367), (2368, 2378), (2378, 2379), (2380, 2382), (2383, 2390), (2390, 2391), (2391, 2395), (2395, 2397), (2398, 2404), (2405, 2408), (2408, 2410), (2411, 2412), (2413, 2421), (2422, 2425), (2426, 2429), (2430, 2436), (2437, 2440), (2441, 2445), (2446, 2453), (2453, 2454), (2454, 2458), (2459, 2462), (2463, 2471), (2472, 2474), (2475, 2479), (2479, 2480), (2481, 2485), (2486, 2489), (2490, 2495), (2495, 2497), (2498, 2502), (2503, 2507), (2508, 2512), (2513, 2515), (2516, 2521), (2522, 2525), (2526, 2533), (2534, 2537), (2538, 2541), (2542, 2550), (2551, 2556), (2557, 2560), (2560, 2561), (2562, 2571), (2571, 2572), (2573, 2574), (2575, 2582), (2583, 2587), (2588, 2597), (2598, 2600), (2601, 2607), (2608, 2611), (2612, 2616), (2617, 2621), (2622, 2633), (2634, 2642), (2643, 2645), (2646, 2649), (2650, 2652), (2653, 2657), (2658, 2661), (2662, 2666), (2667, 2668), (2669, 2675), (2676, 2684), (2684, 2685), (2685, 2686), (2686, 2687), (2687, 2694), (2695, 2703), (2704, 2706), (2707, 2710), (2711, 2715), (2716, 2721), (2722, 2724), (2725, 2728), (2729, 2737), (2738, 2740), (2741, 2748), (2748, 2749), (2749, 2753), (2753, 2754), (2755, 2756), (2757, 2765), (2766, 2773), (2774, 2777), (2778, 2781), (2782, 2786), (2787, 2790), (2791, 2795), (2796, 2799), (2800, 2804), (2805, 2807), (2808, 2813), (2814, 2819), (2819, 2820), (2821, 2823), (2824, 2831), (2831, 2832), (2832, 2836), (2837, 2840), (2841, 2848), (2849, 2852), (2853, 2860), (2861, 2863), (2864, 2867), (2868, 2874), (2874, 2875), (2876, 2878), (2879, 2882), (2883, 2884), (2885, 2890), (2891, 2896), (2897, 2899), (2900, 2903), (2904, 2909), (2909, 2910), (2911, 2918), (2918, 2919), (2919, 2923), (2924, 2930), (2931, 2938), (2939, 2942), (2943, 2948), (2948, 2949), (2950, 2953), (2954, 2956), (2957, 2960), (2960, 2964), (2965, 2968), (2969, 2973), (2974, 2976), (2977, 2979), (2980, 2983), (2984, 2991), (2992, 2998), (2998, 3000), (3000, 3001), (3002, 3005), (3006, 3013), (3014, 3017), (3018, 3024), (3025, 3029), (3030, 3035), (3036, 3040), (3041, 3046), (3046, 3047), (3048, 3055), (3055, 3056), (3056, 3060), (3061, 3067), (3067, 3072), (3073, 3076), (3077, 3082), (3083, 3088), (3089, 3094), (3095, 3100), (3100, 3101), (3102, 3105), (3106, 3112), (3113, 3115), (3116, 3119), (3120, 3128), (3129, 3137), (3137, 3138), (3139, 3142), (3143, 3148), (3149, 3156), (3157, 3161), (3161, 3164), (3165, 3169), (3170, 3175), (3175, 3176), (3177, 3183), (3184, 3186), (3187, 3190), (3191, 3197), (3198, 3200), (3201, 3208), (3208, 3209), (3209, 3213), (3214, 3217), (3218, 3222), (3222, 3226), (3227, 3230), (3231, 3236), (3237, 3242), (3243, 3246), (3247, 3251), (3252, 3255), (3256, 3260), (3261, 3263), (3264, 3270), (3271, 3276), (3276, 3277), (3278, 3281), (3282, 3287), (3288, 3291), (3292, 3297), (3298, 3302), (3303, 3306), (3307, 3311), (3312, 3322), (3323, 3325), (3326, 3331), (3331, 3332), (3333, 3336), (3337, 3341), (3342, 3344), (3345, 3347), (3348, 3350), (3351, 3352), (3353, 3358), (3359, 3362), (3363, 3369), (3370, 3377), (3378, 3382), (3383, 3386), (3386, 3387), (3388, 3390), (3391, 3398), (3398, 3399), (3399, 3403), (3404, 3408), (3408, 3410), (3411, 3418), (3419, 3422), (3423, 3428), (3429, 3434), (3435, 3438), (3439, 3443), (3444, 3447), (3448, 3452), (3453, 3455), (3456, 3461), (3461, 3462), (3463, 3467), (3468, 3473), (3474, 3478), (3479, 3484), (3485, 3487), (3488, 3491), (3492, 3498), (3499, 3503), (3504, 3505), (3506, 3510), (3511, 3516), (3517, 3519), (3520, 3524), (3525, 3529), (3530, 3532), (3533, 3540), (3541, 3545), (3545, 3546), (3547, 3550), (3551, 3561), (3561, 3562), (3563, 3570), (3570, 3571), (3571, 3575), (3576, 3581), (3582, 3586), (3587, 3591), (3592, 3596), (3597, 3604), (3604, 3607), (3608, 3614), (3614, 3615), (3616, 3623), (3624, 3632), (3633, 3634), (3635, 3639), (3640, 3642), (3643, 3647), (3648, 3653), (3654, 3656), (3657, 3660), (3661, 3666), (3667, 3669), (3670, 3677), (3677, 3678), (3678, 3682), (3682, 3683), (3684, 3687), (3688, 3694), (3695, 3696), (3697, 3699), (3700, 3706), (3706, 3707), (3708, 3715), (3715, 3716), (3716, 3720), (3721, 3725), (3725, 3727), (3728, 3732), (3733, 3737), (3738, 3743), (3744, 3749), (3750, 3751), (3752, 3758), (3758, 3759), (3760, 3766), (3767, 3771), (3772, 3775), (3776, 3782), (3783, 3785), (3786, 3788), (3789, 3792), (3792, 3793), (3794, 3796), (3797, 3800), (3801, 3812), (3813, 3819), (3820, 3824), (3825, 3828), (3829, 3834), (3835, 3838), (3839, 3845), (3845, 3846), (3847, 3849), (3850, 3854), (3855, 3864), (3865, 3868), (3869, 3873), (3874, 3877), (3878, 3882), (3883, 3885), (3886, 3891), (3892, 3893), (3894, 3900), (3900, 3901), (3902, 3909), (3909, 3910), (3910, 3914), (3915, 3919), (3920, 3924), (3925, 3938), (3939, 3944), (3945, 3948), (3949, 3955), (3956, 3959), (3960, 3962), (3963, 3968), (3969, 3971), (3972, 3976), (3976, 3977), (3978, 3980), (3981, 3982), (3983, 3989), (3989, 3990), (3991, 3998), (3998, 3999), (3999, 4003), (4004, 4006), (4007, 4011), (4012, 4016), (4017, 4021), (4022, 4024), (4025, 4028), (4029, 4036), (4037, 4042), (4043, 4048), (4049, 4050), (4051, 4057), (4057, 4058), (4059, 4062), (4063, 4067), (4068, 4070), (4071, 4073), (4074, 4076), (4077, 4079), (4080, 4087), (4088, 4094), (4094, 4095), (4096, 4098), (4099, 4102), (4103, 4108), (4108, 4109), (4110, 4114), (4115, 4119), (4120, 4123), (4124, 4135), (4136, 4141), (4142, 4145), (4146, 4152), (4152, 4153), (4154, 4157), (4158, 4163), (4164, 4168), (4169, 4173), (4174, 4176), (4177, 4184), (4184, 4186), (4187, 4195), (4196, 4200), (4201, 4207), (4208, 4213), (4214, 4218), (4219, 4225), (4226, 4229), (4230, 4234), (4234, 4235), (4236, 4245), (4245, 4246), (4247, 4248), (4249, 4256), (4257, 4261), (4262, 4271), (4272, 4274), (4275, 4280), (4280, 4282), (4283, 4289), (4290, 4293), (4294, 4298), (4299, 4306), (4307, 4311), (4312, 4313), (4314, 4320), (4321, 4327), (4328, 4330), (4331, 4337), (4338, 4342), (4343, 4346), (4347, 4351), (4352, 4355), (4356, 4360), (4361, 4363), (4364, 4369), (4370, 4376), (4376, 4377), (4377, 4378), (4378, 4379), (4379, 4382), (4383, 4391), (4392, 4393), (4394, 4398), (4399, 4401), (4402, 4406), (4407, 4412), (4413, 4415), (4416, 4419), (4420, 4425), (4426, 4428), (4429, 4436), (4436, 4437), (4437, 4441), (4441, 4442), (4443, 4446), (4447, 4453), (4454, 4456), (4457, 4459), (4460, 4461), (4462, 4468), (4469, 4476), (4477, 4480), (4481, 4487), (4487, 4489), (4490, 4497), (4498, 4501), (4501, 4502), (4503, 4506), (4507, 4510), (4511, 4520), (4521, 4523), (4524, 4527), (4528, 4535), (4536, 4538), (4539, 4542), (4543, 4549), (4550, 4557), (4558, 4563), (4564, 4567), (4568, 4579), (4579, 4580), (4581, 4586), (4587, 4590), (4591, 4597), (4598, 4602), (4603, 4606), (4607, 4608), (4609, 4612), (4613, 4624), (4625, 4627), (4628, 4632), (4633, 4637), (4637, 4638), (4639, 4642), (4643, 4647), (4648, 4651), (4652, 4654), (4655, 4658), (4659, 4661), (4662, 4668), (4669, 4670), (4671, 4678), (4679, 4685), (4685, 4686), (4687, 4693), (4694, 4698), (4699, 4704), (4705, 4706), (4707, 4717), (4718, 4724), (4724, 4725), (4725, 4726), (4726, 4727), (4727, 4729), (4730, 4731), (4732, 4738), (4738, 4739), (4740, 4747), (4747, 4748), (4748, 4752), (4753, 4758), (4759, 4761), (4762, 4764), (4765, 4766), (4767, 4774), (4775, 4780), (4780, 4781), (4782, 4785), (4786, 4789), (4790, 4796), (4797, 4800), (4801, 4803), (4804, 4807), (4808, 4811), (4812, 4814), (4815, 4817), (4817, 4818), (4819, 4825), (4826, 4828), (4829, 4832), (4833, 4839), (4840, 4846), (4847, 4850), (4851, 4857), (4858, 4864), (4864, 4865), (4866, 4869), (4870, 4876), (4877, 4878), (4879, 4883), (4884, 4888), (4889, 4892), (4892, 4894), (4894, 4897), (4898, 4903), (4903, 4905), (4906, 4908), (4909, 4912), (4913, 4918), (4919, 4921), (4922, 4925), (4925, 4926), (4927, 4934), (4935, 4943), (4944, 4945), (4946, 4950), (4951, 4953), (4954, 4958), (4959, 4964), (4965, 4967), (4968, 4971), (4972, 4977), (4978, 4980), (4981, 4988), (4988, 4989), (4989, 4993), (4994, 4999), (5000, 5004), (5005, 5012), (5013, 5019), (5020, 5022), (5023, 5024), (5025, 5032), (5033, 5042), (5043, 5047), (5048, 5055), (5056, 5059), (5060, 5064), (5064, 5065), (5066, 5073), (5073, 5074), (5074, 5078), (5079, 5083), (5084, 5090), (5091, 5093), (5094, 5096), (5097, 5098), (5099, 5106), (5107, 5115), (5115, 5116), (5117, 5119), (5120, 5122), (5123, 5126), (5127, 5128), (5129, 5135), (5136, 5145), (5145, 5146), (5146, 5147), (5147, 5148), (5148, 5150), (5151, 5155), (5155, 5157), (5158, 5162), (5163, 5167), (5168, 5170), (5171, 5173), (5173, 5174), (5175, 5180), (5181, 5183), (5184, 5189), (5190, 5193), (5194, 5205), (5206, 5213), (5214, 5218), (5219, 5222), (5223, 5229), (5230, 5235), (5236, 5242), (5243, 5250), (5250, 5251), (5252, 5254), (5255, 5259), (5260, 5270), (5271, 5273), (5274, 5280), (5281, 5288), (5289, 5292), (5293, 5303), (5304, 5306), (5307, 5312), (5313, 5315), (5316, 5326), (5327, 5329), (5330, 5331), (5332, 5335), (5336, 5342), (5343, 5349), (5349, 5350), (5351, 5353), (5354, 5355), (5356, 5362), (5362, 5363), (5364, 5366), (5367, 5371), (5372, 5374), (5375, 5377), (5378, 5384), (5385, 5386), (5387, 5396), (5396, 5397), (5398, 5403), (5404, 5413), (5414, 5416), (5417, 5422), (5422, 5423), (5424, 5426), (5427, 5429), (5430, 5434), (5434, 5436), (5437, 5440), (5441, 5444), (5445, 5456), (5457, 5464), (5465, 5472), (5472, 5473), (5473, 5477), (5477, 5479), (5480, 5486), (5487, 5494), (5495, 5500), (5501, 5507), (5508, 5515), (5515, 5516), (5517, 5519), (5520, 5526), (5526, 5528), (5529, 5533), (5534, 5538), (5539, 5549), (5550, 5552), (5552, 5553), (5554, 5557), (5558, 5561), (5562, 5566), (5567, 5572), (5573, 5575), (5576, 5578), (5579, 5580), (5581, 5586), (5586, 5591), (5592, 5598), (5599, 5602), (5603, 5606), (5606, 5608), (5609, 5613), (5614, 5616), (5617, 5623), (5624, 5627), (5628, 5632), (5633, 5635), (5636, 5645), (5645, 5646), (5647, 5656), (5656, 5657), (5658, 5659), (5660, 5667), (5668, 5675), (5676, 5684), (5685, 5693), (5694, 5697), (5698, 5702), (5703, 5710), (5711, 5715), (5716, 5717), (5718, 5724), (5725, 5731), (5732, 5739), (5740, 5742), (5743, 5746), (5747, 5751), (5752, 5756), (5757, 5765), (5766, 5778), (5779, 5781), (5782, 5790), (5790, 5791), (5791, 5792), (5792, 5793), (5793, 5795), (5796, 5806), (5806, 5807), (5808, 5814), (5815, 5822), (5822, 5823), (5823, 5827), (5827, 5828), (5829, 5836), (5836, 5837), (5837, 5841), (5841, 5842), (5843, 5850), (5850, 5851), (5851, 5855), (5855, 5856), (5857, 5860), (5861, 5865), (5866, 5870), (5871, 5878), (5879, 5884), (5885, 5891), (5892, 5897), (5898, 5900), (5901, 5910), (5911, 5913), (5914, 5919), (5920, 5926), (5926, 5927), (5928, 5930), (5931, 5935), (5936, 5940), (5940, 5942), (5943, 5947), (5948, 5953), (5953, 5955), (5956, 5962), (5962, 5963), (5964, 5968), (5969, 5974), (5975, 5979), (5980, 5986), (5987, 5991), (5992, 5993), (5994, 5998), (5999, 6003), (6004, 6009), (6010, 6013), (6014, 6019), (6020, 6025), (6026, 6035), (6036, 6038), (6039, 6044), (6044, 6045), (6046, 6049), (6049, 6050), (6051, 6061), (6061, 6062), (6063, 6067), (6068, 6073), (6074, 6076), (6077, 6083), (6084, 6086), (6087, 6092), (6093, 6099), (6099, 6100), (6101, 6103), (6104, 6105), (6106, 6112), (6112, 6113), (6114, 6118), (6119, 6123), (6124, 6126), (6127, 6129), (6130, 6137), (6138, 6142), (6143, 6147), (6148, 6157), (6158, 6164), (6165, 6168), (6169, 6174), (6174, 6175), (6176, 6185), (6185, 6186), (6187, 6188), (6189, 6191), (6192, 6199), (6200, 6207), (6208, 6216), (6217, 6225), (6225, 6226)], 'preds': ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'O', 'O', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'O', 'O', 'O', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'O'], 'pred_scores': [0.49072265625, 0.486328125, 0.48681640625, 0.4873046875, 0.483642578125, 0.484375, 0.48583984375, 0.486328125, 0.482421875, 0.48388671875, 0.48583984375, 0.4853515625, 0.48486328125, 0.486328125, 0.48193359375, 0.4794921875, 0.48046875, 0.4814453125, 0.47998046875, 0.48291015625, 0.456787109375, 0.4697265625, 0.465576171875, 0.469482421875, 0.465576171875, 0.47021484375, 0.466064453125, 0.4658203125, 0.46630859375, 0.464599609375, 0.466552734375, 0.46630859375, 0.46728515625, 0.46533203125, 0.466796875, 0.466796875, 0.46630859375, 0.466796875, 0.465087890625, 0.46435546875, 0.46875, 0.466064453125, 0.46875, 0.46630859375, 0.47021484375, 0.473876953125, 0.478515625, 0.46142578125, 0.46533203125, 0.4609375, 0.460205078125, 0.455810546875, 0.455322265625, 0.46875, 0.458984375, 0.454833984375, 0.45849609375, 0.4560546875, 0.456787109375, 0.45654296875, 0.45654296875, 0.46240234375, 0.464599609375, 0.462890625, 0.451171875, 0.453369140625, 0.4560546875, 0.448486328125, 0.447265625, 0.449951171875, 0.44580078125, 0.446533203125, 0.44775390625, 0.4482421875, 0.44775390625, 0.449951171875, 0.44921875, 0.44384765625, 0.444091796875, 0.44775390625, 0.44580078125, 0.444580078125, 0.445556640625, 0.44677734375, 0.4501953125, 0.447265625, 0.45458984375, 0.447021484375, 0.450439453125, 0.44970703125, 0.45166015625, 0.449462890625, 0.45458984375, 0.45556640625, 0.4541015625, 0.452392578125, 0.453369140625, 0.455322265625, 0.455078125, 0.45361328125, 0.455322265625, 0.455810546875, 0.457763671875, 0.451171875, 0.45458984375, 0.4453125, 0.457763671875, 0.453369140625, 0.453125, 0.457275390625, 0.451416015625, 0.46240234375, 0.45263671875, 0.450927734375, 0.450927734375, 0.443359375, 0.44873046875, 0.457763671875, 0.45458984375, 0.44921875, 0.44921875, 0.449951171875, 0.4501953125, 0.453125, 0.455322265625, 0.454833984375, 0.45068359375, 0.4658203125, 0.450927734375, 0.452392578125, 0.45166015625, 0.452880859375, 0.45263671875, 0.44873046875, 0.44921875, 0.45654296875, 0.447509765625, 0.4091796875, 0.45654296875, 0.455810546875, 0.451171875, 0.45361328125, 0.454833984375, 0.45166015625, 0.45166015625, 0.45068359375, 0.449951171875, 0.373291015625, 0.34033203125, 0.2227783203125, 0.34716796875, 0.301025390625, 0.453125, 0.458251953125, 0.4580078125, 0.4619140625, 0.460205078125, 0.46240234375, 0.4638671875, 0.46044921875, 0.45458984375, 0.46142578125, 0.45361328125, 0.427490234375, 0.39453125, 0.46435546875, 0.46484375, 0.460205078125, 0.450927734375, 0.451171875, 0.4365234375, 0.38525390625, 0.43798828125, 0.37451171875, 0.4599609375, 0.464599609375, 0.458740234375, 0.46435546875, 0.466796875, 0.45166015625, 0.31396484375, 0.467041015625, 0.4443359375, 0.46240234375, 0.459716796875, 0.45654296875, 0.4541015625, 0.4482421875, 0.4365234375, 0.39892578125, 0.49853515625, 0.4970703125, 0.28271484375, 0.263671875, 0.24853515625, 0.25390625, 0.37060546875, 0.3623046875, 0.348388671875, 0.36083984375, 0.355712890625, 0.349609375, 0.36181640625, 0.376220703125, 0.3720703125, 0.365966796875, 0.34619140625, 0.3466796875, 0.36181640625, 0.35400390625, 0.3583984375, 0.35888671875, 0.350341796875, 0.36669921875, 0.35400390625, 0.352294921875, 0.35595703125, 0.350830078125, 0.34814453125, 0.352294921875, 0.341552734375, 0.349853515625, 0.346923828125, 0.314453125, 0.2841796875, 0.49267578125, 0.498046875, 0.498046875, 0.490478515625, 0.494384765625, 0.497802734375, 0.49755859375, 0.498046875, 0.49853515625, 0.4990234375, 0.4990234375, 0.4990234375, 0.49853515625, 0.49853515625, 0.46240234375, 0.498779296875, 0.498779296875, 0.4990234375, 0.4990234375, 0.498779296875, 0.498779296875, 0.4990234375, 0.498779296875, 0.4990234375, 0.498779296875, 0.46142578125, 0.497802734375, 0.4990234375, 0.499267578125, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.49951171875, 0.49951171875, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.493408203125, 0.498046875, 0.498779296875, 0.4990234375, 0.4990234375, 0.4990234375, 0.49951171875, 0.499267578125, 0.49951171875, 0.499267578125, 0.49951171875, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.4990234375, 0.49951171875, 0.4990234375, 0.49951171875, 0.4990234375, 0.4990234375, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.494140625, 0.49609375, 0.49853515625, 0.498291015625, 0.4990234375, 0.498779296875, 0.4990234375, 0.498779296875, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.498779296875, 0.498779296875, 0.4990234375, 0.49853515625, 0.498046875, 0.498779296875, 0.498779296875, 0.4990234375, 0.49853515625, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.49853515625, 0.4990234375, 0.4990234375, 0.498779296875, 0.49755859375, 0.48828125, 0.497802734375, 0.498291015625, 0.498046875, 0.498046875, 0.498291015625, 0.498046875, 0.49755859375, 0.498046875, 0.498291015625, 0.49853515625, 0.498046875, 0.49755859375, 0.49853515625, 0.498046875, 0.49755859375, 0.49853515625, 0.49853515625, 0.498046875, 0.498046875, 0.497802734375, 0.498291015625, 0.498046875, 0.49755859375, 0.498046875, 0.49853515625, 0.498046875, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.498291015625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.498046875, 0.498291015625, 0.49853515625, 0.49853515625, 0.498291015625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.488525390625, 0.47314453125, 0.49267578125, 0.492919921875, 0.49365234375, 0.49462890625, 0.494140625, 0.494873046875, 0.49658203125, 0.49755859375, 0.49658203125, 0.49755859375, 0.49755859375, 0.49755859375, 0.498046875, 0.49658203125, 0.49755859375, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.498291015625, 0.498291015625, 0.4951171875, 0.4990234375, 0.4990234375, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.4990234375, 0.49951171875, 0.4990234375, 0.49951171875, 0.498779296875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.4990234375, 0.4990234375, 0.49951171875, 0.49951171875, 0.498779296875, 0.4990234375, 0.4990234375, 0.49853515625, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.4990234375, 0.49951171875, 0.498779296875, 0.497314453125, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.49951171875, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.4990234375, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.4990234375, 0.49853515625, 0.463623046875, 0.4990234375, 0.4990234375, 0.4990234375, 0.49951171875, 0.49951171875, 0.499267578125, 0.49755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49658203125, 0.490478515625, 0.498046875, 0.498046875, 0.498046875, 0.49853515625, 0.49853515625, 0.49755859375, 0.498046875, 0.498046875, 0.498291015625, 0.498046875, 0.498046875, 0.49853515625, 0.49658203125, 0.498046875, 0.498291015625, 0.498046875, 0.498291015625, 0.498291015625, 0.49853515625, 0.4970703125, 0.49853515625, 0.49609375, 0.49755859375, 0.49853515625, 0.49755859375, 0.498291015625, 0.498291015625, 0.494873046875, 0.49755859375, 0.497802734375, 0.497802734375, 0.496337890625, 0.498291015625, 0.49853515625, 0.498046875, 0.49755859375, 0.498046875, 0.498046875, 0.48974609375, 0.24462890625, 0.26416015625, 0.2578125, 0.2462158203125, 0.2392578125, 0.250732421875, 0.2666015625, 0.271728515625, 0.28271484375, 0.28076171875, 0.28271484375, 0.27490234375, 0.28857421875, 0.28173828125, 0.294677734375, 0.286376953125, 0.303955078125, 0.292724609375, 0.291259765625, 0.273193359375, 0.27880859375, 0.2548828125, 0.265625, 0.48974609375, 0.476806640625, 0.3544921875, 0.4619140625, 0.46875, 0.46875, 0.4697265625, 0.46728515625, 0.4677734375, 0.471435546875, 0.4716796875, 0.4716796875, 0.474609375, 0.474609375, 0.474609375, 0.471923828125, 0.474609375, 0.4736328125, 0.475830078125, 0.474365234375, 0.47216796875, 0.47216796875, 0.4716796875, 0.4697265625, 0.47021484375, 0.46875, 0.47119140625, 0.47216796875, 0.470703125, 0.467529296875, 0.451171875, 0.49560546875, 0.49609375, 0.49609375, 0.496337890625, 0.49658203125, 0.49462890625, 0.4970703125, 0.496337890625, 0.49658203125, 0.4970703125, 0.496337890625, 0.49609375, 0.49755859375, 0.496826171875, 0.49755859375, 0.49755859375, 0.4970703125, 0.497314453125, 0.497314453125, 0.4970703125, 0.496337890625, 0.4970703125, 0.497314453125, 0.4970703125, 0.49755859375, 0.49755859375, 0.498046875, 0.49658203125, 0.4970703125, 0.496826171875, 0.497802734375, 0.497314453125, 0.496826171875, 0.49755859375, 0.497802734375, 0.4970703125, 0.49658203125, 0.498291015625, 0.49755859375, 0.498046875, 0.4970703125, 0.4970703125, 0.49755859375, 0.49609375, 0.498046875, 0.498046875, 0.498046875, 0.498046875, 0.4970703125, 0.49658203125, 0.496337890625, 0.497314453125, 0.497802734375, 0.498046875, 0.49755859375, 0.49755859375, 0.498046875, 0.498046875, 0.498046875, 0.497802734375, 0.495361328125, 0.496826171875, 0.497314453125, 0.4970703125, 0.4970703125, 0.497314453125, 0.4970703125, 0.49755859375, 0.49755859375, 0.497802734375, 0.498046875, 0.498046875, 0.498046875, 0.498046875, 0.497802734375, 0.493896484375, 0.489501953125, 0.4931640625, 0.489501953125, 0.4951171875, 0.49462890625, 0.4951171875, 0.49462890625, 0.4951171875, 0.494384765625, 0.49365234375, 0.493408203125, 0.49462890625, 0.49560546875, 0.493408203125, 0.4931640625, 0.494140625, 0.4931640625, 0.493408203125, 0.4951171875, 0.49560546875, 0.495361328125, 0.4951171875, 0.495361328125, 0.49609375, 0.49560546875, 0.49658203125, 0.49658203125, 0.495849609375, 0.49658203125, 0.49658203125, 0.495849609375, 0.49560546875, 0.494873046875, 0.49462890625, 0.49560546875, 0.49560546875, 0.49462890625, 0.49560546875, 0.494873046875, 0.495849609375, 0.495361328125, 0.49560546875, 0.495361328125, 0.495361328125, 0.495849609375, 0.490234375, 0.4853515625, 0.492919921875, 0.4931640625, 0.493408203125, 0.49267578125, 0.492919921875, 0.492919921875, 0.49267578125, 0.49365234375, 0.491943359375, 0.49169921875, 0.492919921875, 0.4921875, 0.49267578125, 0.49365234375, 0.494140625, 0.49267578125, 0.493896484375, 0.49365234375, 0.49462890625, 0.493896484375, 0.49365234375, 0.494140625, 0.494384765625, 0.49462890625, 0.49365234375, 0.494140625, 0.494384765625, 0.49365234375, 0.494140625, 0.49462890625, 0.494140625, 0.494873046875, 0.494140625, 0.4541015625, 0.49169921875, 0.49365234375, 0.493408203125, 0.494140625, 0.493896484375, 0.494140625, 0.494140625, 0.494140625, 0.494140625, 0.4931640625, 0.49365234375, 0.494140625, 0.49365234375, 0.475341796875, 0.478515625, 0.4814453125, 0.47314453125, 0.48388671875, 0.481201171875, 0.482421875, 0.48193359375, 0.48486328125, 0.4853515625, 0.48828125, 0.486328125, 0.48876953125, 0.486328125, 0.48828125, 0.48681640625, 0.4892578125, 0.4912109375, 0.490234375, 0.490234375, 0.48828125, 0.48779296875, 0.48876953125, 0.4912109375, 0.4921875, 0.4931640625, 0.494140625, 0.493408203125, 0.493896484375, 0.49365234375, 0.494140625, 0.49365234375, 0.4921875, 0.476806640625, 0.493408203125, 0.493896484375, 0.49267578125, 0.49462890625, 0.494140625, 0.49365234375, 0.493896484375, 0.479248046875, 0.49365234375, 0.4931640625, 0.49365234375, 0.49365234375, 0.493408203125, 0.493408203125, 0.494140625, 0.493408203125, 0.494140625, 0.47998046875, 0.4892578125, 0.4912109375, 0.49072265625, 0.48974609375, 0.48974609375, 0.48828125, 0.48828125, 0.4912109375, 0.491943359375, 0.491943359375, 0.49169921875, 0.491455078125, 0.492919921875, 0.49169921875, 0.4921875, 0.49267578125, 0.4921875, 0.49169921875, 0.4912109375, 0.4912109375, 0.49267578125, 0.49072265625, 0.4921875, 0.49267578125, 0.490234375, 0.492919921875, 0.4736328125, 0.48583984375, 0.486328125, 0.48876953125, 0.48876953125, 0.489990234375, 0.48876953125, 0.48828125, 0.48974609375, 0.49072265625, 0.490478515625, 0.4912109375, 0.4892578125, 0.48828125, 0.490478515625, 0.49072265625, 0.490234375, 0.4892578125, 0.489990234375, 0.489501953125, 0.48876953125, 0.489501953125, 0.4892578125, 0.489501953125, 0.489013671875, 0.48828125, 0.491943359375, 0.48974609375, 0.487060546875, 0.48388671875, 0.486328125, 0.48876953125, 0.489501953125, 0.4873046875, 0.48681640625, 0.486328125, 0.488525390625, 0.4853515625, 0.4853515625, 0.486083984375, 0.485595703125, 0.48583984375, 0.486328125, 0.486328125, 0.48681640625, 0.48583984375, 0.4873046875, 0.4873046875, 0.48779296875, 0.4853515625, 0.4892578125, 0.486572265625, 0.48583984375, 0.4853515625, 0.486083984375, 0.486572265625, 0.44873046875, 0.1783447265625, 0.21923828125, 0.178955078125, 0.2314453125, 0.246826171875, 0.2242431640625, 0.2939453125, 0.30029296875, 0.304443359375, 0.30615234375, 0.30859375, 0.32373046875, 0.3193359375, 0.320556640625, 0.31005859375, 0.322265625, 0.31103515625, 0.33056640625, 0.32763671875, 0.32666015625, 0.259521484375, 0.309326171875, 0.314697265625, 0.316162109375, 0.3232421875, 0.31982421875, 0.31640625, 0.30810546875, 0.458984375, 0.4296875, 0.37255859375, 0.441650390625, 0.4453125, 0.455322265625, 0.445556640625, 0.44482421875, 0.44189453125, 0.45068359375, 0.453369140625, 0.47021484375, 0.46484375, 0.46826171875, 0.476318359375, 0.47509765625, 0.468994140625, 0.472412109375, 0.48291015625, 0.480712890625, 0.48095703125, 0.47900390625, 0.47314453125, 0.4794921875, 0.479736328125, 0.481689453125, 0.481689453125, 0.483154296875, 0.481689453125, 0.46044921875, 0.474609375, 0.4931640625, 0.494140625, 0.49462890625, 0.4931640625, 0.49365234375, 0.494140625, 0.493408203125, 0.4951171875, 0.494873046875, 0.49365234375, 0.493408203125, 0.4931640625, 0.4921875, 0.49365234375, 0.493408203125, 0.493896484375, 0.494140625, 0.493408203125, 0.491455078125, 0.494140625, 0.49365234375, 0.494140625, 0.494384765625, 0.49365234375, 0.4794921875, 0.49169921875, 0.491943359375, 0.49169921875, 0.491943359375, 0.4921875, 0.49169921875, 0.4912109375, 0.4921875, 0.49169921875, 0.4931640625, 0.4912109375, 0.48974609375, 0.490234375, 0.491455078125, 0.4912109375, 0.49267578125, 0.490478515625, 0.489501953125, 0.39599609375, 0.4345703125, 0.43603515625, 0.490234375, 0.489501953125, 0.4912109375, 0.491943359375, 0.4921875, 0.4921875, 0.493408203125, 0.49267578125, 0.49267578125, 0.49267578125, 0.4931640625, 0.4921875, 0.49169921875, 0.49169921875, 0.492431640625, 0.49267578125, 0.49365234375, 0.492919921875, 0.4873046875, 0.49267578125, 0.49169921875, 0.49267578125, 0.482421875, 0.490478515625, 0.492431640625, 0.49267578125, 0.4931640625, 0.493408203125, 0.49267578125, 0.49365234375, 0.492431640625, 0.49267578125, 0.49365234375, 0.49365234375, 0.4931640625, 0.49365234375, 0.48876953125, 0.49365234375, 0.49365234375, 0.49365234375, 0.4931640625, 0.4931640625, 0.49365234375, 0.49267578125, 0.4931640625, 0.4931640625, 0.49267578125, 0.49072265625, 0.47607421875, 0.48583984375, 0.481689453125, 0.48388671875, 0.48388671875, 0.482666015625, 0.48681640625, 0.4892578125, 0.490478515625, 0.489990234375, 0.490234375, 0.489013671875, 0.48974609375, 0.490478515625, 0.49169921875, 0.4912109375, 0.49169921875, 0.49267578125, 0.4921875, 0.4921875, 0.49267578125, 0.49267578125, 0.4921875, 0.493408203125, 0.4931640625, 0.4921875, 0.4921875, 0.490234375, 0.494140625, 0.494873046875, 0.49462890625, 0.4951171875, 0.494384765625, 0.494384765625, 0.494384765625, 0.49560546875, 0.4951171875, 0.490966796875, 0.49462890625, 0.49560546875, 0.494873046875, 0.4951171875, 0.494873046875, 0.4951171875, 0.49365234375, 0.47216796875, 0.47705078125, 0.4853515625, 0.49609375, 0.496337890625, 0.49658203125, 0.49609375, 0.49609375, 0.49560546875, 0.49560546875, 0.49609375, 0.495361328125, 0.495849609375, 0.495849609375, 0.496826171875, 0.496337890625, 0.496337890625, 0.49609375, 0.49658203125, 0.49609375, 0.495849609375, 0.49609375, 0.482421875, 0.495361328125, 0.4970703125, 0.4970703125, 0.496826171875, 0.49658203125, 0.496826171875, 0.4970703125, 0.4970703125, 0.496826171875, 0.4970703125, 0.49658203125, 0.4970703125, 0.4970703125, 0.4970703125, 0.4970703125, 0.4970703125, 0.49658203125, 0.49609375, 0.495849609375, 0.48095703125, 0.496337890625, 0.49609375, 0.49658203125, 0.49658203125, 0.49658203125, 0.496826171875, 0.49658203125, 0.496826171875, 0.496826171875, 0.488525390625, 0.4970703125, 0.496826171875, 0.496337890625, 0.49658203125, 0.48486328125, 0.49169921875, 0.49560546875, 0.49560546875, 0.49560546875, 0.49609375, 0.495849609375, 0.4970703125, 0.49609375, 0.49609375, 0.49560546875, 0.4951171875, 0.49609375, 0.49658203125, 0.49609375, 0.49609375, 0.49609375, 0.49609375, 0.49609375, 0.496826171875, 0.496337890625, 0.496826171875, 0.496337890625, 0.49658203125, 0.4970703125, 0.49609375, 0.492919921875, 0.49609375, 0.496337890625, 0.496337890625, 0.496337890625, 0.49609375, 0.49609375, 0.496826171875, 0.49609375, 0.49609375, 0.49658203125, 0.49658203125, 0.496337890625, 0.49658203125, 0.49609375, 0.495849609375, 0.49609375, 0.49609375, 0.49609375, 0.49609375, 0.496337890625, 0.483154296875, 0.277099609375, 0.259033203125, 0.2081298828125, 0.2239990234375, 0.1986083984375, 0.2890625, 0.298095703125, 0.326416015625, 0.338623046875, 0.3330078125, 0.330810546875, 0.322265625, 0.333251953125, 0.322265625, 0.3466796875, 0.34375, 0.36865234375, 0.365478515625, 0.361083984375, 0.361328125, 0.361328125, 0.36328125, 0.36767578125, 0.344970703125, 0.498046875, 0.498046875, 0.393798828125, 0.40673828125, 0.290283203125, 0.25341796875, 0.49462890625, 0.495361328125, 0.49560546875, 0.49560546875, 0.4951171875, 0.4951171875, 0.495849609375, 0.49658203125, 0.495361328125, 0.4951171875, 0.49609375, 0.410400390625, 0.4912109375, 0.49658203125, 0.49658203125, 0.49658203125, 0.49755859375, 0.4970703125, 0.4970703125, 0.497314453125, 0.4970703125, 0.49755859375, 0.4970703125, 0.49658203125, 0.49658203125, 0.495361328125, 0.497802734375, 0.497802734375, 0.497802734375, 0.497802734375, 0.497802734375, 0.497802734375, 0.49755859375, 0.49755859375, 0.497802734375, 0.49755859375, 0.497802734375, 0.49755859375, 0.497802734375, 0.497802734375, 0.49755859375, 0.49755859375, 0.4970703125, 0.49755859375, 0.4970703125, 0.49755859375, 0.4970703125, 0.49755859375, 0.4970703125, 0.4423828125, 0.495849609375, 0.495361328125, 0.49560546875, 0.49658203125, 0.496826171875, 0.49609375, 0.49609375, 0.49609375, 0.49609375, 0.49609375, 0.49560546875, 0.470703125, 0.49365234375, 0.47998046875, 0.492431640625, 0.494140625, 0.4951171875, 0.4951171875, 0.4951171875, 0.4951171875, 0.49462890625, 0.49462890625, 0.49462890625, 0.49462890625, 0.494140625, 0.49462890625, 0.49462890625, 0.4873046875, 0.46826171875, 0.4677734375, 0.46728515625, 0.466064453125, 0.467041015625, 0.4658203125, 0.46728515625, 0.4638671875, 0.44775390625, 0.49951171875]}, {'id': 'D46BCB48440A', 'input_ids': [1779, 82, 1394, 13, 2949, 6, 10010, 2128, 1067, 7, 55, 87, 65, 621, 4, 33433, 16, 41, 2979, 6, 6025, 18, 174, 7, 277, 621, 4, 38, 206, 18192, 50141, 19178, 82, 146, 357, 5717, 4, 993, 2188, 38, 206, 596, 18192, 2607, 16, 4719, 47, 1522, 6, 817, 724, 283, 1528, 6, 8, 817, 1022, 4, 50118, 50118, 133, 1219, 38, 206, 18192, 244, 16, 4719, 47, 1522, 4, 345, 32, 171, 2702, 82, 8, 631, 11, 5, 232, 4, 280, 115, 2581, 47, 11, 98, 171, 1319, 4, 520, 38, 300, 4036, 7, 10, 32382, 8, 62, 4115, 537, 4, 38, 21, 98, 1227, 7, 213, 53, 939, 46405, 216, 114, 939, 197, 213, 7, 5, 537, 4, 407, 939, 553, 127, 3795, 13, 2949, 4, 1892, 79, 174, 162, 24, 1979, 75, 28, 5, 275, 1114, 6, 100, 115, 120, 15762, 4, 38, 1507, 19, 69, 8, 399, 75, 213, 4, 280, 2949, 31, 127, 3795, 5305, 162, 31, 562, 15762, 4, 50118, 50118, 21518, 1219, 38, 206, 17638, 5504, 244, 16, 146, 1175, 283, 1528, 4, 11812, 7, 110, 724, 16, 1256, 543, 4, 125, 114, 47, 33, 951, 7, 1920, 47, 149, 24, 47, 64, 109, 24, 4, 520, 38, 851, 62, 15, 1959, 41, 16688, 4, 1308, 1441, 174, 162, 103, 2949, 2758, 38, 240, 7, 489, 164, 454, 939, 1348, 127, 724, 4, 178, 26, 79, 16765, 13, 162, 4, 38, 1299, 7917, 456, 8, 1372, 14, 79, 89, 13, 162, 4, 50118, 50118, 133, 94, 1219, 38, 206, 18192, 244, 16, 817, 1022, 4, 27341, 32, 2247, 8, 98, 32, 814, 4, 252, 64, 146, 383, 1369, 19, 1533, 9, 106, 4, 497, 84, 334, 6, 627, 11728, 5559, 32, 182, 21250, 4, 166, 1137, 84, 3254, 53, 51, 399, 75, 4161, 4, 407, 52, 1194, 82, 198, 5, 334, 8, 553, 106, 7, 1203, 10, 2225, 4, 3128, 52, 58, 626, 4, 166, 77, 81, 7, 5, 334, 792, 4, 178, 174, 106, 59, 5, 21250, 11728, 5559, 23, 1304, 4, 252, 1507, 14, 1304, 197, 464, 49, 11728, 5559, 7, 12732, 11728, 5559, 4, 178, 1714, 5, 11728, 5559, 1665, 10, 1304, 4, 50118, 50118, 41245, 5504, 64, 28, 7163, 50, 45, 7163, 4, 125, 114, 24, 64, 244, 47, 172, 2540, 4161, 7, 24, 4, 1599, 75, 1803, 24, 66, 479, 2847, 171, 82, 206, 24, 18, 23584, 4, 125, 24, 244, 11, 98, 171, 101, 489, 47, 1522, 6, 19746, 1175, 283, 1528, 50, 817, 1022, 4, 370, 64, 75, 109, 960, 15, 110, 4, 208, 40034, 24, 18, 357, 7, 1394, 13, 244, 4, 1437, 1437, 50145, 50143, 1437, 1437, 50145, 50143, 1437, 1437, 50145, 50143], 'text': \"When people ask for advice,they sometimes talk to more than one person. Advice is an opinion,that's told to another person. I think advises\\xa0help people make better choices. Some reasons I think why advises helps is keeps you safe, makes goal come true, and makes changes.\\n\\nThe reason I think advises help is keeps you safe. There are many dangerous people and thing in the world. That could hurt you in so many ways. When I got invited to a sixteen and up birthday party. I was so ready to go but i didnt know if i should go to the party. So i asked my mom for advice. Then she told me it wouldn't be the best idea,I could get kidnapped. I agreed with her and didn't go. That advice from my mom saved me from getting kidnapped.\\n\\nAnother reason I think Advises help is make goals come true. Getting to your goal is pretty hard. But if you have someone to push you through it you can do it. When I gave up on becoming an Artist. My friend told me some advice telling I need to keep going until i reached my goal. And said she cheering for me. I felt hopeful again and happy that she there for me.\\n\\nThe last reason I think advises help is makes changes. Words are powerful and so are action. They can make things happen with multiple of them. At our school,the lunches are very unhealthy. We tell our teacher but they didn't listen. So we interview people around the school and asked them to sign a paper. Once we were done. We when over to the school board. And told them about the unhealthy lunches at schools. They agreed that schools should change their lunches to healthier lunches. And changed the lunches served a schools.\\n\\nAdvises can be helpful or not helpful. But if it can help you then please listen to it. Don't block it out .So many people think it's useless. But it help in so many like keep you safe,make goals come true or makes changes. You can't do everything on your. Sometime it's better to ask for help.   \\xa0 \\xa0 \\xa0   \\xa0 \\xa0 \\xa0   \\xa0 \\xa0 \\xa0\", 'offset_mapping': [(0, 4), (5, 11), (12, 15), (16, 19), (20, 26), (26, 27), (27, 31), (32, 41), (42, 46), (47, 49), (50, 54), (55, 59), (60, 63), (64, 70), (70, 71), (72, 78), (79, 81), (82, 84), (85, 92), (92, 93), (93, 97), (97, 99), (100, 104), (105, 107), (108, 115), (116, 122), (122, 123), (124, 125), (126, 131), (132, 139), (139, 140), (140, 144), (145, 151), (152, 156), (157, 163), (164, 171), (171, 172), (173, 177), (178, 185), (186, 187), (188, 193), (194, 197), (198, 205), (206, 211), (212, 214), (215, 220), (221, 224), (225, 229), (229, 230), (231, 236), (237, 241), (242, 246), (247, 251), (251, 252), (253, 256), (257, 262), (263, 270), (270, 271), (271, 272), (272, 273), (273, 276), (277, 283), (284, 285), (286, 291), (292, 299), (300, 304), (305, 307), (308, 313), (314, 317), (318, 322), (322, 323), (324, 329), (330, 333), (334, 338), (339, 348), (349, 355), (356, 359), (360, 365), (366, 368), (369, 372), (373, 378), (378, 379), (380, 384), (385, 390), (391, 395), (396, 399), (400, 402), (403, 405), (406, 410), (411, 415), (415, 416), (417, 421), (422, 423), (424, 427), (428, 435), (436, 438), (439, 440), (441, 448), (449, 452), (453, 455), (456, 464), (465, 470), (470, 471), (472, 473), (474, 477), (478, 480), (481, 486), (487, 489), (490, 492), (493, 496), (497, 498), (499, 504), (505, 509), (510, 512), (513, 514), (515, 521), (522, 524), (525, 527), (528, 531), (532, 537), (537, 538), (539, 541), (542, 543), (544, 549), (550, 552), (553, 556), (557, 560), (561, 567), (567, 568), (569, 573), (574, 577), (578, 582), (583, 585), (586, 588), (589, 595), (595, 597), (598, 600), (601, 604), (605, 609), (610, 614), (614, 615), (615, 616), (617, 622), (623, 626), (627, 636), (636, 637), (638, 639), (640, 646), (647, 651), (652, 655), (656, 659), (660, 664), (664, 666), (667, 669), (669, 670), (671, 675), (676, 682), (683, 687), (688, 690), (691, 694), (695, 700), (701, 703), (704, 708), (709, 716), (717, 726), (726, 727), (727, 728), (728, 729), (729, 736), (737, 743), (744, 745), (746, 751), (752, 755), (755, 759), (760, 764), (765, 767), (768, 772), (773, 778), (779, 783), (784, 788), (788, 789), (790, 797), (798, 800), (801, 805), (806, 810), (811, 813), (814, 820), (821, 825), (825, 826), (827, 830), (831, 833), (834, 837), (838, 842), (843, 850), (851, 853), (854, 858), (859, 862), (863, 870), (871, 873), (874, 877), (878, 881), (882, 884), (885, 887), (887, 888), (889, 893), (894, 895), (896, 900), (901, 903), (904, 906), (907, 915), (916, 918), (919, 925), (925, 926), (927, 929), (930, 936), (937, 941), (942, 944), (945, 949), (950, 956), (957, 964), (965, 966), (967, 971), (972, 974), (975, 979), (980, 985), (986, 991), (992, 993), (994, 1001), (1002, 1004), (1005, 1009), (1009, 1010), (1011, 1014), (1015, 1019), (1020, 1023), (1024, 1032), (1033, 1036), (1037, 1039), (1039, 1040), (1041, 1042), (1043, 1047), (1048, 1055), (1056, 1061), (1062, 1065), (1066, 1071), (1072, 1076), (1077, 1080), (1081, 1086), (1087, 1090), (1091, 1093), (1093, 1094), (1094, 1095), (1095, 1096), (1096, 1099), (1100, 1104), (1105, 1111), (1112, 1113), (1114, 1119), (1120, 1127), (1128, 1132), (1133, 1135), (1136, 1141), (1142, 1149), (1149, 1150), (1151, 1156), (1157, 1160), (1161, 1169), (1170, 1173), (1174, 1176), (1177, 1180), (1181, 1187), (1187, 1188), (1189, 1193), (1194, 1197), (1198, 1202), (1203, 1209), (1210, 1216), (1217, 1221), (1222, 1230), (1231, 1233), (1234, 1238), (1238, 1239), (1240, 1242), (1243, 1246), (1247, 1253), (1253, 1254), (1254, 1257), (1258, 1261), (1261, 1265), (1266, 1269), (1270, 1274), (1275, 1284), (1284, 1285), (1286, 1288), (1289, 1293), (1294, 1297), (1298, 1305), (1306, 1309), (1310, 1314), (1315, 1319), (1319, 1321), (1322, 1328), (1328, 1329), (1330, 1332), (1333, 1335), (1336, 1345), (1346, 1352), (1353, 1359), (1360, 1363), (1364, 1370), (1371, 1374), (1375, 1380), (1381, 1385), (1386, 1388), (1389, 1393), (1394, 1395), (1396, 1401), (1401, 1402), (1403, 1407), (1408, 1410), (1411, 1415), (1416, 1420), (1420, 1421), (1422, 1424), (1425, 1429), (1430, 1434), (1435, 1437), (1438, 1441), (1442, 1448), (1449, 1454), (1454, 1455), (1456, 1459), (1460, 1464), (1465, 1469), (1470, 1475), (1476, 1479), (1480, 1489), (1490, 1493), (1493, 1497), (1498, 1500), (1501, 1508), (1508, 1509), (1510, 1514), (1515, 1521), (1522, 1526), (1527, 1534), (1535, 1541), (1542, 1548), (1549, 1554), (1555, 1558), (1558, 1562), (1563, 1565), (1566, 1575), (1576, 1579), (1579, 1583), (1583, 1584), (1585, 1588), (1589, 1596), (1597, 1600), (1601, 1604), (1604, 1608), (1609, 1615), (1616, 1617), (1618, 1625), (1625, 1626), (1626, 1627), (1627, 1628), (1628, 1631), (1631, 1635), (1636, 1639), (1640, 1642), (1643, 1650), (1651, 1653), (1654, 1657), (1658, 1665), (1665, 1666), (1667, 1670), (1671, 1673), (1674, 1676), (1677, 1680), (1681, 1685), (1686, 1689), (1690, 1694), (1695, 1701), (1702, 1708), (1709, 1711), (1712, 1714), (1714, 1715), (1716, 1719), (1719, 1721), (1722, 1727), (1728, 1730), (1731, 1734), (1735, 1736), (1736, 1738), (1739, 1743), (1744, 1750), (1751, 1756), (1757, 1759), (1759, 1761), (1762, 1769), (1769, 1770), (1771, 1774), (1775, 1777), (1778, 1782), (1783, 1785), (1786, 1788), (1789, 1793), (1794, 1798), (1799, 1803), (1804, 1807), (1808, 1812), (1812, 1813), (1813, 1817), (1818, 1823), (1824, 1828), (1829, 1833), (1834, 1836), (1837, 1842), (1843, 1850), (1850, 1851), (1852, 1855), (1856, 1859), (1859, 1861), (1862, 1864), (1865, 1875), (1876, 1878), (1879, 1883), (1883, 1884), (1885, 1886), (1886, 1893), (1894, 1896), (1896, 1898), (1899, 1905), (1906, 1908), (1909, 1912), (1913, 1916), (1917, 1921), (1921, 1922), (1923, 1923), (1924, 1924), (1925, 1928), (1929, 1930), (1931, 1931), (1932, 1932), (1933, 1936), (1937, 1938), (1939, 1939), (1940, 1940), (1941, 1944), (1945, 1946)], 'preds': ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Claim', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Claim', 'O', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Claim', 'I-Claim', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'B-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence'], 'pred_scores': [0.484375, 0.470703125, 0.47509765625, 0.474609375, 0.47216796875, 0.471923828125, 0.47900390625, 0.478515625, 0.480712890625, 0.48046875, 0.48095703125, 0.48095703125, 0.479736328125, 0.47900390625, 0.47265625, 0.482666015625, 0.478271484375, 0.479248046875, 0.476806640625, 0.4755859375, 0.4814453125, 0.47509765625, 0.4736328125, 0.474853515625, 0.47509765625, 0.46484375, 0.39501953125, 0.468994140625, 0.466796875, 0.46728515625, 0.489990234375, 0.49169921875, 0.49365234375, 0.49267578125, 0.4931640625, 0.4921875, 0.450927734375, 0.4248046875, 0.419921875, 0.4345703125, 0.400634765625, 0.409423828125, 0.39404296875, 0.357666015625, 0.3671875, 0.44189453125, 0.497802734375, 0.497314453125, 0.42236328125, 0.486328125, 0.498046875, 0.49853515625, 0.49755859375, 0.274658203125, 0.4609375, 0.48583984375, 0.49658203125, 0.4697265625, 0.5, 0.499755859375, 0.40966796875, 0.404541015625, 0.413330078125, 0.400146484375, 0.380859375, 0.3583984375, 0.350341796875, 0.256103515625, 0.26806640625, 0.25830078125, 0.25927734375, 0.4931640625, 0.497802734375, 0.498046875, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49755859375, 0.49853515625, 0.49853515625, 0.4990234375, 0.498779296875, 0.4990234375, 0.498779296875, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.49853515625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4970703125, 0.5, 0.49755859375, 0.499755859375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.49365234375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.489501953125, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.497802734375, 0.49951171875, 0.49951171875, 0.41943359375, 0.4208984375, 0.41748046875, 0.41064453125, 0.3623046875, 0.36279296875, 0.3583984375, 0.359130859375, 0.2281494140625, 0.251220703125, 0.25732421875, 0.249755859375, 0.2802734375, 0.493408203125, 0.49658203125, 0.49658203125, 0.496337890625, 0.49560546875, 0.496337890625, 0.49609375, 0.496337890625, 0.49755859375, 0.497802734375, 0.498291015625, 0.498291015625, 0.498291015625, 0.498291015625, 0.49853515625, 0.498779296875, 0.498291015625, 0.49853515625, 0.498291015625, 0.498291015625, 0.49853515625, 0.49853515625, 0.498779296875, 0.49853515625, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49169921875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.490234375, 0.499267578125, 0.49951171875, 0.45947265625, 0.431396484375, 0.42724609375, 0.423828125, 0.412353515625, 0.353271484375, 0.357421875, 0.37890625, 0.2152099609375, 0.30712890625, 0.267578125, 0.46533203125, 0.493896484375, 0.4951171875, 0.49560546875, 0.495849609375, 0.495849609375, 0.49609375, 0.480224609375, 0.49658203125, 0.4970703125, 0.49755859375, 0.497802734375, 0.497802734375, 0.497802734375, 0.497802734375, 0.497802734375, 0.497314453125, 0.49072265625, 0.49462890625, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.48681640625, 0.499267578125, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.487548828125, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.48583984375, 0.49951171875, 0.499755859375, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.49951171875, 0.49951171875, 0.4990234375, 0.499267578125, 0.499267578125, 0.49951171875, 0.499267578125, 0.499267578125, 0.499267578125, 0.4990234375, 0.49755859375, 0.5, 0.5, 0.46875, 0.470947265625, 0.4794921875, 0.4794921875, 0.479736328125, 0.476806640625, 0.4833984375, 0.479248046875, 0.390869140625, 0.4609375, 0.474365234375, 0.4736328125, 0.47314453125, 0.473388671875, 0.474609375, 0.463623046875, 0.471435546875, 0.471435546875, 0.4736328125, 0.47412109375, 0.47265625, 0.4755859375, 0.4814453125, 0.4814453125, 0.482421875, 0.484375, 0.472900390625, 0.47412109375, 0.481201171875, 0.479736328125, 0.48046875, 0.486328125, 0.48291015625, 0.484130859375, 0.470458984375, 0.4814453125, 0.48828125, 0.48681640625, 0.487548828125, 0.486328125, 0.48779296875, 0.48974609375, 0.49072265625, 0.48974609375, 0.490478515625, 0.4892578125, 0.4921875, 0.491455078125, 0.49169921875, 0.4912109375, 0.490234375, 0.49169921875, 0.49072265625, 0.4853515625, 0.4814453125, 0.484375, 0.4853515625, 0.486083984375, 0.486328125, 0.487060546875, 0.486328125, 0.483642578125, 0.48095703125, 0.48095703125, 0.48046875, 0.48046875, 0.4814453125, 0.48095703125, 0.481201171875, 0.48095703125, 0.480224609375, 0.472412109375, 0.49951171875, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875]}, {'id': '0FB0700DAF44', 'input_ids': [14229, 10, 333, 695, 6, 33, 47, 655, 553, 10, 333, 919, 59, 1271, 50, 8119, 402, 116, 1793, 6, 77, 47, 58, 7739, 13, 10, 10638, 1296, 6, 222, 47, 655, 1394, 110, 1041, 50, 21771, 59, 430, 1319, 7, 3692, 10, 1402, 936, 116, 287, 7037, 13, 97, 18, 5086, 16, 941, 10142, 25, 24, 2386, 13, 41, 1736, 7, 1325, 10, 3143, 9, 430, 2728, 1567, 10, 576, 5674, 4, 21371, 6, 145, 5544, 8, 1996, 171, 82, 13, 49, 5086, 2386, 65, 7, 1346, 141, 144, 82, 228, 438, 16637, 402, 4, 152, 16, 941, 505, 25, 4730, 1533, 5086, 64, 1157, 951, 7, 185, 167, 2728, 88, 1316, 8, 17980, 106, 1090, 459, 3677, 7, 5, 937, 2437, 4, 25225, 430, 82, 18, 2979, 64, 28, 10142, 11, 10, 3143, 9, 5458, 4, 50118, 50118, 10993, 8, 16501, 6, 10, 372, 1246, 59, 141, 4730, 97, 18, 5086, 16, 7163, 16, 77, 951, 16, 442, 5, 2031, 227, 7893, 50, 4885, 32155, 31, 7893, 4, 83, 1294, 64, 1183, 15, 10, 1012, 4238, 14, 7893, 16, 1099, 6, 8, 64, 1880, 49, 3425, 16976, 4, 635, 6, 15, 277, 4238, 6, 5, 1294, 64, 465, 20170, 59, 5, 144, 27857, 154, 7893, 2187, 14, 64, 800, 5, 144, 32331, 1075, 833, 11, 5, 2900, 6, 70, 5, 150, 45, 20242, 352, 28428, 82, 18, 19147, 4, 152, 1294, 40, 1325, 10, 3143, 9, 430, 2728, 8, 5086, 15, 10, 1402, 5674, 6, 61, 2386, 106, 7, 146, 5, 275, 13527, 2031, 50, 568, 716, 15, 141, 51, 18107, 99, 51, 794, 4, 17110, 5846, 6, 10, 1294, 64, 28, 174, 31, 39, 2598, 18295, 14, 7893, 16, 1531, 6, 32076, 6, 8, 817, 106, 1372, 4, 635, 6, 114, 5, 1294, 6990, 10, 400, 3299, 6, 51, 40, 28, 3978, 8225, 4, 83, 3299, 40, 144, 533, 1137, 106, 14, 7893, 6, 1712, 29626, 27243, 23, 78, 6, 64, 483, 7, 1473, 251, 1385, 4914, 4, 50118, 50118, 1106, 5, 1294, 6990, 258, 39, 964, 8, 39, 3333, 6, 37, 16, 441, 7, 304, 39, 17219, 337, 2417, 7, 10922, 7059, 61, 2031, 40, 28, 275, 13, 123, 11, 5, 251, 422, 4, 50118, 50118, 42395, 6, 1996, 13, 1533, 5086, 64, 21576, 1594, 405, 148, 9150, 13, 10, 737, 8534, 6, 25, 12260, 24143, 782, 7, 146, 2390, 15, 99, 51, 240, 7, 224, 50, 109, 4, 286, 1246, 6, 24, 64, 28, 7163, 11, 5458, 101, 1727, 6, 258, 13, 5, 121, 4, 104, 4, 50, 1622, 11, 334, 4, 318, 10, 1294, 16, 878, 13, 10, 737, 11, 558, 7, 3594, 39, 73, 1843, 334, 6, 37, 73, 8877, 64, 1394, 10, 5859, 8, 5544, 2437, 4, 1234, 6, 1996, 97, 521, 16, 49, 275, 5673, 7, 14999, 335, 4, 1944, 521, 64, 6296, 123, 73, 1843, 59, 99, 51, 236, 6, 101, 357, 514, 856, 12825, 5069, 6, 23459, 6, 50, 12732, 689, 4, 1892, 6, 5, 1294, 878, 64, 146, 1022, 7, 5, 169, 51, 422, 13, 5, 729, 6, 8, 15, 39, 73, 1843, 1901, 6, 185, 10, 430, 1548, 4, 96, 1285, 6, 114, 5, 1294, 878, 6990, 41, 4194, 6, 51, 40, 120, 7, 216, 10, 55, 10556, 169, 5, 334, 64, 28, 2782, 4, 1773, 10, 1294, 6, 190, 25, 10, 1294, 1036, 6, 965, 75, 441, 7, 146, 10, 1233, 464, 7, 10, 334, 6, 51, 64, 6296, 5, 334, 792, 59, 1319, 7, 146, 5, 334, 357, 4, 318, 951, 16, 878, 13, 5, 394, 9, 5, 315, 532, 6, 10, 1122, 1548, 64, 28, 551, 4, 1234, 6, 51, 64, 1394, 5, 82, 6, 15, 592, 433, 50, 11, 13467, 6, 59, 1313, 1319, 7, 3114, 84, 247, 4, 572, 5, 1984, 9524, 5, 2979, 9, 937, 7768, 6, 51, 64, 637, 8225, 7, 914, 5, 1217, 9, 167, 3434, 4, 404, 11, 70, 6, 1996, 13, 5, 2979, 9, 1533, 430, 82, 64, 278, 5, 1984, 4102, 31, 643, 4, 50118, 50118, 10787, 82, 129, 1394, 65, 1907, 9, 2437, 13, 49, 2979, 4, 5365, 129, 65, 2979, 64, 483, 7, 2430, 4914, 6, 215, 25, 442, 5, 1593, 5717, 1330, 7, 474, 50, 1265, 6, 25, 129, 65, 2437, 16, 2329, 10887, 88, 442, 10, 568, 4, 9068, 6, 1996, 1533, 430, 82, 54, 33, 430, 14218, 16, 4499, 7, 442, 5, 275, 5717, 11, 301, 4, 2585, 39830, 6, 4730, 1533, 5086, 15, 10, 1402, 948, 64, 32156, 483, 7, 357, 775, 13, 2172, 4, 50141], 'text': \"During a group project, have you ever asked a group member about adding or replacing something? Or, when you were studying for a math test, did you ever ask your parents or sibling about different ways to tackle a certain problem? Asking for other's opinions is especially beneficial as it allows for an individual to receive a variety of different views towards a given topic. Likewise, being diverse and asking many people for their opinions allows one to understand how most people percieve something. This is especially important as knowing multiple opinions can allow someone to take those views into account and sway themseleves to the general audience. Knowing different people's opinion can be beneficial in a variety of situations.\\n\\nFirst and foremost, a great example about how knowing other's opinions is helpful is when someone is making the choice between smoking or refraining from smoking. A student can watch on a TV channel that smoking is bad, and can damage their internal organs. However, on another channel, the student can find advertisements about the most addicting smoking device that can release the most dopomine in the brain, all the while not severly harming people's lungs. This student will receive a variety of different views and opinions on a certain topic, which allows them to make the best educated choice or decision based on how they interpret what they saw. Similarily, a student can be told from his fellow classmates that smoking is fun, joyful, and makes them happy. However, if the student asks a local doctor, they will be informed differently. A doctor will most likely tell them that smoking, although seeming harmless at first, can lead to serious long term consequences.\\n\\nIf the student asks both his friends and his doctors, he is able to use his judgemental skills to determing which choice will be best for him in the long run.\\n\\nFurthermore, asking for multiple opinions can benifit during competitions for a position slot, as cadidates needs to make decisions on what they need to say or do. For example, it can be helpful in situations like elections, both for the U.S. or simply in school. If a student is running for a position in office to represent his/her school, he/she can ask a widespread and diverse audience. First, asking other students is their best bet to obtaining information. Other students can inform him/her about what they want, like better water fountains, recess, or healthier food. Then, the student running can make changes to the way they run for the election, and on his/her speech, take a different approach. In addition, if the student running asks an adult, they will get to know a more realistic way the school can be improved. Since a student, even as a student officer, isn't able to make a significant change to a school, they can inform the school board about ways to make the school better. If someone is running for the president of the United States, a similar approach can be taken. First, they can ask the people, on social media or in speeches, about positive ways to reform our country. After the candidate receives the opinion of general audiences, they can campaign differently to match the view of those voting. All in all, asking for the opinion of multiple different people can set the candidate apart from others.\\n\\nMany people only ask one type of audience for their opinion. Having only one opinion can lead to negative consequences, such as making the wrong choices related to health or education, as only one audience is adressed into making a decision. Therefore, asking multiple different people who have different backgrounds is essential to making the best choices in life. Conclusively, knowing multiple opinions on a certain matter can evidently lead to better results for individuals.\\xa0\", 'offset_mapping': [(0, 6), (7, 8), (9, 14), (15, 22), (22, 23), (24, 28), (29, 32), (33, 37), (38, 43), (44, 45), (46, 51), (52, 58), (59, 64), (65, 71), (72, 74), (75, 84), (85, 94), (94, 95), (96, 98), (98, 99), (100, 104), (105, 108), (109, 113), (114, 122), (123, 126), (127, 128), (129, 133), (134, 138), (138, 139), (140, 143), (144, 147), (148, 152), (153, 156), (157, 161), (162, 169), (170, 172), (173, 180), (181, 186), (187, 196), (197, 201), (202, 204), (205, 211), (212, 213), (214, 221), (222, 229), (229, 230), (231, 233), (233, 237), (238, 241), (242, 247), (247, 249), (250, 258), (259, 261), (262, 272), (273, 283), (284, 286), (287, 289), (290, 296), (297, 300), (301, 303), (304, 314), (315, 317), (318, 325), (326, 327), (328, 335), (336, 338), (339, 348), (349, 354), (355, 362), (363, 364), (365, 370), (371, 376), (376, 377), (378, 386), (386, 387), (388, 393), (394, 401), (402, 405), (406, 412), (413, 417), (418, 424), (425, 428), (429, 434), (435, 443), (444, 450), (451, 454), (455, 457), (458, 468), (469, 472), (473, 477), (478, 484), (485, 488), (488, 489), (489, 493), (494, 503), (503, 504), (505, 509), (510, 512), (513, 523), (524, 533), (534, 536), (537, 544), (545, 553), (554, 562), (563, 566), (567, 572), (573, 580), (581, 583), (584, 588), (589, 594), (595, 600), (601, 605), (606, 613), (614, 617), (618, 622), (623, 627), (627, 629), (629, 631), (631, 634), (635, 637), (638, 641), (642, 649), (650, 658), (658, 659), (660, 667), (668, 677), (678, 684), (684, 686), (687, 694), (695, 698), (699, 701), (702, 712), (713, 715), (716, 717), (718, 725), (726, 728), (729, 739), (739, 740), (740, 741), (741, 742), (742, 747), (748, 751), (752, 760), (760, 761), (762, 763), (764, 769), (770, 777), (778, 783), (784, 787), (788, 795), (796, 801), (801, 803), (804, 812), (813, 815), (816, 823), (824, 826), (827, 831), (832, 839), (840, 842), (843, 849), (850, 853), (854, 860), (861, 868), (869, 876), (877, 879), (880, 883), (883, 890), (891, 895), (896, 903), (903, 904), (905, 906), (907, 914), (915, 918), (919, 924), (925, 927), (928, 929), (930, 932), (933, 940), (941, 945), (946, 953), (954, 956), (957, 960), (960, 961), (962, 965), (966, 969), (970, 976), (977, 982), (983, 991), (992, 998), (998, 999), (1000, 1007), (1007, 1008), (1009, 1011), (1012, 1019), (1020, 1027), (1027, 1028), (1029, 1032), (1033, 1040), (1041, 1044), (1045, 1049), (1050, 1064), (1065, 1070), (1071, 1074), (1075, 1079), (1080, 1086), (1086, 1089), (1090, 1097), (1098, 1104), (1105, 1109), (1110, 1113), (1114, 1121), (1122, 1125), (1126, 1130), (1131, 1134), (1134, 1136), (1136, 1139), (1140, 1142), (1143, 1146), (1147, 1152), (1152, 1153), (1154, 1157), (1158, 1161), (1162, 1167), (1168, 1171), (1172, 1177), (1177, 1179), (1180, 1187), (1188, 1194), (1194, 1196), (1197, 1202), (1202, 1203), (1204, 1208), (1209, 1216), (1217, 1221), (1222, 1229), (1230, 1231), (1232, 1239), (1240, 1242), (1243, 1252), (1253, 1258), (1259, 1262), (1263, 1271), (1272, 1274), (1275, 1276), (1277, 1284), (1285, 1290), (1290, 1291), (1292, 1297), (1298, 1304), (1305, 1309), (1310, 1312), (1313, 1317), (1318, 1321), (1322, 1326), (1327, 1335), (1336, 1342), (1343, 1345), (1346, 1354), (1355, 1360), (1361, 1363), (1364, 1367), (1368, 1372), (1373, 1382), (1383, 1387), (1388, 1392), (1393, 1396), (1396, 1397), (1398, 1405), (1405, 1408), (1408, 1409), (1410, 1411), (1412, 1419), (1420, 1423), (1424, 1426), (1427, 1431), (1432, 1436), (1437, 1440), (1441, 1447), (1448, 1458), (1459, 1463), (1464, 1471), (1472, 1474), (1475, 1478), (1478, 1479), (1480, 1486), (1486, 1487), (1488, 1491), (1492, 1497), (1498, 1502), (1503, 1508), (1508, 1509), (1510, 1517), (1517, 1518), (1519, 1521), (1522, 1525), (1526, 1533), (1534, 1538), (1539, 1540), (1541, 1546), (1547, 1553), (1553, 1554), (1555, 1559), (1560, 1564), (1565, 1567), (1568, 1576), (1577, 1588), (1588, 1589), (1590, 1591), (1592, 1598), (1599, 1603), (1604, 1608), (1609, 1615), (1616, 1620), (1621, 1625), (1626, 1630), (1631, 1638), (1638, 1639), (1640, 1648), (1649, 1656), (1657, 1665), (1666, 1668), (1669, 1674), (1674, 1675), (1676, 1679), (1680, 1684), (1685, 1687), (1688, 1695), (1696, 1700), (1701, 1705), (1706, 1718), (1718, 1719), (1719, 1720), (1720, 1721), (1721, 1723), (1724, 1727), (1728, 1735), (1736, 1740), (1741, 1745), (1746, 1749), (1750, 1757), (1758, 1761), (1762, 1765), (1766, 1773), (1773, 1774), (1775, 1777), (1778, 1780), (1781, 1785), (1786, 1788), (1789, 1792), (1793, 1796), (1797, 1806), (1806, 1808), (1809, 1815), (1816, 1818), (1819, 1824), (1824, 1828), (1829, 1834), (1835, 1841), (1842, 1846), (1847, 1849), (1850, 1854), (1855, 1858), (1859, 1862), (1863, 1865), (1866, 1869), (1870, 1874), (1875, 1878), (1878, 1879), (1879, 1880), (1880, 1881), (1881, 1892), (1892, 1893), (1894, 1900), (1901, 1904), (1905, 1913), (1914, 1922), (1923, 1926), (1927, 1930), (1930, 1932), (1932, 1934), (1935, 1941), (1942, 1954), (1955, 1958), (1959, 1960), (1961, 1969), (1970, 1974), (1974, 1975), (1976, 1978), (1979, 1982), (1982, 1988), (1989, 1994), (1995, 1997), (1998, 2002), (2003, 2012), (2013, 2015), (2016, 2020), (2021, 2025), (2026, 2030), (2031, 2033), (2034, 2037), (2038, 2040), (2041, 2043), (2043, 2044), (2045, 2048), (2049, 2056), (2056, 2057), (2058, 2060), (2061, 2064), (2065, 2067), (2068, 2075), (2076, 2078), (2079, 2089), (2090, 2094), (2095, 2104), (2104, 2105), (2106, 2110), (2111, 2114), (2115, 2118), (2119, 2120), (2120, 2121), (2121, 2122), (2122, 2123), (2124, 2126), (2127, 2133), (2134, 2136), (2137, 2143), (2143, 2144), (2145, 2147), (2148, 2149), (2150, 2157), (2158, 2160), (2161, 2168), (2169, 2172), (2173, 2174), (2175, 2183), (2184, 2186), (2187, 2193), (2194, 2196), (2197, 2206), (2207, 2210), (2210, 2211), (2211, 2214), (2215, 2221), (2221, 2222), (2223, 2225), (2225, 2226), (2226, 2229), (2230, 2233), (2234, 2237), (2238, 2239), (2240, 2250), (2251, 2254), (2255, 2262), (2263, 2271), (2271, 2272), (2273, 2278), (2278, 2279), (2280, 2286), (2287, 2292), (2293, 2301), (2302, 2304), (2305, 2310), (2311, 2315), (2316, 2319), (2320, 2322), (2323, 2332), (2333, 2344), (2344, 2345), (2346, 2351), (2352, 2360), (2361, 2364), (2365, 2371), (2372, 2375), (2375, 2376), (2376, 2379), (2380, 2385), (2386, 2390), (2391, 2395), (2396, 2400), (2400, 2401), (2402, 2406), (2407, 2413), (2414, 2419), (2420, 2421), (2421, 2425), (2425, 2429), (2429, 2430), (2431, 2437), (2437, 2438), (2439, 2441), (2442, 2451), (2452, 2456), (2456, 2457), (2458, 2462), (2462, 2463), (2464, 2467), (2468, 2475), (2476, 2483), (2484, 2487), (2488, 2492), (2493, 2500), (2501, 2503), (2504, 2507), (2508, 2511), (2512, 2516), (2517, 2520), (2521, 2524), (2525, 2528), (2529, 2537), (2537, 2538), (2539, 2542), (2543, 2545), (2546, 2549), (2549, 2550), (2550, 2553), (2554, 2560), (2560, 2561), (2562, 2566), (2567, 2568), (2569, 2578), (2579, 2587), (2587, 2588), (2589, 2591), (2592, 2600), (2600, 2601), (2602, 2604), (2605, 2608), (2609, 2616), (2617, 2624), (2625, 2629), (2630, 2632), (2633, 2638), (2638, 2639), (2640, 2644), (2645, 2649), (2650, 2653), (2654, 2656), (2657, 2661), (2662, 2663), (2664, 2668), (2669, 2678), (2679, 2682), (2683, 2686), (2687, 2693), (2694, 2697), (2698, 2700), (2701, 2709), (2709, 2710), (2711, 2716), (2717, 2718), (2719, 2726), (2726, 2727), (2728, 2732), (2733, 2735), (2736, 2737), (2738, 2745), (2746, 2753), (2753, 2754), (2755, 2758), (2758, 2760), (2761, 2765), (2766, 2768), (2769, 2773), (2774, 2775), (2776, 2787), (2788, 2794), (2795, 2797), (2798, 2799), (2800, 2806), (2806, 2807), (2808, 2812), (2813, 2816), (2817, 2823), (2824, 2827), (2828, 2834), (2835, 2840), (2841, 2846), (2847, 2851), (2852, 2854), (2855, 2859), (2860, 2863), (2864, 2870), (2871, 2877), (2877, 2878), (2879, 2881), (2882, 2889), (2890, 2892), (2893, 2900), (2901, 2904), (2905, 2908), (2909, 2918), (2919, 2921), (2922, 2925), (2926, 2932), (2933, 2939), (2939, 2940), (2941, 2942), (2943, 2950), (2951, 2959), (2960, 2963), (2964, 2966), (2967, 2972), (2972, 2973), (2974, 2979), (2979, 2980), (2981, 2985), (2986, 2989), (2990, 2993), (2994, 2997), (2998, 3004), (3004, 3005), (3006, 3008), (3009, 3015), (3016, 3021), (3022, 3024), (3025, 3027), (3028, 3036), (3036, 3037), (3038, 3043), (3044, 3052), (3053, 3057), (3058, 3060), (3061, 3067), (3068, 3071), (3072, 3079), (3079, 3080), (3081, 3086), (3087, 3090), (3091, 3100), (3101, 3109), (3110, 3113), (3114, 3121), (3122, 3124), (3125, 3132), (3133, 3142), (3142, 3143), (3144, 3148), (3149, 3152), (3153, 3161), (3162, 3173), (3174, 3176), (3177, 3182), (3183, 3186), (3187, 3191), (3192, 3194), (3195, 3200), (3201, 3207), (3207, 3208), (3209, 3212), (3213, 3215), (3216, 3219), (3219, 3220), (3221, 3227), (3228, 3231), (3232, 3235), (3236, 3243), (3244, 3246), (3247, 3255), (3256, 3265), (3266, 3272), (3273, 3276), (3277, 3280), (3281, 3284), (3285, 3294), (3295, 3300), (3301, 3305), (3306, 3312), (3312, 3313), (3313, 3314), (3314, 3315), (3315, 3319), (3320, 3326), (3327, 3331), (3332, 3335), (3336, 3339), (3340, 3344), (3345, 3347), (3348, 3356), (3357, 3360), (3361, 3366), (3367, 3374), (3374, 3375), (3376, 3382), (3383, 3387), (3388, 3391), (3392, 3399), (3400, 3403), (3404, 3408), (3409, 3411), (3412, 3420), (3421, 3433), (3433, 3434), (3435, 3439), (3440, 3442), (3443, 3449), (3450, 3453), (3454, 3459), (3460, 3467), (3468, 3475), (3476, 3478), (3479, 3485), (3486, 3488), (3489, 3498), (3498, 3499), (3500, 3502), (3503, 3507), (3508, 3511), (3512, 3520), (3521, 3523), (3524, 3526), (3526, 3532), (3533, 3537), (3538, 3544), (3545, 3546), (3547, 3555), (3555, 3556), (3557, 3566), (3566, 3567), (3568, 3574), (3575, 3583), (3584, 3593), (3594, 3600), (3601, 3604), (3605, 3609), (3610, 3619), (3620, 3631), (3632, 3634), (3635, 3644), (3645, 3647), (3648, 3654), (3655, 3658), (3659, 3663), (3664, 3671), (3672, 3674), (3675, 3679), (3679, 3680), (3681, 3684), (3684, 3693), (3693, 3694), (3695, 3702), (3703, 3711), (3712, 3720), (3721, 3723), (3724, 3725), (3726, 3733), (3734, 3740), (3741, 3744), (3745, 3754), (3755, 3759), (3760, 3762), (3763, 3769), (3770, 3777), (3778, 3781), (3782, 3793), (3793, 3794), (3794, 3795)], 'preds': ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'B-Position', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Evidence', 'I-Lead', 'I-Lead', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Lead', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'B-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'O', 'O', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence'], 'pred_scores': [0.498046875, 0.4970703125, 0.49658203125, 0.4970703125, 0.496826171875, 0.498046875, 0.49755859375, 0.498046875, 0.498046875, 0.498046875, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.497802734375, 0.4970703125, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.4970703125, 0.49755859375, 0.49755859375, 0.49755859375, 0.49853515625, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.4970703125, 0.4970703125, 0.49755859375, 0.49755859375, 0.49755859375, 0.49658203125, 0.49609375, 0.3115234375, 0.255859375, 0.25, 0.24853515625, 0.2459716796875, 0.25537109375, 0.255859375, 0.26318359375, 0.242431640625, 0.24462890625, 0.241943359375, 0.2315673828125, 0.241943359375, 0.2412109375, 0.236572265625, 0.23681640625, 0.236572265625, 0.2802734375, 0.242431640625, 0.236572265625, 0.239990234375, 0.2315673828125, 0.2384033203125, 0.238037109375, 0.238525390625, 0.24365234375, 0.247802734375, 0.1959228515625, 0.25048828125, 0.26220703125, 0.2349853515625, 0.223876953125, 0.22900390625, 0.2301025390625, 0.2291259765625, 0.2301025390625, 0.2310791015625, 0.234130859375, 0.2347412109375, 0.228515625, 0.226806640625, 0.2318115234375, 0.2303466796875, 0.2352294921875, 0.2327880859375, 0.2303466796875, 0.22802734375, 0.232421875, 0.2322998046875, 0.2646484375, 0.189453125, 0.1422119140625, 0.13330078125, 0.1361083984375, 0.1368408203125, 0.1712646484375, 0.1834716796875, 0.190185546875, 0.19921875, 0.2056884765625, 0.20263671875, 0.208984375, 0.2095947265625, 0.200439453125, 0.20556640625, 0.20263671875, 0.20263671875, 0.1756591796875, 0.19970703125, 0.1982421875, 0.196044921875, 0.19873046875, 0.204345703125, 0.197021484375, 0.191162109375, 0.194580078125, 0.190673828125, 0.1590576171875, 0.287109375, 0.2384033203125, 0.25439453125, 0.23828125, 0.261474609375, 0.261962890625, 0.26220703125, 0.28271484375, 0.2734375, 0.25830078125, 0.26513671875, 0.261962890625, 0.276611328125, 0.2449951171875, 0.498046875, 0.496337890625, 0.2137451171875, 0.257568359375, 0.253173828125, 0.261962890625, 0.3134765625, 0.39208984375, 0.39111328125, 0.39013671875, 0.380859375, 0.380859375, 0.37353515625, 0.38232421875, 0.38134765625, 0.368896484375, 0.361328125, 0.39697265625, 0.3896484375, 0.42578125, 0.42333984375, 0.424072265625, 0.39501953125, 0.41552734375, 0.41064453125, 0.412841796875, 0.412353515625, 0.412353515625, 0.4091796875, 0.41357421875, 0.412841796875, 0.4169921875, 0.32958984375, 0.49267578125, 0.494873046875, 0.49560546875, 0.49560546875, 0.494140625, 0.4951171875, 0.495849609375, 0.496337890625, 0.49560546875, 0.49609375, 0.495849609375, 0.49462890625, 0.495849609375, 0.49609375, 0.49609375, 0.49609375, 0.49560546875, 0.495361328125, 0.49267578125, 0.49267578125, 0.494140625, 0.495361328125, 0.4951171875, 0.494873046875, 0.4951171875, 0.495849609375, 0.494873046875, 0.49560546875, 0.49560546875, 0.494140625, 0.4951171875, 0.494873046875, 0.49560546875, 0.494140625, 0.4951171875, 0.494140625, 0.494140625, 0.4951171875, 0.49462890625, 0.494140625, 0.49267578125, 0.4951171875, 0.49365234375, 0.494140625, 0.494140625, 0.49462890625, 0.492431640625, 0.494140625, 0.47607421875, 0.494384765625, 0.49267578125, 0.494873046875, 0.4951171875, 0.49462890625, 0.49560546875, 0.495361328125, 0.495361328125, 0.4951171875, 0.491943359375, 0.46484375, 0.3662109375, 0.327880859375, 0.336181640625, 0.2978515625, 0.30859375, 0.284423828125, 0.28125, 0.27734375, 0.2802734375, 0.275634765625, 0.27978515625, 0.27734375, 0.28564453125, 0.2822265625, 0.288818359375, 0.43408203125, 0.280517578125, 0.2734375, 0.27001953125, 0.268798828125, 0.265380859375, 0.257568359375, 0.26416015625, 0.266845703125, 0.26708984375, 0.263916015625, 0.26611328125, 0.26416015625, 0.269287109375, 0.274658203125, 0.28173828125, 0.27783203125, 0.272705078125, 0.279296875, 0.274658203125, 0.30322265625, 0.42822265625, 0.43896484375, 0.444580078125, 0.46875, 0.46728515625, 0.467041015625, 0.471435546875, 0.474365234375, 0.4765625, 0.46728515625, 0.475341796875, 0.472900390625, 0.47607421875, 0.47265625, 0.47802734375, 0.478515625, 0.4775390625, 0.475830078125, 0.47412109375, 0.4775390625, 0.47705078125, 0.47607421875, 0.476318359375, 0.44970703125, 0.4638671875, 0.458984375, 0.4658203125, 0.456787109375, 0.4609375, 0.4609375, 0.461181640625, 0.46240234375, 0.4609375, 0.458251953125, 0.45849609375, 0.46142578125, 0.4599609375, 0.462890625, 0.46240234375, 0.463134765625, 0.458251953125, 0.45947265625, 0.45556640625, 0.4609375, 0.46240234375, 0.45849609375, 0.460205078125, 0.45947265625, 0.46484375, 0.45947265625, 0.4697265625, 0.47119140625, 0.464111328125, 0.46728515625, 0.47119140625, 0.4609375, 0.46044921875, 0.463134765625, 0.460205078125, 0.46337890625, 0.462646484375, 0.4658203125, 0.46923828125, 0.45703125, 0.2802734375, 0.256591796875, 0.265625, 0.2313232421875, 0.2425537109375, 0.2393798828125, 0.257080078125, 0.27001953125, 0.265380859375, 0.276611328125, 0.27783203125, 0.26611328125, 0.2685546875, 0.26220703125, 0.28076171875, 0.298095703125, 0.29736328125, 0.306396484375, 0.303466796875, 0.302734375, 0.30712890625, 0.31103515625, 0.312744140625, 0.30859375, 0.310302734375, 0.30859375, 0.298583984375, 0.302734375, 0.30078125, 0.301513671875, 0.29833984375, 0.30322265625, 0.3056640625, 0.29541015625, 0.302001953125, 0.298828125, 0.2281494140625, 0.49755859375, 0.496826171875, 0.4072265625, 0.3798828125, 0.303466796875, 0.441162109375, 0.446533203125, 0.443603515625, 0.453857421875, 0.45263671875, 0.44873046875, 0.45166015625, 0.44921875, 0.450439453125, 0.44775390625, 0.44677734375, 0.44775390625, 0.45068359375, 0.4287109375, 0.349365234375, 0.42626953125, 0.42431640625, 0.416015625, 0.412109375, 0.40966796875, 0.408935546875, 0.41162109375, 0.412109375, 0.411865234375, 0.411865234375, 0.41259765625, 0.41796875, 0.415283203125, 0.416015625, 0.2646484375, 0.3427734375, 0.47998046875, 0.483154296875, 0.48486328125, 0.492919921875, 0.4931640625, 0.494140625, 0.493408203125, 0.493408203125, 0.49365234375, 0.49365234375, 0.4931640625, 0.4931640625, 0.494140625, 0.494140625, 0.493896484375, 0.46142578125, 0.49365234375, 0.49169921875, 0.49560546875, 0.49462890625, 0.494384765625, 0.49462890625, 0.4921875, 0.47998046875, 0.49853515625, 0.498291015625, 0.49853515625, 0.4990234375, 0.4990234375, 0.49853515625, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.498046875, 0.496826171875, 0.4990234375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.498046875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.49951171875, 0.499755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.488037109375, 0.49951171875, 0.49951171875, 0.499755859375, 0.4873046875, 0.49853515625, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.4951171875, 0.49951171875, 0.499755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.4892578125, 0.49951171875, 0.49951171875, 0.499755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.47705078125, 0.49658203125, 0.49853515625, 0.4990234375, 0.4990234375, 0.49951171875, 0.499267578125, 0.49951171875, 0.499267578125, 0.49951171875, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.49951171875, 0.49951171875, 0.499267578125, 0.499267578125, 0.499267578125, 0.4990234375, 0.49755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.4951171875, 0.497802734375, 0.499267578125, 0.499267578125, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.496337890625, 0.499267578125, 0.49951171875, 0.499267578125, 0.499267578125, 0.49951171875, 0.499267578125, 0.499267578125, 0.499267578125, 0.49951171875, 0.4990234375, 0.498046875, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.499267578125, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49365234375, 0.4619140625, 0.460693359375, 0.454833984375, 0.46484375, 0.455078125, 0.4443359375, 0.448486328125, 0.4453125, 0.4462890625, 0.45361328125, 0.445556640625, 0.442626953125, 0.448974609375, 0.441162109375, 0.4365234375, 0.4404296875, 0.443115234375, 0.445068359375, 0.437255859375, 0.443603515625, 0.496337890625, 0.497314453125, 0.49072265625, 0.49609375, 0.495849609375, 0.49609375, 0.49609375, 0.49609375, 0.49658203125, 0.496337890625, 0.49609375, 0.49658203125, 0.49609375, 0.49560546875, 0.493896484375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.4970703125, 0.497314453125, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49169921875, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.497314453125, 0.49755859375, 0.497314453125, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.495849609375, 0.484375, 0.494873046875, 0.4951171875, 0.49365234375, 0.4931640625, 0.4931640625, 0.492431640625, 0.492431640625, 0.4921875, 0.492431640625, 0.491943359375, 0.491943359375, 0.49267578125, 0.492431640625, 0.4697265625, 0.492431640625, 0.492919921875, 0.492431640625, 0.492431640625, 0.490234375, 0.45556640625, 0.439208984375, 0.456787109375, 0.483154296875, 0.48974609375, 0.489501953125, 0.4892578125, 0.4892578125, 0.488525390625, 0.48681640625, 0.48779296875, 0.4853515625, 0.486572265625, 0.486328125, 0.486328125, 0.48583984375, 0.4853515625, 0.484130859375, 0.46875, 0.5, 0.49951171875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875]}, {'id': 'D72CB1C11673', 'input_ids': [31845, 5717, 11, 301, 64, 28, 182, 1202, 4, 1806, 747, 1394, 13, 2949, 77, 51, 64, 45, 2845, 15, 65, 631, 4, 85, 18, 460, 205, 7, 1394, 643, 13, 49, 2949, 77, 442, 10, 2031, 4, 520, 47, 33, 1533, 5086, 47, 33, 5, 1460, 7, 146, 5, 275, 2031, 13, 2512, 4, 9402, 1533, 5086, 64, 244, 10, 621, 146, 10, 357, 2031, 142, 24, 64, 7280, 3992, 1389, 6, 10, 372, 778, 7, 1532, 402, 92, 6, 64, 28, 182, 7163, 8, 10142, 4, 50118, 50118, 3972, 1642, 19, 6, 9402, 335, 31, 55, 87, 65, 621, 64, 7280, 3992, 1389, 4, 520, 442, 10, 568, 89, 16, 10, 778, 14, 47, 64, 555, 182, 5882, 8, 13203, 4, 8374, 5882, 64, 1303, 10, 621, 7, 492, 62, 15, 99, 51, 32, 608, 4, 5365, 1533, 5086, 31, 82, 64, 146, 8348, 41, 1973, 540, 1202, 8, 55, 3013, 4, 20, 335, 14, 47, 1325, 31, 643, 189, 33, 10, 780, 3099, 11, 5, 499, 4, 1944, 16592, 2979, 64, 146, 10, 621, 619, 3230, 11, 442, 5, 235, 2031, 4, 50118, 50118, 1779, 47, 1394, 97, 82, 13, 49, 2979, 47, 64, 67, 1532, 171, 92, 383, 4, 7632, 16, 430, 8, 189, 33, 55, 676, 87, 47, 4, 9402, 97, 16592, 2979, 64, 1303, 47, 7, 2364, 10, 92, 6707, 50, 8567, 4, 286, 1246, 6, 103, 6909, 2949, 115, 6396, 47, 141, 7, 109, 402, 5, 4577, 169, 4, 1876, 82, 32, 182, 430, 8, 33, 676, 430, 383, 11, 301, 4, 9402, 2949, 31, 643, 64, 6396, 47, 10, 319, 4, 166, 70, 1532, 31, 84, 6160, 11, 301, 6, 30, 3565, 110, 375, 3734, 47, 189, 2097, 951, 1493, 31, 442, 5, 276, 5021, 4, 50118, 50118, 14696, 25558, 643, 2979, 64, 28, 182, 7163, 8, 10142, 4, 10883, 97, 16592, 2949, 8, 608, 99, 51, 224, 189, 483, 7, 10, 372, 4258, 4, 520, 47, 1325, 97, 5086, 549, 51, 32, 205, 50, 1099, 47, 40, 28, 441, 7, 356, 23, 106, 31, 10, 430, 477, 9, 1217, 4, 286, 1246, 6, 520, 10, 333, 9, 82, 492, 47, 2949, 15, 2512, 6, 47, 172, 216, 141, 51, 356, 23, 47, 25, 10, 621, 4, 7632, 1326, 23, 1402, 383, 31, 10, 430, 12429, 4, 1336, 951, 1493, 1326, 23, 24, 189, 28, 141, 63, 3518, 7, 28, 5915, 11, 301, 4, 50118, 50118, 1121, 6427, 6, 370, 64, 1532, 31, 643, 3734, 30, 1818, 5, 2949, 14, 951, 492, 47, 4, 11102, 2390, 64, 1303, 3992, 15, 10, 621, 4, 8136, 1295, 7, 103, 6909, 2949, 189, 723, 110, 1403, 12, 29704, 142, 47, 117, 1181, 619, 314, 66, 4, 12738, 643, 13, 2949, 77, 442, 10, 1202, 568, 4, 520, 47, 2639, 643, 2979, 55, 1616, 32, 577, 21016, 2512, 4, 50141], 'text': \"Making choices in life can be very difficult. People often ask for advice when they can not decide on one thing. It's always good to ask others for their advice when making a choice. When you have multiple opinions you have the ability to make the best choice for yourself. Seeking multiple opinions can help a person make a better choice because it can decrease stress levels, a great chance to learn something new, can be very helpful and beneficial.\\n\\nTo begin with, Seeking information from more than one person can decrease stress levels. When making a decision there is a chance that you can become very stressed and overwhelmed. Being stressed can cause a person to give up on what they are doing. Having multiple opinions from people can make choosing an option less difficult and more easier. The information that you receive from others may have a special meaning in the future. Other peoples opinion can make a person feel confident in making the right choice.\\n\\nWhen you ask other people for their opinion you can also learn many new things. Everyone is different and may have more experience than you. Seeking other peoples opinion can cause you to gain a new skill or lesson. For example, someones advice could teach you how to do something the correct way. Many people are very different and have experience different things in life. Seeking advice from others can teach you a lot. We all learn from our mistakes in life, by sharing your past experiences you may prevent someone else from making the same mistake.\\n\\nSeeking others opinion can be very helpful and beneficial. Taking other peoples advice and doing what they say may lead to a great outcome. When you receive other opinions whether they are good or bad you will be able to look at them from a different point of view. For example, When a group of people give you advice on yourself, you then know how they look at you as a person. Everyone looks at certain things from a different prospective. How someone else looks at it may be how its supposed to be viewed in life.\\n\\nIn conclusion, You can learn from others experiences by seeking the advice that someone give you. Making decisions can cause stress on a person. Relating to someones advice may higher your self-esteem because you no longer feel left out. Ask others for advice when making a difficult decision. When you seek others opinion more opportunities are available fro yourself.\\xa0\", 'offset_mapping': [(0, 6), (7, 14), (15, 17), (18, 22), (23, 26), (27, 29), (30, 34), (35, 44), (44, 45), (46, 52), (53, 58), (59, 62), (63, 66), (67, 73), (74, 78), (79, 83), (84, 87), (88, 91), (92, 98), (99, 101), (102, 105), (106, 111), (111, 112), (113, 115), (115, 117), (118, 124), (125, 129), (130, 132), (133, 136), (137, 143), (144, 147), (148, 153), (154, 160), (161, 165), (166, 172), (173, 174), (175, 181), (181, 182), (183, 187), (188, 191), (192, 196), (197, 205), (206, 214), (215, 218), (219, 223), (224, 227), (228, 235), (236, 238), (239, 243), (244, 247), (248, 252), (253, 259), (260, 263), (264, 272), (272, 273), (274, 281), (282, 290), (291, 299), (300, 303), (304, 308), (309, 310), (311, 317), (318, 322), (323, 324), (325, 331), (332, 338), (339, 346), (347, 349), (350, 353), (354, 362), (363, 369), (370, 376), (376, 377), (378, 379), (380, 385), (386, 392), (393, 395), (396, 401), (402, 411), (412, 415), (415, 416), (417, 420), (421, 423), (424, 428), (429, 436), (437, 440), (441, 451), (451, 452), (452, 453), (453, 454), (454, 456), (457, 462), (463, 467), (467, 468), (469, 476), (477, 488), (489, 493), (494, 498), (499, 503), (504, 507), (508, 514), (515, 518), (519, 527), (528, 534), (535, 541), (541, 542), (543, 547), (548, 554), (555, 556), (557, 565), (566, 571), (572, 574), (575, 576), (577, 583), (584, 588), (589, 592), (593, 596), (597, 603), (604, 608), (609, 617), (618, 621), (622, 633), (633, 634), (635, 640), (641, 649), (650, 653), (654, 659), (660, 661), (662, 668), (669, 671), (672, 676), (677, 679), (680, 682), (683, 687), (688, 692), (693, 696), (697, 702), (702, 703), (704, 710), (711, 719), (720, 728), (729, 733), (734, 740), (741, 744), (745, 749), (750, 758), (759, 761), (762, 768), (769, 773), (774, 783), (784, 787), (788, 792), (793, 799), (799, 800), (801, 804), (805, 816), (817, 821), (822, 825), (826, 833), (834, 838), (839, 845), (846, 849), (850, 854), (855, 856), (857, 864), (865, 872), (873, 875), (876, 879), (880, 886), (886, 887), (888, 893), (894, 901), (902, 909), (910, 913), (914, 918), (919, 920), (921, 927), (928, 932), (933, 942), (943, 945), (946, 952), (953, 956), (957, 962), (963, 969), (969, 970), (970, 971), (971, 972), (972, 976), (977, 980), (981, 984), (985, 990), (991, 997), (998, 1001), (1002, 1007), (1008, 1015), (1016, 1019), (1020, 1023), (1024, 1028), (1029, 1034), (1035, 1039), (1040, 1043), (1044, 1050), (1050, 1051), (1052, 1060), (1061, 1063), (1064, 1073), (1074, 1077), (1078, 1081), (1082, 1086), (1087, 1091), (1092, 1102), (1103, 1107), (1108, 1111), (1111, 1112), (1113, 1120), (1121, 1126), (1127, 1134), (1135, 1142), (1143, 1146), (1147, 1152), (1153, 1156), (1157, 1159), (1160, 1164), (1165, 1166), (1167, 1170), (1171, 1176), (1177, 1179), (1180, 1186), (1186, 1187), (1188, 1191), (1192, 1199), (1199, 1200), (1201, 1205), (1205, 1209), (1210, 1216), (1217, 1222), (1223, 1228), (1229, 1232), (1233, 1236), (1237, 1239), (1240, 1242), (1243, 1252), (1253, 1256), (1257, 1264), (1265, 1268), (1268, 1269), (1270, 1274), (1275, 1281), (1282, 1285), (1286, 1290), (1291, 1300), (1301, 1304), (1305, 1309), (1310, 1320), (1321, 1330), (1331, 1337), (1338, 1340), (1341, 1345), (1345, 1346), (1347, 1354), (1355, 1361), (1362, 1366), (1367, 1373), (1374, 1377), (1378, 1383), (1384, 1387), (1388, 1389), (1390, 1393), (1393, 1394), (1395, 1397), (1398, 1401), (1402, 1407), (1408, 1412), (1413, 1416), (1417, 1425), (1426, 1428), (1429, 1433), (1433, 1434), (1435, 1437), (1438, 1445), (1446, 1450), (1451, 1455), (1456, 1467), (1468, 1471), (1472, 1475), (1476, 1483), (1484, 1491), (1492, 1496), (1497, 1501), (1502, 1508), (1509, 1512), (1513, 1517), (1518, 1525), (1525, 1526), (1526, 1527), (1527, 1528), (1528, 1530), (1530, 1535), (1536, 1542), (1543, 1550), (1551, 1554), (1555, 1557), (1558, 1562), (1563, 1570), (1571, 1574), (1575, 1585), (1585, 1586), (1587, 1593), (1594, 1599), (1600, 1607), (1608, 1614), (1615, 1618), (1619, 1624), (1625, 1629), (1630, 1634), (1635, 1638), (1639, 1642), (1643, 1647), (1648, 1650), (1651, 1652), (1653, 1658), (1659, 1666), (1666, 1667), (1668, 1672), (1673, 1676), (1677, 1684), (1685, 1690), (1691, 1699), (1700, 1707), (1708, 1712), (1713, 1716), (1717, 1721), (1722, 1724), (1725, 1728), (1729, 1732), (1733, 1737), (1738, 1740), (1741, 1745), (1746, 1748), (1749, 1753), (1754, 1756), (1757, 1761), (1762, 1766), (1767, 1768), (1769, 1778), (1779, 1784), (1785, 1787), (1788, 1792), (1792, 1793), (1794, 1797), (1798, 1805), (1805, 1806), (1807, 1811), (1812, 1813), (1814, 1819), (1820, 1822), (1823, 1829), (1830, 1834), (1835, 1838), (1839, 1845), (1846, 1848), (1849, 1857), (1857, 1858), (1859, 1862), (1863, 1867), (1868, 1872), (1873, 1876), (1877, 1881), (1882, 1886), (1887, 1889), (1890, 1893), (1894, 1896), (1897, 1898), (1899, 1905), (1905, 1906), (1907, 1915), (1916, 1921), (1922, 1924), (1925, 1932), (1933, 1939), (1940, 1944), (1945, 1946), (1947, 1956), (1957, 1968), (1968, 1969), (1970, 1973), (1974, 1981), (1982, 1986), (1987, 1992), (1993, 1995), (1996, 1998), (1999, 2002), (2003, 2005), (2006, 2009), (2010, 2013), (2014, 2022), (2023, 2025), (2026, 2028), (2029, 2035), (2036, 2038), (2039, 2043), (2043, 2044), (2044, 2045), (2045, 2046), (2046, 2048), (2049, 2059), (2059, 2060), (2061, 2064), (2065, 2068), (2069, 2074), (2075, 2079), (2080, 2086), (2087, 2098), (2099, 2101), (2102, 2109), (2110, 2113), (2114, 2120), (2121, 2125), (2126, 2133), (2134, 2138), (2139, 2142), (2142, 2143), (2144, 2150), (2151, 2160), (2161, 2164), (2165, 2170), (2171, 2177), (2178, 2180), (2181, 2182), (2183, 2189), (2189, 2190), (2191, 2194), (2194, 2199), (2200, 2202), (2203, 2207), (2207, 2211), (2212, 2218), (2219, 2222), (2223, 2229), (2230, 2234), (2235, 2239), (2239, 2240), (2240, 2246), (2247, 2254), (2255, 2258), (2259, 2261), (2262, 2268), (2269, 2273), (2274, 2278), (2279, 2282), (2282, 2283), (2284, 2287), (2288, 2294), (2295, 2298), (2299, 2305), (2306, 2310), (2311, 2317), (2318, 2319), (2320, 2329), (2330, 2338), (2338, 2339), (2340, 2344), (2345, 2348), (2349, 2353), (2354, 2360), (2361, 2368), (2369, 2373), (2374, 2387), (2388, 2391), (2392, 2401), (2402, 2405), (2406, 2414), (2414, 2415), (2415, 2416)], 'preds': ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'B-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'O', 'O', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence'], 'pred_scores': [0.495361328125, 0.48779296875, 0.489501953125, 0.489990234375, 0.48974609375, 0.490234375, 0.49072265625, 0.490234375, 0.4833984375, 0.4853515625, 0.485107421875, 0.485595703125, 0.48486328125, 0.482421875, 0.484375, 0.484375, 0.48486328125, 0.48486328125, 0.4853515625, 0.482177734375, 0.487060546875, 0.483154296875, 0.416259765625, 0.34423828125, 0.341064453125, 0.336669921875, 0.33544921875, 0.335205078125, 0.318603515625, 0.3115234375, 0.316162109375, 0.31689453125, 0.3251953125, 0.320068359375, 0.34033203125, 0.330078125, 0.33447265625, 0.29736328125, 0.269287109375, 0.36474609375, 0.3720703125, 0.36669921875, 0.363037109375, 0.3740234375, 0.362548828125, 0.331787109375, 0.347412109375, 0.357666015625, 0.36181640625, 0.3408203125, 0.357421875, 0.3642578125, 0.361572265625, 0.3583984375, 0.35888671875, 0.326416015625, 0.421142578125, 0.42724609375, 0.43798828125, 0.44140625, 0.4404296875, 0.44580078125, 0.441162109375, 0.435546875, 0.438232421875, 0.4140625, 0.428955078125, 0.4384765625, 0.494384765625, 0.49658203125, 0.498046875, 0.49755859375, 0.41650390625, 0.48828125, 0.49658203125, 0.498046875, 0.498046875, 0.498046875, 0.498046875, 0.497314453125, 0.36376953125, 0.487060546875, 0.49462890625, 0.4970703125, 0.49609375, 0.418212890625, 0.393310546875, 0.40869140625, 0.5, 0.5, 0.48095703125, 0.462646484375, 0.45361328125, 0.460205078125, 0.302001953125, 0.3203125, 0.32763671875, 0.3203125, 0.323974609375, 0.328857421875, 0.330322265625, 0.313232421875, 0.303955078125, 0.284912109375, 0.300048828125, 0.3125, 0.492431640625, 0.49609375, 0.496337890625, 0.49609375, 0.49658203125, 0.496337890625, 0.4599609375, 0.49658203125, 0.49658203125, 0.496337890625, 0.49658203125, 0.49658203125, 0.49658203125, 0.496337890625, 0.49658203125, 0.49658203125, 0.498046875, 0.49560546875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.498046875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.49853515625, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.4912109375, 0.499267578125, 0.4990234375, 0.498046875, 0.498779296875, 0.498779296875, 0.498779296875, 0.498779296875, 0.498779296875, 0.49853515625, 0.498779296875, 0.498779296875, 0.49853515625, 0.498779296875, 0.49853515625, 0.498779296875, 0.498779296875, 0.49755859375, 0.5, 0.5, 0.425048828125, 0.36083984375, 0.36962890625, 0.37353515625, 0.3681640625, 0.366943359375, 0.36279296875, 0.359130859375, 0.344970703125, 0.3232421875, 0.339111328125, 0.306640625, 0.31689453125, 0.31201171875, 0.3203125, 0.32763671875, 0.4921875, 0.4931640625, 0.49560546875, 0.4951171875, 0.494873046875, 0.49560546875, 0.49560546875, 0.496337890625, 0.4951171875, 0.495361328125, 0.4951171875, 0.4970703125, 0.4990234375, 0.4990234375, 0.499267578125, 0.4990234375, 0.499267578125, 0.499267578125, 0.4990234375, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.49951171875, 0.49951171875, 0.47705078125, 0.49853515625, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.499755859375, 0.499267578125, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.499755859375, 0.49951171875, 0.4990234375, 0.49951171875, 0.499267578125, 0.499267578125, 0.499267578125, 0.49951171875, 0.499267578125, 0.499267578125, 0.499267578125, 0.47607421875, 0.498779296875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.5, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.499267578125, 0.499267578125, 0.49951171875, 0.499267578125, 0.49951171875, 0.499267578125, 0.49853515625, 0.5, 0.5, 0.394775390625, 0.38330078125, 0.36279296875, 0.360107421875, 0.3525390625, 0.3525390625, 0.34765625, 0.35302734375, 0.35595703125, 0.355712890625, 0.35302734375, 0.48486328125, 0.49609375, 0.49609375, 0.49658203125, 0.49658203125, 0.496826171875, 0.4970703125, 0.49755859375, 0.49755859375, 0.4970703125, 0.49755859375, 0.4970703125, 0.49755859375, 0.497314453125, 0.4970703125, 0.4970703125, 0.4951171875, 0.4970703125, 0.4970703125, 0.49755859375, 0.4970703125, 0.497314453125, 0.4970703125, 0.4970703125, 0.49755859375, 0.4970703125, 0.4970703125, 0.4970703125, 0.4970703125, 0.496826171875, 0.496826171875, 0.4970703125, 0.4970703125, 0.4970703125, 0.4970703125, 0.4970703125, 0.496826171875, 0.496826171875, 0.496826171875, 0.496826171875, 0.496826171875, 0.49560546875, 0.491943359375, 0.491455078125, 0.494140625, 0.49755859375, 0.498779296875, 0.4990234375, 0.4990234375, 0.498779296875, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.45166015625, 0.498779296875, 0.498779296875, 0.4990234375, 0.4990234375, 0.498779296875, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.491455078125, 0.496826171875, 0.4970703125, 0.496826171875, 0.4970703125, 0.4970703125, 0.4970703125, 0.49658203125, 0.49658203125, 0.4970703125, 0.49658203125, 0.49609375, 0.49560546875, 0.49560546875, 0.49560546875, 0.49560546875, 0.495849609375, 0.49609375, 0.495361328125, 0.4951171875, 0.49609375, 0.49560546875, 0.495849609375, 0.495849609375, 0.49560546875, 0.495849609375, 0.4951171875, 0.487060546875, 0.5, 0.5, 0.452880859375, 0.4072265625, 0.4306640625, 0.4287109375, 0.49658203125, 0.49609375, 0.49609375, 0.49609375, 0.496337890625, 0.49609375, 0.49609375, 0.496337890625, 0.49609375, 0.49609375, 0.49658203125, 0.49609375, 0.49658203125, 0.49609375, 0.4892578125, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.49853515625, 0.498046875, 0.496337890625, 0.498291015625, 0.49853515625, 0.498291015625, 0.498291015625, 0.498291015625, 0.498046875, 0.498046875, 0.498046875, 0.498046875, 0.486328125, 0.498291015625, 0.498046875, 0.498046875, 0.498046875, 0.498046875, 0.498046875, 0.498291015625, 0.498291015625, 0.49755859375, 0.49560546875, 0.49658203125, 0.49658203125, 0.4970703125, 0.496826171875, 0.4970703125, 0.4970703125, 0.497314453125, 0.49755859375, 0.496826171875, 0.49609375, 0.496337890625, 0.496826171875, 0.496826171875, 0.4970703125, 0.496826171875, 0.4970703125, 0.496826171875, 0.4970703125, 0.495849609375, 0.49609375, 0.494384765625, 0.5, 0.5, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875]}, {'id': 'DF920E0A7337', 'input_ids': [17781, 47, 655, 553, 55, 87, 65, 621, 13, 244, 15, 99, 1152, 7, 907, 11, 10, 1068, 116, 21902, 29, 32, 10, 1969, 1246, 9, 1818, 55, 87, 65, 2979, 4, 21902, 29, 32, 450, 15, 5, 340, 6, 11, 2038, 1612, 6, 8, 97, 2127, 25, 157, 4, 345, 32, 10, 319, 9, 82, 14, 64, 244, 47, 907, 5, 235, 1152, 25, 157, 4, 252, 64, 70, 490, 47, 62, 7, 92, 2956, 4, 38, 206, 1686, 7, 55, 87, 65, 621, 15, 41, 2979, 16, 10, 357, 2031, 142, 24, 924, 47, 55, 87, 65, 1973, 6, 24, 64, 464, 110, 4263, 9, 10, 5674, 6, 8, 24, 22604, 47, 59, 99, 97, 82, 2254, 4, 50118, 50118, 10993, 6, 38, 206, 24, 924, 47, 55, 87, 65, 1973, 4, 509, 2979, 9, 10, 621, 429, 8439, 110, 2031, 15, 41, 1973, 1195, 87, 1273, 24, 62, 4, 20, 1086, 477, 9, 1996, 99, 16, 5, 357, 2031, 6, 16, 7, 146, 24, 357, 6, 45, 3007, 4, 370, 115, 416, 33, 5, 357, 2979, 6, 8, 14, 621, 429, 17948, 24, 6, 53, 55, 82, 74, 492, 47, 10, 205, 2394, 9, 99, 47, 240, 7, 216, 4, 16210, 5086, 64, 22265, 47, 1706, 430, 5274, 4, 22248, 5274, 40, 144, 9, 5, 86, 146, 383, 213, 11, 5, 235, 2698, 4, 3139, 205, 7, 311, 3143, 11, 99, 47, 214, 164, 7, 1339, 11, 645, 7, 120, 5, 275, 2031, 4, 509, 2979, 115, 28, 951, 54, 965, 75, 3978, 15, 5, 1114, 4, 252, 429, 45, 216, 932, 59, 5, 5674, 8, 429, 95, 194, 10, 9624, 1948, 4, 280, 64, 269, 3211, 47, 160, 114, 47, 218, 75, 120, 55, 2956, 87, 95, 14, 65, 621, 4, 280, 64, 33, 5, 276, 1683, 25, 99, 38, 26, 137, 4, 280, 65, 621, 115, 7319, 24, 70, 62, 13, 47, 4, 404, 9, 5, 82, 47, 1394, 924, 47, 55, 87, 99, 47, 802, 21, 5, 275, 2031, 4, 50118, 50118, 19192, 6, 24, 64, 464, 110, 4263, 15, 5, 5674, 4, 509, 621, 64, 464, 110, 1973, 6, 53, 24, 189, 45, 483, 47, 11, 5, 235, 2698, 4, 280, 2698, 115, 146, 47, 13865, 19, 110, 2031, 114, 47, 32, 12818, 10, 1152, 7, 192, 61, 65, 7, 120, 4, 370, 115, 185, 14, 65, 5151, 2949, 8, 1407, 24, 6, 53, 24, 429, 45, 28, 5, 275, 2949, 47, 115, 120, 4, 16210, 82, 33, 10, 357, 778, 9, 981, 47, 7, 5, 235, 2979, 4, 520, 47, 120, 5, 2979, 9, 1533, 82, 6, 24, 17172, 66, 99, 429, 28, 5, 2674, 1973, 6, 50, 99, 429, 28, 5, 357, 1973, 4, 83, 319, 9, 498, 6, 2992, 110, 2979, 16, 13, 5, 357, 4, 370, 115, 28, 546, 23, 5, 1593, 2031, 6, 8, 1533, 5086, 429, 483, 47, 7, 5, 235, 2718, 4, 85, 2029, 92, 2956, 8, 1319, 7, 356, 23, 10, 1068, 8, 146, 5, 235, 2031, 4, 85, 64, 146, 47, 464, 110, 2979, 4, 50118, 50118, 35703, 6, 24, 22604, 47, 59, 99, 97, 82, 2254, 4, 5365, 55, 87, 65, 621, 18, 2979, 429, 483, 7, 41, 1288, 19, 167, 82, 4, 370, 115, 28, 269, 4889, 15, 10, 1402, 1152, 47, 32, 667, 7, 907, 6, 8, 951, 115, 1871, 14, 1445, 1068, 30, 2609, 10, 205, 1732, 9, 14, 1152, 4, 370, 115, 67, 1532, 55, 59, 2040, 8, 16592, 5086, 11, 10, 1402, 443, 6, 50, 10, 1402, 86, 4, 1876, 82, 32, 430, 8, 2128, 14, 16, 716, 160, 9, 5, 1737, 198, 106, 6, 8, 147, 51, 1733, 62, 14, 115, 3327, 99, 10, 621, 3829, 4, 318, 47, 1394, 1533, 82, 11, 5, 276, 443, 47, 2307, 62, 11, 6, 47, 197, 28, 981, 2512, 7, 5, 235, 2031, 4, 85, 64, 67, 483, 7, 529, 92, 82, 6, 8, 442, 92, 964, 4, 370, 115, 2854, 15, 41, 2979, 8, 386, 10, 2175, 89, 4, 85, 70, 2607, 47, 15, 4730, 45, 129, 99, 47, 101, 6, 53, 99, 10, 319, 9, 97, 82, 101, 4, 50118, 50118, 1121, 6427, 6, 2609, 55, 87, 65, 5151, 1217, 16, 357, 142, 24, 924, 55, 87, 65, 2979, 6, 24, 64, 464, 110, 308, 2979, 6, 8, 24, 64, 6296, 47, 15, 99, 97, 82, 2254, 4, 318, 47, 32, 655, 21514, 82, 6, 50, 546, 13, 2949, 31, 97, 82, 7, 146, 5, 235, 568, 6, 146, 686, 47, 1394, 1533, 82, 8, 50141, 3654, 95, 65, 621, 13, 14, 2949, 328, 38, 460, 1394, 964, 6, 284, 6, 50, 97, 82, 13, 244, 8, 2949, 114, 38, 197, 109, 402, 50, 45, 4, 370, 348, 1153, 553, 1533, 82, 13, 2949, 25, 157, 328], 'text': \"Have you ever asked more than one person for help on what product to buy in a situation? Interviews are a perfect example of seeking more than one opinion. Interviews are seen on the news, in professional sports, and other places as well. There are a lot of people that can help you buy the right product as well. They can all open you up to new ideas. I think talking to more than one person on an opinion is a better choice because it shows you more than one option, it can change your perspective of a topic, and it informs you about what other people enjoy.\\n\\nFirst, I think it shows you more than one option. One opinion of a person might destroy your choice on an option rather than opening it up. The whole point of asking what is the better choice, is to make it better, not worse. You could already have the better opinion, and that person might ruin it, but more people would give you a good balance of what you need to know. Multiple opinions can stride you toward different answers. Different answers will most of the time make things go in the right direction. Its good to show variety in what you're going to pick in order to get the best choice. One opinion could be someone who isn't informed on the idea. They might not know anything about the topic and might just state a random answer. That can really throw you off if you don't get more ideas than just that one person. That can have the same effect as what I said before. That one person could mess it all up for you. All of the people you ask shows you more than what you thought was the best choice.\\n\\nNext, it can change your perspective on the topic. One person can change your option, but it may not lead you in the right direction. That direction could make you unhappy with your choice if you are comparing a product to see which one to get. You could take that one persons advice and follow it, but it might not be the best advice you could get. Multiple people have a better chance of leading you to the right opinion. When you get the opinion of multiple people, it balances out what might be the favorite option, or what might be the better option. A lot of times, changing your opinion is for the better. You could be looking at the wrong choice, and multiple opinions might lead you to the right path. It gives new ideas and ways to look at a situation and make the right choice. It can make you change your opinion.\\n\\nFinally, it informs you about what other people enjoy. Having more than one person's opinion might lead to an agreement with those people. You could be really stuck on a certain product you are trying to buy, and someone could save that entire situation by finding a good version of that product. You could also learn more about culture and peoples opinions in a certain area, or a certain time. Many people are different and sometimes that is based off of the environment around them, and where they grow up that could affect what a person likes. If you ask multiple people in the same area you grew up in, you should be leading yourself to the right choice. It can also lead to meeting new people, and making new friends. You could agree on an opinion and start a bond there. It all helps you on knowing not only what you like, but what a lot of other people like.\\n\\nIn conclusion, finding more than one persons view is better because it shows more than one opinion, it can change your own opinion, and it can inform you on what other people enjoy. If you are ever interviewing people, or looking for advice from other people to make the right decision, make sure you ask multiple people and\\xa0not just one person for that advice! I always ask friends, family, or other people for help and advice if I should do something or not. You've probably asked multiple people for advice as well!\", 'offset_mapping': [(0, 4), (5, 8), (9, 13), (14, 19), (20, 24), (25, 29), (30, 33), (34, 40), (41, 44), (45, 49), (50, 52), (53, 57), (58, 65), (66, 68), (69, 72), (73, 75), (76, 77), (78, 87), (87, 88), (89, 98), (98, 99), (100, 103), (104, 105), (106, 113), (114, 121), (122, 124), (125, 132), (133, 137), (138, 142), (143, 146), (147, 154), (154, 155), (156, 165), (165, 166), (167, 170), (171, 175), (176, 178), (179, 182), (183, 187), (187, 188), (189, 191), (192, 204), (205, 211), (211, 212), (213, 216), (217, 222), (223, 229), (230, 232), (233, 237), (237, 238), (239, 244), (245, 248), (249, 250), (251, 254), (255, 257), (258, 264), (265, 269), (270, 273), (274, 278), (279, 282), (283, 286), (287, 290), (291, 296), (297, 304), (305, 307), (308, 312), (312, 313), (314, 318), (319, 322), (323, 326), (327, 331), (332, 335), (336, 338), (339, 341), (342, 345), (346, 351), (351, 352), (353, 354), (355, 360), (361, 368), (369, 371), (372, 376), (377, 381), (382, 385), (386, 392), (393, 395), (396, 398), (399, 406), (407, 409), (410, 411), (412, 418), (419, 425), (426, 433), (434, 436), (437, 442), (443, 446), (447, 451), (452, 456), (457, 460), (461, 467), (467, 468), (469, 471), (472, 475), (476, 482), (483, 487), (488, 499), (500, 502), (503, 504), (505, 510), (510, 511), (512, 515), (516, 518), (519, 526), (527, 530), (531, 536), (537, 541), (542, 547), (548, 554), (555, 560), (560, 561), (561, 562), (562, 563), (563, 568), (568, 569), (570, 571), (572, 577), (578, 580), (581, 586), (587, 590), (591, 595), (596, 600), (601, 604), (605, 611), (611, 612), (613, 616), (617, 624), (625, 627), (628, 629), (630, 636), (637, 642), (643, 650), (651, 655), (656, 662), (663, 665), (666, 668), (669, 675), (676, 682), (683, 687), (688, 695), (696, 698), (699, 701), (701, 702), (703, 706), (707, 712), (713, 718), (719, 721), (722, 728), (729, 733), (734, 736), (737, 740), (741, 747), (748, 754), (754, 755), (756, 758), (759, 761), (762, 766), (767, 769), (770, 776), (776, 777), (778, 781), (782, 787), (787, 788), (789, 792), (793, 798), (799, 806), (807, 811), (812, 815), (816, 822), (823, 830), (830, 831), (832, 835), (836, 840), (841, 847), (848, 853), (854, 858), (859, 861), (861, 862), (863, 866), (867, 871), (872, 878), (879, 884), (885, 889), (890, 893), (894, 895), (896, 900), (901, 908), (909, 911), (912, 916), (917, 920), (921, 925), (926, 928), (929, 933), (933, 934), (935, 943), (944, 952), (953, 956), (957, 963), (964, 967), (968, 974), (975, 984), (985, 992), (992, 993), (994, 1003), (1004, 1011), (1012, 1016), (1017, 1021), (1022, 1024), (1025, 1028), (1029, 1033), (1034, 1038), (1039, 1045), (1046, 1048), (1049, 1051), (1052, 1055), (1056, 1061), (1062, 1071), (1071, 1072), (1073, 1076), (1077, 1081), (1082, 1084), (1085, 1089), (1090, 1097), (1098, 1100), (1101, 1105), (1106, 1109), (1109, 1112), (1113, 1118), (1119, 1121), (1122, 1126), (1127, 1129), (1130, 1135), (1136, 1138), (1139, 1142), (1143, 1146), (1147, 1151), (1152, 1158), (1158, 1159), (1160, 1163), (1164, 1171), (1172, 1177), (1178, 1180), (1181, 1188), (1189, 1192), (1193, 1196), (1196, 1198), (1199, 1207), (1208, 1210), (1211, 1214), (1215, 1219), (1219, 1220), (1221, 1225), (1226, 1231), (1232, 1235), (1236, 1240), (1241, 1249), (1250, 1255), (1256, 1259), (1260, 1265), (1266, 1269), (1270, 1275), (1276, 1280), (1281, 1286), (1287, 1288), (1289, 1295), (1296, 1302), (1302, 1303), (1304, 1308), (1309, 1312), (1313, 1319), (1320, 1325), (1326, 1329), (1330, 1333), (1334, 1336), (1337, 1340), (1341, 1344), (1344, 1346), (1347, 1350), (1351, 1355), (1356, 1361), (1362, 1366), (1367, 1371), (1372, 1376), (1377, 1380), (1381, 1387), (1387, 1388), (1389, 1393), (1394, 1397), (1398, 1402), (1403, 1406), (1407, 1411), (1412, 1418), (1419, 1421), (1422, 1426), (1427, 1428), (1429, 1433), (1434, 1440), (1440, 1441), (1442, 1446), (1447, 1450), (1451, 1457), (1458, 1463), (1464, 1468), (1469, 1471), (1472, 1475), (1476, 1478), (1479, 1482), (1483, 1486), (1486, 1487), (1488, 1491), (1492, 1494), (1495, 1498), (1499, 1505), (1506, 1509), (1510, 1513), (1514, 1519), (1520, 1523), (1524, 1528), (1529, 1533), (1534, 1538), (1539, 1542), (1543, 1550), (1551, 1554), (1555, 1558), (1559, 1563), (1564, 1570), (1570, 1571), (1571, 1572), (1572, 1573), (1573, 1577), (1577, 1578), (1579, 1581), (1582, 1585), (1586, 1592), (1593, 1597), (1598, 1609), (1610, 1612), (1613, 1616), (1617, 1622), (1622, 1623), (1624, 1627), (1628, 1634), (1635, 1638), (1639, 1645), (1646, 1650), (1651, 1657), (1657, 1658), (1659, 1662), (1663, 1665), (1666, 1669), (1670, 1673), (1674, 1678), (1679, 1682), (1683, 1685), (1686, 1689), (1690, 1695), (1696, 1705), (1705, 1706), (1707, 1711), (1712, 1721), (1722, 1727), (1728, 1732), (1733, 1736), (1737, 1744), (1745, 1749), (1750, 1754), (1755, 1761), (1762, 1764), (1765, 1768), (1769, 1772), (1773, 1782), (1783, 1784), (1785, 1792), (1793, 1795), (1796, 1799), (1800, 1805), (1806, 1809), (1810, 1812), (1813, 1816), (1816, 1817), (1818, 1821), (1822, 1827), (1828, 1832), (1833, 1837), (1838, 1841), (1842, 1849), (1850, 1856), (1857, 1860), (1861, 1867), (1868, 1870), (1870, 1871), (1872, 1875), (1876, 1878), (1879, 1884), (1885, 1888), (1889, 1891), (1892, 1895), (1896, 1900), (1901, 1907), (1908, 1911), (1912, 1917), (1918, 1921), (1921, 1922), (1923, 1931), (1932, 1938), (1939, 1943), (1944, 1945), (1946, 1952), (1953, 1959), (1960, 1962), (1963, 1970), (1971, 1974), (1975, 1977), (1978, 1981), (1982, 1987), (1988, 1995), (1995, 1996), (1997, 2001), (2002, 2005), (2006, 2009), (2010, 2013), (2014, 2021), (2022, 2024), (2025, 2033), (2034, 2040), (2040, 2041), (2042, 2044), (2045, 2053), (2054, 2057), (2058, 2062), (2063, 2068), (2069, 2071), (2072, 2075), (2076, 2084), (2085, 2091), (2091, 2092), (2093, 2095), (2096, 2100), (2101, 2106), (2107, 2109), (2110, 2113), (2114, 2120), (2121, 2127), (2127, 2128), (2129, 2130), (2131, 2134), (2135, 2137), (2138, 2143), (2143, 2144), (2145, 2153), (2154, 2158), (2159, 2166), (2167, 2169), (2170, 2173), (2174, 2177), (2178, 2184), (2184, 2185), (2186, 2189), (2190, 2195), (2196, 2198), (2199, 2206), (2207, 2209), (2210, 2213), (2214, 2219), (2220, 2226), (2226, 2227), (2228, 2231), (2232, 2240), (2241, 2249), (2250, 2255), (2256, 2260), (2261, 2264), (2265, 2267), (2268, 2271), (2272, 2277), (2278, 2282), (2282, 2283), (2284, 2286), (2287, 2292), (2293, 2296), (2297, 2302), (2303, 2306), (2307, 2311), (2312, 2314), (2315, 2319), (2320, 2322), (2323, 2324), (2325, 2334), (2335, 2338), (2339, 2343), (2344, 2347), (2348, 2353), (2354, 2360), (2360, 2361), (2362, 2364), (2365, 2368), (2369, 2373), (2374, 2377), (2378, 2384), (2385, 2389), (2390, 2397), (2397, 2398), (2398, 2399), (2399, 2400), (2400, 2407), (2407, 2408), (2409, 2411), (2412, 2419), (2420, 2423), (2424, 2429), (2430, 2434), (2435, 2440), (2441, 2447), (2448, 2453), (2453, 2454), (2455, 2461), (2462, 2466), (2467, 2471), (2472, 2475), (2476, 2482), (2482, 2484), (2485, 2492), (2493, 2498), (2499, 2503), (2504, 2506), (2507, 2509), (2510, 2519), (2520, 2524), (2525, 2530), (2531, 2537), (2537, 2538), (2539, 2542), (2543, 2548), (2549, 2551), (2552, 2558), (2559, 2564), (2565, 2567), (2568, 2569), (2570, 2577), (2578, 2585), (2586, 2589), (2590, 2593), (2594, 2600), (2601, 2603), (2604, 2607), (2607, 2608), (2609, 2612), (2613, 2620), (2621, 2626), (2627, 2631), (2632, 2636), (2637, 2643), (2644, 2653), (2654, 2656), (2657, 2664), (2665, 2666), (2667, 2671), (2672, 2679), (2680, 2682), (2683, 2687), (2688, 2695), (2695, 2696), (2697, 2700), (2701, 2706), (2707, 2711), (2712, 2717), (2718, 2722), (2723, 2728), (2729, 2736), (2737, 2740), (2741, 2748), (2749, 2757), (2758, 2760), (2761, 2762), (2763, 2770), (2771, 2775), (2775, 2776), (2777, 2779), (2780, 2781), (2782, 2789), (2790, 2794), (2794, 2795), (2796, 2800), (2801, 2807), (2808, 2811), (2812, 2821), (2822, 2825), (2826, 2835), (2836, 2840), (2841, 2843), (2844, 2849), (2850, 2853), (2854, 2856), (2857, 2860), (2861, 2872), (2873, 2879), (2880, 2884), (2884, 2885), (2886, 2889), (2890, 2895), (2896, 2900), (2901, 2905), (2906, 2908), (2909, 2913), (2914, 2919), (2920, 2926), (2927, 2931), (2932, 2933), (2934, 2940), (2941, 2946), (2946, 2947), (2948, 2950), (2951, 2954), (2955, 2958), (2959, 2967), (2968, 2974), (2975, 2977), (2978, 2981), (2982, 2986), (2987, 2991), (2992, 2995), (2996, 3000), (3001, 3003), (3004, 3006), (3006, 3007), (3008, 3011), (3012, 3018), (3019, 3021), (3022, 3029), (3030, 3038), (3039, 3041), (3042, 3045), (3046, 3051), (3052, 3058), (3058, 3059), (3060, 3062), (3063, 3066), (3067, 3071), (3072, 3076), (3077, 3079), (3080, 3087), (3088, 3091), (3092, 3098), (3098, 3099), (3100, 3103), (3104, 3110), (3111, 3114), (3115, 3122), (3122, 3123), (3124, 3127), (3128, 3133), (3134, 3139), (3140, 3142), (3143, 3145), (3146, 3153), (3154, 3157), (3158, 3163), (3164, 3165), (3166, 3170), (3171, 3176), (3176, 3177), (3178, 3180), (3181, 3184), (3185, 3190), (3191, 3194), (3195, 3197), (3198, 3205), (3206, 3209), (3210, 3214), (3215, 3219), (3220, 3223), (3224, 3228), (3228, 3229), (3230, 3233), (3234, 3238), (3239, 3240), (3241, 3244), (3245, 3247), (3248, 3253), (3254, 3260), (3261, 3265), (3265, 3266), (3266, 3267), (3267, 3268), (3268, 3270), (3271, 3281), (3281, 3282), (3283, 3290), (3291, 3295), (3296, 3300), (3301, 3304), (3305, 3312), (3313, 3317), (3318, 3320), (3321, 3327), (3328, 3335), (3336, 3338), (3339, 3344), (3345, 3349), (3350, 3354), (3355, 3358), (3359, 3366), (3366, 3367), (3368, 3370), (3371, 3374), (3375, 3381), (3382, 3386), (3387, 3390), (3391, 3398), (3398, 3399), (3400, 3403), (3404, 3406), (3407, 3410), (3411, 3417), (3418, 3421), (3422, 3424), (3425, 3429), (3430, 3435), (3436, 3442), (3443, 3448), (3448, 3449), (3450, 3452), (3453, 3456), (3457, 3460), (3461, 3465), (3466, 3478), (3479, 3485), (3485, 3486), (3487, 3489), (3490, 3497), (3498, 3501), (3502, 3508), (3509, 3513), (3514, 3519), (3520, 3526), (3527, 3529), (3530, 3534), (3535, 3538), (3539, 3544), (3545, 3553), (3553, 3554), (3555, 3559), (3560, 3564), (3565, 3568), (3569, 3572), (3573, 3581), (3582, 3588), (3589, 3592), (3592, 3593), (3593, 3596), (3597, 3601), (3602, 3605), (3606, 3612), (3613, 3616), (3617, 3621), (3622, 3628), (3628, 3629), (3630, 3631), (3632, 3638), (3639, 3642), (3643, 3650), (3650, 3651), (3652, 3658), (3658, 3659), (3660, 3662), (3663, 3668), (3669, 3675), (3676, 3679), (3680, 3684), (3685, 3688), (3689, 3695), (3696, 3698), (3699, 3700), (3701, 3707), (3708, 3710), (3711, 3720), (3721, 3723), (3724, 3727), (3727, 3728), (3729, 3732), (3732, 3735), (3736, 3744), (3745, 3750), (3751, 3759), (3760, 3766), (3767, 3770), (3771, 3777), (3778, 3780), (3781, 3785), (3785, 3786)], 'preds': ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'O', 'O', 'O', 'B-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'O', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence'], 'pred_scores': [0.49853515625, 0.498779296875, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.498779296875, 0.49853515625, 0.4990234375, 0.498779296875, 0.4990234375, 0.4990234375, 0.498779296875, 0.4990234375, 0.498779296875, 0.4990234375, 0.4990234375, 0.498779296875, 0.4990234375, 0.49755859375, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.498291015625, 0.498046875, 0.498046875, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.49853515625, 0.498046875, 0.49853515625, 0.49853515625, 0.49853515625, 0.498291015625, 0.49853515625, 0.498291015625, 0.496337890625, 0.498046875, 0.4970703125, 0.47021484375, 0.49658203125, 0.496337890625, 0.49560546875, 0.49658203125, 0.49658203125, 0.49658203125, 0.49609375, 0.496337890625, 0.468505859375, 0.4970703125, 0.49609375, 0.49658203125, 0.496337890625, 0.49560546875, 0.4951171875, 0.493896484375, 0.492919921875, 0.4931640625, 0.4931640625, 0.492431640625, 0.49267578125, 0.49267578125, 0.49072265625, 0.468017578125, 0.48974609375, 0.489013671875, 0.41162109375, 0.498046875, 0.496826171875, 0.49755859375, 0.497802734375, 0.498046875, 0.497802734375, 0.498046875, 0.497802734375, 0.498046875, 0.49755859375, 0.498046875, 0.497802734375, 0.45703125, 0.46826171875, 0.496337890625, 0.49853515625, 0.49853515625, 0.4990234375, 0.49853515625, 0.498046875, 0.4423828125, 0.49169921875, 0.49658203125, 0.49853515625, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.498291015625, 0.25146484375, 0.47314453125, 0.4892578125, 0.49609375, 0.49853515625, 0.4990234375, 0.49853515625, 0.49853515625, 0.49853515625, 0.49755859375, 0.49072265625, 0.5, 0.5, 0.486328125, 0.466796875, 0.35791015625, 0.3154296875, 0.235595703125, 0.290283203125, 0.29736328125, 0.297119140625, 0.30322265625, 0.302490234375, 0.294677734375, 0.27783203125, 0.482421875, 0.4912109375, 0.491455078125, 0.4921875, 0.4912109375, 0.4912109375, 0.48974609375, 0.4912109375, 0.49072265625, 0.4912109375, 0.4921875, 0.4912109375, 0.490234375, 0.4912109375, 0.49072265625, 0.490966796875, 0.489990234375, 0.49267578125, 0.4921875, 0.4990234375, 0.4990234375, 0.499267578125, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49365234375, 0.49853515625, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.4970703125, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.49951171875, 0.49658203125, 0.498779296875, 0.4990234375, 0.4990234375, 0.49853515625, 0.49853515625, 0.4990234375, 0.4990234375, 0.4990234375, 0.498046875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.4990234375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.493408203125, 0.498291015625, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.499755859375, 0.499755859375, 0.49951171875, 0.499755859375, 0.499755859375, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.49951171875, 0.494140625, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.49951171875, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.49658203125, 0.49853515625, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.482666015625, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.484375, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.48779296875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499755859375, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.498779296875, 0.49658203125, 0.4970703125, 0.49755859375, 0.49755859375, 0.4970703125, 0.49755859375, 0.49755859375, 0.4970703125, 0.49755859375, 0.4970703125, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49755859375, 0.49658203125, 0.5, 0.5, 0.486083984375, 0.4697265625, 0.2802734375, 0.26123046875, 0.281005859375, 0.289794921875, 0.296875, 0.297607421875, 0.28076171875, 0.281982421875, 0.259521484375, 0.4873046875, 0.48681640625, 0.488037109375, 0.4892578125, 0.4892578125, 0.4892578125, 0.481689453125, 0.490234375, 0.49169921875, 0.4912109375, 0.4921875, 0.49169921875, 0.4921875, 0.4921875, 0.49267578125, 0.49072265625, 0.49169921875, 0.4921875, 0.490966796875, 0.499267578125, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.498046875, 0.4990234375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499267578125, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.4990234375, 0.49560546875, 0.4970703125, 0.497802734375, 0.498046875, 0.49755859375, 0.4970703125, 0.497802734375, 0.49755859375, 0.49755859375, 0.498046875, 0.498046875, 0.49755859375, 0.49755859375, 0.498046875, 0.4951171875, 0.49853515625, 0.498779296875, 0.498779296875, 0.4990234375, 0.498779296875, 0.498779296875, 0.49853515625, 0.498779296875, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.499267578125, 0.4990234375, 0.499267578125, 0.499267578125, 0.499267578125, 0.4990234375, 0.4990234375, 0.49755859375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.499267578125, 0.4990234375, 0.49853515625, 0.499267578125, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.49951171875, 0.499267578125, 0.4990234375, 0.499267578125, 0.4990234375, 0.4990234375, 0.499267578125, 0.499267578125, 0.4990234375, 0.499267578125, 0.499267578125, 0.499267578125, 0.499267578125, 0.497802734375, 0.4970703125, 0.497802734375, 0.49755859375, 0.497314453125, 0.498046875, 0.497802734375, 0.497802734375, 0.497802734375, 0.498046875, 0.49755859375, 0.497802734375, 0.498046875, 0.498046875, 0.497314453125, 0.498046875, 0.49755859375, 0.495849609375, 0.495849609375, 0.4951171875, 0.4951171875, 0.494384765625, 0.495361328125, 0.494140625, 0.49365234375, 0.49267578125, 0.40087890625, 0.5, 0.483154296875, 0.47119140625, 0.29150390625, 0.270263671875, 0.27197265625, 0.28662109375, 0.29638671875, 0.30615234375, 0.316650390625, 0.303955078125, 0.262939453125, 0.48681640625, 0.4931640625, 0.493408203125, 0.493408203125, 0.49365234375, 0.493896484375, 0.494140625, 0.49462890625, 0.494873046875, 0.494873046875, 0.495849609375, 0.49560546875, 0.4951171875, 0.49560546875, 0.495361328125, 0.494873046875, 0.487548828125, 0.49951171875, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.499755859375, 0.499755859375, 0.499755859375, 0.499755859375, 0.5, 0.499755859375, 0.49951171875, 0.49853515625, 0.5, 0.499755859375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.49951171875, 0.498291015625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.47509765625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4990234375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.486328125, 0.4990234375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.499267578125, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.423583984375, 0.4990234375, 0.49951171875, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.49853515625, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.4990234375, 0.498046875, 0.49951171875, 0.49951171875, 0.424560546875, 0.429931640625, 0.4423828125, 0.396240234375, 0.49365234375, 0.49365234375, 0.49267578125, 0.49267578125, 0.493408203125, 0.493896484375, 0.494384765625, 0.4951171875, 0.495849609375, 0.498046875, 0.498046875, 0.498046875, 0.497802734375, 0.497802734375, 0.49755859375, 0.495849609375, 0.498291015625, 0.498291015625, 0.498291015625, 0.498291015625, 0.498291015625, 0.498046875, 0.49755859375, 0.4970703125, 0.498291015625, 0.498291015625, 0.498291015625, 0.498291015625, 0.498291015625, 0.498291015625, 0.498291015625, 0.498291015625, 0.4921875, 0.47802734375, 0.473388671875, 0.47509765625, 0.473876953125, 0.476318359375, 0.4755859375, 0.475830078125, 0.47802734375, 0.478759765625, 0.478515625, 0.47802734375, 0.48193359375, 0.4814453125, 0.482666015625, 0.478515625, 0.47998046875, 0.461669921875, 0.478271484375, 0.479736328125, 0.47412109375, 0.4736328125, 0.47119140625, 0.47119140625, 0.4716796875, 0.4736328125, 0.47509765625, 0.47265625, 0.46728515625, 0.4775390625, 0.47802734375, 0.4794921875, 0.478515625, 0.47216796875, 0.47021484375, 0.471435546875, 0.468017578125, 0.4501953125, 0.43408203125, 0.43798828125, 0.44091796875, 0.442626953125, 0.444091796875, 0.444091796875, 0.4375, 0.4384765625, 0.44091796875, 0.436279296875, 0.4365234375, 0.4375, 0.43994140625, 0.43408203125, 0.43310546875, 0.4423828125, 0.4423828125, 0.43701171875, 0.44091796875, 0.438232421875, 0.455078125, 0.3828125, 0.3720703125, 0.376953125, 0.379150390625, 0.3798828125, 0.38330078125, 0.3798828125, 0.38427734375, 0.369140625, 0.36669921875, 0.367431640625, 0.49951171875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875, 0.082763671875]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jn(pst, start, end):\n",
        "    return \" \".join([str(x) for x in pst[start:end]])\n",
        "\n",
        "\n",
        "def link_evidence(oof):\n",
        "    thresh = 1\n",
        "    idu = oof['id'].unique()\n",
        "    idc = idu[1]\n",
        "    eoof = oof[oof['class'] == \"Evidence\"]\n",
        "    neoof = oof[oof['class'] != \"Evidence\"]\n",
        "    for thresh2 in range(26,27, 1):\n",
        "        retval = []\n",
        "        for idv in idu:\n",
        "            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n",
        "                   'Counterclaim', 'Rebuttal']:\n",
        "                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n",
        "                if len(q) == 0:\n",
        "                    continue\n",
        "                pst = []\n",
        "                for i,r in q.iterrows():\n",
        "                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n",
        "                start = 1\n",
        "                end = 1\n",
        "                for i in range(2,len(pst)):\n",
        "                    cur = pst[i]\n",
        "                    end = i\n",
        "                    #if pst[start] == 205:\n",
        "                    #   print(cur, pst[start], cur - pst[start])\n",
        "                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n",
        "                        retval.append((idv, c, jn(pst, start, end)))\n",
        "                        start = i + 1\n",
        "                v = (idv, c, jn(pst, start, end+1))\n",
        "                #print(v)\n",
        "                retval.append(v)\n",
        "        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n",
        "        roof = roof.merge(neoof, how='outer')\n",
        "        return roof"
      ],
      "metadata": {
        "id": "_lVBTwLVvGP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proba_thresh = {\n",
        "    \"Lead\": 0.7,\n",
        "    \"Position\": 0.55,\n",
        "    \"Evidence\": 0.65,\n",
        "    \"Claim\": 0.55,\n",
        "    \"Concluding Statement\": 0.7,\n",
        "    \"Counterclaim\": 0.5,\n",
        "    \"Rebuttal\": 0.55,\n",
        "}\n",
        "\n",
        "min_thresh = {\n",
        "    \"Lead\": 9,\n",
        "    \"Position\": 5,\n",
        "    \"Evidence\": 14,\n",
        "    \"Claim\": 3,\n",
        "    \"Concluding Statement\": 11,\n",
        "    \"Counterclaim\": 6,\n",
        "    \"Rebuttal\": 4,\n",
        "}\n",
        "\n",
        "submission = []\n",
        "for sample_idx, sample in enumerate(test_samples):\n",
        "    preds = sample[\"preds\"]\n",
        "    offset_mapping = sample[\"offset_mapping\"]\n",
        "    sample_id = sample[\"id\"]\n",
        "    sample_text = sample[\"text\"]\n",
        "    sample_input_ids = sample[\"input_ids\"]\n",
        "    sample_pred_scores = sample[\"pred_scores\"]\n",
        "    sample_preds = []\n",
        "\n",
        "    if len(preds) < len(offset_mapping):\n",
        "        preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n",
        "        sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n",
        "    \n",
        "    idx = 0\n",
        "    phrase_preds = []\n",
        "    while idx < len(offset_mapping):\n",
        "        start, _ = offset_mapping[idx]\n",
        "        if preds[idx] != \"O\":\n",
        "            label = preds[idx][2:]\n",
        "        else:\n",
        "            label = \"O\"\n",
        "        phrase_scores = []\n",
        "        phrase_scores.append(sample_pred_scores[idx])\n",
        "        idx += 1\n",
        "        while idx < len(offset_mapping):\n",
        "            if label == \"O\":\n",
        "                matching_label = \"O\"\n",
        "            else:\n",
        "                matching_label = f\"I-{label}\"\n",
        "            if preds[idx] == matching_label:\n",
        "                _, end = offset_mapping[idx]\n",
        "                phrase_scores.append(sample_pred_scores[idx])\n",
        "                idx += 1\n",
        "            else:\n",
        "                break\n",
        "        if \"end\" in locals():\n",
        "            phrase = sample_text[start:end]\n",
        "            phrase_preds.append((phrase, start, end, label, phrase_scores))\n",
        "\n",
        "    temp_df = []\n",
        "    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n",
        "        word_start = len(sample_text[:start].split())\n",
        "        word_end = word_start + len(sample_text[start:end].split())\n",
        "        word_end = min(word_end, len(sample_text.split()))\n",
        "        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n",
        "        if label != \"O\":\n",
        "            #print(f'{sum(phrase_scores) / len(phrase_scores)} {proba_thresh[label]}')\n",
        "            #if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n",
        "            if len(ps.split()) >= min_thresh[label]:\n",
        "                temp_df.append((sample_id, label, ps))\n",
        "\n",
        "    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n",
        "    submission.append(temp_df)\n",
        "\n",
        "    \n",
        "\n",
        "submission = pd.concat(submission).reset_index(drop=True)\n",
        "submission = link_evidence(submission)\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "CWwayHXn_AOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "Xp_CLw5uEPFa",
        "outputId": "c9ea70a9-2087-4ad7-ddd4-902db4ca37e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-01b75f3e-08ff-40b3-8d88-908317a83625\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>class</th>\n",
              "      <th>predictionstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18409261F5C2</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>162 163 164 165 166 167 168 169 170 171 172 17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18409261F5C2</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>441 442 443 444 445 446 447 448 449 450 451 45...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18409261F5C2</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>739 740 741 742 743 744 745 746 747 748 749 75...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D46BCB48440A</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D46BCB48440A</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>150 151 152 153 154 155 156 157 158 159 160 16...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01b75f3e-08ff-40b3-8d88-908317a83625')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01b75f3e-08ff-40b3-8d88-908317a83625 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01b75f3e-08ff-40b3-8d88-908317a83625');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             id     class                                   predictionstring\n",
              "0  18409261F5C2  Evidence  162 163 164 165 166 167 168 169 170 171 172 17...\n",
              "1  18409261F5C2  Evidence  441 442 443 444 445 446 447 448 449 450 451 45...\n",
              "2  18409261F5C2  Evidence  739 740 741 742 743 744 745 746 747 748 749 75...\n",
              "3  D46BCB48440A  Evidence  56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 7...\n",
              "4  D46BCB48440A  Evidence  150 151 152 153 154 155 156 157 158 159 160 16..."
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}